{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfc088e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original byonic columns:\n",
      "Index(['PID', 'Prot._x000D_\\nRank', 'Pos.', 'Sequence_x000D_\\n(unformatted)',\n",
      "       'Mods_x000D_\\n(variable)', 'Glycans', 'PEP_x000D_\\n2D',\n",
      "       'PEP_x000D_\\n1D', '|Log Prob|', 'Score', 'Delta_x000D_\\nScore',\n",
      "       'Delta Mod._x000D_\\nScore', 'z', 'Obs._x000D_\\nm/z',\n",
      "       'Calc._x000D_\\nm/z', 'ppm_x000D_\\nerr.', 'Off-_x000D_\\nBy-X',\n",
      "       'Obs._x000D_\\nMH', 'Calc._x000D_\\nMH', 'Cleavage',\n",
      "       'Glycans_x000D_\\nPos.', 'Protein_x000D_\\nName', 'Prot._x000D_\\nId',\n",
      "       'Scan_x000D_\\nTime', 'Scan #', 'Mods_x000D_\\n(fixed)', 'Comment',\n",
      "       'Fragment_x000D_\\nType', 'FDR_x000D_\\n2D', 'FDR_x000D_\\n1D',\n",
      "       'FDR uniq._x000D_\\n2D', 'FDR uniq._x000D_\\n1D', 'q-value_x000D_\\n2D',\n",
      "       'q-value_x000D_\\n1D', 'Scan info', 'MobilityValue'],\n",
      "      dtype='object')\n",
      "\n",
      "Fixed byonic columns:\n",
      "Index(['PID', 'Prot.\\r\\nRank', 'Pos.', 'Sequence\\r\\n(unformatted)',\n",
      "       'Mods\\r\\n(variable)', 'Glycans', 'PEP\\r\\n2D', 'PEP\\r\\n1D', '|Log Prob|',\n",
      "       'Score', 'Delta\\r\\nScore', 'Delta Mod.\\r\\nScore', 'z', 'Obs.\\r\\nm/z',\n",
      "       'Calc.\\r\\nm/z', 'ppm\\r\\nerr.', 'Off-\\r\\nBy-X', 'Obs.\\r\\nMH',\n",
      "       'Calc.\\r\\nMH', 'Cleavage', 'Glycans\\r\\nPos.', 'Protein\\r\\nName',\n",
      "       'Prot.\\r\\nId', 'Scan\\r\\nTime', 'Scan #', 'Mods\\r\\n(fixed)', 'Comment',\n",
      "       'Fragment\\r\\nType', 'FDR\\r\\n2D', 'FDR\\r\\n1D', 'FDR uniq.\\r\\n2D',\n",
      "       'FDR uniq.\\r\\n1D', 'q-value\\r\\n2D', 'q-value\\r\\n1D', 'Scan info',\n",
      "       'MobilityValue'],\n",
      "      dtype='object')\n",
      "\n",
      "Original byonic data size:\n",
      "row: 409\n",
      "col: 36\n",
      "\n",
      "----- Byonic data preprocessing completed. -----\n",
      "\n",
      "Original byos columns:\n",
      "Index(['Row#', 'PID', 'Protein_x000D_\\nname', 'Sequence',\n",
      "       'XIC area_x000D_\\nsummed', 'XIC_x000D_\\nAUC', 'XIC_x000D_\\nRatio%',\n",
      "       'Apex Time_x000D_\\n(Posit)', 'MS_x000D_\\nAlias name',\n",
      "       'Mod._x000D_\\nSummary', 'Mod._x000D_\\nAAs', 'z', 'Validate', 'Comment',\n",
      "       'Labels', 'Var. Pos._x000D_\\nProtein', 'Var. Pos._x000D_\\nPeptide',\n",
      "       'Start_x000D_\\nAA', 'End_x000D_\\nAA', 'PEP_x000D_\\n2D',\n",
      "       'PEP_x000D_\\n1D', 'Score', 'Delta_x000D_\\nScore',\n",
      "       'Delta Mod._x000D_\\nScore', 'Obs._x000D_\\nm/z', 'Calc._x000D_\\nm/z',\n",
      "       'ppm', 'Off-_x000D_\\nBy-X', 'Obs.M', 'Calc.M',\n",
      "       'Delta R.T. Obs-_x000D_\\nDelta R.T. Prd.',\n",
      "       'Scan Time(s)_x000D_\\n(Posit)', 'Glycans', 'MS_x000D_\\nId', '_prot_id',\n",
      "       'Apex Int._x000D_\\n(Posit)', 'Scan Number(s)_x000D_\\n(Posit)',\n",
      "       'Obs. time_x000D_\\nVar (min)', 'Obs. time_x000D_\\nWild (min)',\n",
      "       'XIC_x000D_\\nStart', 'XIC_x000D_\\nEnd', 'MS2 Search_x000D_\\nAlias name',\n",
      "       'MS2 Search_x000D_\\nFilename', 'MS_x000D_\\nFilename',\n",
      "       'Quant_x000D_\\nlevel', 'Digest_x000D_\\nname',\n",
      "       'Digest_x000D_\\nStart Peptide', 'Digest_x000D_\\nEnd Peptide',\n",
      "       'Digest_x000D_\\nN-term ragged', 'Digest_x000D_\\nC-term ragged',\n",
      "       'Digest_x000D_\\nMissed Cleavages', 'Byonic Comment',\n",
      "       'Protein_x000D_\\nalias name', 'Fragment_x000D_\\ntype(s)', 'In silico',\n",
      "       'Sample_x000D_\\ntype', 'Protein molecular_x000D_\\nweight',\n",
      "       'Protein isoelectric_x000D_\\npoint', 'Total XIC AUC_x000D_\\nAveragine',\n",
      "       'MS1_x000D_\\ncorrelation', 'XIC_x000D_\\ncorrelation', 'FWHM',\n",
      "       'Protein_x000D_\\nannotation', 'XIC_x000D_\\nproposals', 'Center of m/z',\n",
      "       'Scan info', 'Protein_x000D_\\noccurrence(s)',\n",
      "       'Fixed Mod._x000D_\\nSummary', 'MS/MS Query', 'Isotope Query',\n",
      "       'Mobility Start', 'Mobility End', 'Glycan_x000D_\\nstructure',\n",
      "       'MS1 isotope_x000D_\\nenvelope confidence'],\n",
      "      dtype='object')\n",
      "\n",
      "Fixed byos columns:\n",
      "Index(['Row#', 'PID', 'Protein\\r\\nname', 'Sequence', 'XIC area\\r\\nsummed',\n",
      "       'XIC\\r\\nAUC', 'XIC\\r\\nRatio%', 'Apex Time\\r\\n(Posit)',\n",
      "       'MS\\r\\nAlias name', 'Mod.\\r\\nSummary', 'Mod.\\r\\nAAs', 'z', 'Validate',\n",
      "       'Comment', 'Labels', 'Var. Pos.\\r\\nProtein', 'Var. Pos.\\r\\nPeptide',\n",
      "       'Start\\r\\nAA', 'End\\r\\nAA', 'PEP\\r\\n2D', 'PEP\\r\\n1D', 'Score',\n",
      "       'Delta\\r\\nScore', 'Delta Mod.\\r\\nScore', 'Obs.\\r\\nm/z', 'Calc.\\r\\nm/z',\n",
      "       'ppm', 'Off-\\r\\nBy-X', 'Obs.M', 'Calc.M',\n",
      "       'Delta R.T. Obs-\\r\\nDelta R.T. Prd.', 'Scan Time(s)\\r\\n(Posit)',\n",
      "       'Glycans', 'MS\\r\\nId', '_prot_id', 'Apex Int.\\r\\n(Posit)',\n",
      "       'Scan Number(s)\\r\\n(Posit)', 'Obs. time\\r\\nVar (min)',\n",
      "       'Obs. time\\r\\nWild (min)', 'XIC\\r\\nStart', 'XIC\\r\\nEnd',\n",
      "       'MS2 Search\\r\\nAlias name', 'MS2 Search\\r\\nFilename', 'MS\\r\\nFilename',\n",
      "       'Quant\\r\\nlevel', 'Digest\\r\\nname', 'Digest\\r\\nStart Peptide',\n",
      "       'Digest\\r\\nEnd Peptide', 'Digest\\r\\nN-term ragged',\n",
      "       'Digest\\r\\nC-term ragged', 'Digest\\r\\nMissed Cleavages',\n",
      "       'Byonic Comment', 'Protein\\r\\nalias name', 'Fragment\\r\\ntype(s)',\n",
      "       'In silico', 'Sample\\r\\ntype', 'Protein molecular\\r\\nweight',\n",
      "       'Protein isoelectric\\r\\npoint', 'Total XIC AUC\\r\\nAveragine',\n",
      "       'MS1\\r\\ncorrelation', 'XIC\\r\\ncorrelation', 'FWHM',\n",
      "       'Protein\\r\\nannotation', 'XIC\\r\\nproposals', 'Center of m/z',\n",
      "       'Scan info', 'Protein\\r\\noccurrence(s)', 'Fixed Mod.\\r\\nSummary',\n",
      "       'MS/MS Query', 'Isotope Query', 'Mobility Start', 'Mobility End',\n",
      "       'Glycan\\r\\nstructure', 'MS1 isotope\\r\\nenvelope confidence'],\n",
      "      dtype='object')\n",
      "\n",
      "Extracted byos columns:\n",
      "Index(['Scan Number(s)\\r\\n(Posit)', 'Glycans', 'MS2 Search\\r\\nAlias name',\n",
      "       'XIC area\\r\\nsummed', 'XIC\\r\\nAUC', 'Apex Int.\\r\\n(Posit)', 'Calc.M',\n",
      "       'Calc.MH', 'Sequence'],\n",
      "      dtype='object')\n",
      "\n",
      "----- Byos data preprocessing completed. -----\n",
      "\n",
      "----- Start combining Byonic & Byos. -----\n",
      "\n",
      "\n",
      "Combined data shape:\n",
      "row --> 409, column --> 50\n",
      "\n",
      "----- Exporting \"_All\" file... This may take some time, please wait. -----\n",
      "\n",
      "<Color Summary>\n",
      "219 rows will be colored light green (#ccffcc).\n",
      "0 rows will be colored green (#99ff99).\n",
      "2 rows will be colored light pink (#ffb6c1).\n",
      "0 rows will be colored deep pink (#ff1493).\n",
      "407 rows will be colored yellow (#ffff66).\n",
      "190 rows will be colorless in byonic & pglyco data.\n",
      "0 rows will be colorless in byos data (absent data in certain scans).\n",
      "\n",
      "----- \"_All\" file exported. -----\n",
      "\n",
      "----- Start preparing simplified version. -----\n",
      "\n",
      "Done sorting by z[Byonic] --> Done sorting by Calc.MH[Byonic] --> Done sorting by PepMS[Byonic] --> Done sorting by rounded_FinalGlycans[Byonic] --> Done sorting by PureSequence[Byonic] --> \n",
      "----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\n",
      "\n",
      "<Color Summary>\n",
      "78 rows will be colored light green (#ccffcc).\n",
      "0 rows will be colored green (#99ff99).\n",
      "0 rows will be colored light pink (#ffb6c1).\n",
      "0 rows will be colored deep pink (#ff1493).\n",
      "78 rows will be colored yellow (#ffff66).\n",
      "0 rows will be colorless in byonic & pglyco data.\n",
      "0 rows will be colorless in byos data (absent data in certain scans).\n",
      "\n",
      "----- \"_UniquePep\" file exported. -----\n",
      "\n",
      "Done sorting by z[Byonic] --> Done sorting by Calc.MH[Byonic] --> Done sorting by PepMS[Byonic] --> Done sorting by rounded_FinalGlycans[Byonic] --> Done sorting by PureSequence[Byonic] --> \n",
      "----- Exporting \"_NglycoPep\" file... This may take some time, please wait. -----\n",
      "\n",
      "<Color Summary>\n",
      "1 rows will be colored light green (#ccffcc).\n",
      "0 rows will be colored green (#99ff99).\n",
      "0 rows will be colored light pink (#ffb6c1).\n",
      "0 rows will be colored deep pink (#ff1493).\n",
      "1 rows will be colored yellow (#ffff66).\n",
      "0 rows will be colorless in byonic & pglyco data.\n",
      "0 rows will be colorless in byos data (absent data in certain scans).\n",
      "\n",
      "----- \"_NglycoPep\" file exported. -----\n",
      "\n",
      "----- Start preparing quantification file of N-glycosylation . -----\n",
      "\n",
      "----- Start summary table construction. -----\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4350\u001b[0m\n\u001b[1;32m   4347\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll tasks completed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExecution time: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[1;32m   4349\u001b[0m \u001b[38;5;66;03m# RUN PROCESSING\u001b[39;00m\n\u001b[0;32m-> 4350\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 4076\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m   4074\u001b[0m         onlyb_gp\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m onlyb_gp\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mswaplevel(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4075\u001b[0m         \u001b[38;5;66;03m# sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\u001b[39;00m\n\u001b[0;32m-> 4076\u001b[0m         \u001b[43monlyb_gp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4077\u001b[0m         onlyb_gp\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m onlyb_gp\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mset_names([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN-site(SequonBased)[Byonic] →\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuant. →\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m   4078\u001b[0m         \u001b[38;5;66;03m# delete a-h in Quant. (the alphabet is just for sorting)\u001b[39;00m\n\u001b[1;32m   4079\u001b[0m \u001b[38;5;66;03m#         onlyb_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'sum_XIC\\r\\nAUC[Byos]', 'sum_Apex Int.\\r\\n(Posit)[Byos]'], level = 1, inplace=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/MS/lib/python3.8/site-packages/pandas/core/frame.py:6950\u001b[0m, in \u001b[0;36mDataFrame.sort_index\u001b[0;34m(self, axis, level, ascending, inplace, kind, na_position, sort_remaining, ignore_index, key)\u001b[0m\n\u001b[1;32m   6851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msort_index\u001b[39m(\n\u001b[1;32m   6852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6853\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6862\u001b[0m     key: IndexKeyFunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   6863\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6865\u001b[0m \u001b[38;5;124;03m    Sort object by labels (along an axis).\u001b[39;00m\n\u001b[1;32m   6866\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6948\u001b[0m \u001b[38;5;124;03m    d  4\u001b[39;00m\n\u001b[1;32m   6949\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6951\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6954\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6957\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort_remaining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_remaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6960\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MS/lib/python3.8/site-packages/pandas/core/generic.py:5072\u001b[0m, in \u001b[0;36mNDFrame.sort_index\u001b[0;34m(self, axis, level, ascending, inplace, kind, na_position, sort_remaining, ignore_index, key)\u001b[0m\n\u001b[1;32m   5068\u001b[0m ascending \u001b[38;5;241m=\u001b[39m validate_ascending(ascending)\n\u001b[1;32m   5070\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m-> 5072\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mget_indexer_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_remaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\n\u001b[1;32m   5074\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5076\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5077\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "File \u001b[0;32m~/miniconda3/envs/MS/lib/python3.8/site-packages/pandas/core/sorting.py:85\u001b[0m, in \u001b[0;36mget_indexer_indexer\u001b[0;34m(target, level, ascending, kind, na_position, sort_remaining, key)\u001b[0m\n\u001b[1;32m     82\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39m_sort_levels_monotonic()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     _, indexer \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msortlevel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_remaining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_remaining\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, ABCMultiIndex):\n\u001b[1;32m     89\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m lexsort_indexer(\n\u001b[1;32m     90\u001b[0m         target\u001b[38;5;241m.\u001b[39m_get_codes_for_sorting(), orders\u001b[38;5;241m=\u001b[39mascending, na_position\u001b[38;5;241m=\u001b[39mna_position\n\u001b[1;32m     91\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/MS/lib/python3.8/site-packages/pandas/core/indexes/multi.py:2455\u001b[0m, in \u001b[0;36mMultiIndex.sortlevel\u001b[0;34m(self, level, ascending, sort_remaining)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[38;5;66;03m# Reverse sorted to retain the order of\u001b[39;00m\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;66;03m# smaller indices that needs to be removed\u001b[39;00m\n\u001b[1;32m   2454\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lev \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(level, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 2455\u001b[0m     \u001b[43mcodes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2456\u001b[0m     shape\u001b[38;5;241m.\u001b[39mpop(lev)\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort_remaining:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop index out of range"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import ticker\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from IPython.display import display, HTML\n",
    "import regex as re # finding specific patterns in str\n",
    "import textwrap # split text into equal parts\n",
    "import collections # return repeated items in list\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from datetime import datetime # attach current date to export filename\n",
    "import sys\n",
    "import ast # convert str back to tuple/list/int, etc\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import string\n",
    "\n",
    "## INPUT EXCEL FILES\n",
    "byonicfile = '20241218_expi-jn1-rbd_Byonic_inSol_TC-byonic' # Please paste filename here. if None, please leave it as empty string '' (NOTE: DO NOT INCLUDE .XLSX HERE)\n",
    "byosfile = '20241218_expi-JN1_Byologic_inSol_TC' # Please paste filename here. if None, please leave it as empty string '' (NOTE: DO NOT INCLUDE .XLSX HERE)\n",
    "pglycofile = '' # Please paste filename here. if None, please leave it as empty string '' (NOTE: DO NOT INCLUDE .XLSX HERE)\n",
    "\n",
    "## INPUT TARGET PROTEIN SEQUENCE FOR MAJOR GLYCOFORM TABLE (PGLYCO SITES MAY BE WRONG, THE SEQ HERE CAN ALSO HELP COMPUTER DETECT THE WRONG SITES)\n",
    "seq = 'MFVFLVLLPLVSSQRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFHHHHHH'\n",
    "\n",
    "# ntu156_seq = 'ANSDCVQVNVTQLPGNENIIKDFLFSNFKEEGTVVVGGYYPTEVWYNCSRTATTTAYEYFSNIHAFYFDMEAMENSTGNARGKPLLFHVHGEPVSVIIYISAYRDDVQQRPLLKHGLVCITESRNIDYNQFTSNQWNSICTGNDRKIPFSVIPTDNGTKIYGLEWNDESVTAYISGHSYSLNINTNWFNNVTLLYSRSSTATWQKSAAYVYQGVSNFTYYKLNNTNGLKTYELCENYEYCTGHATNVFAPIAGGYIPDGFSFNNWFLLTNSSTFVSGRFVTNQPLLVNCLWPVPSFGVAAQEFCFEGAQFSQCNGVSLNNTVDVIRFNLNLTADVQSGMGATVFSLNTTGGVILEISCYNDTVSESSFYSYGEIPFGVTDGPRYCYVLYNGTALKYLGTLPPSVKEIAISKWGHFYINGYNFFSTFPIDCISFNLTTGASGAFWTIAYTSYTEALVQVENTAIKKVTYCNSHINNIKCSQLTANLQNGFYPVASSDVGLVNKSVVLLPIFFAHTAVNITIDLGMKRSGYGQPIASTLSNITLPMQDNNTDVYCVRSNQFSVYTHSTCKSSLWDNNFNQDCTDVLYATAVIKTGTCPFSFDKLNNYLTFNKLCLSLNPTGANCKFDVAARTRTNEQVVRSLYVIYEEGDNIVGVPSDNSGPHDLSVLHLDSCTDYNIYGRTGVGIIRQTNSTILSGLYYTSLSGDLLGFKNVSDGVVYSVTPCDVSAQAAVIDGAIVGAMTSINSELLGLTHWTTTPNFYYYSIYNYTNERTRGTAIDSNAVDCEPIITYSNIGVCKNGALVFINVTHSDGDVQPISTGNVTIPTNFTISVQVEYIQVYTTPVSIDCSRYVCNGNPRCNKLLTQYVSACQTIEQALAMSARLENMEVDSMLFVSENALKLASVEAFNSTEHLDPIYKEWPNIGGSWLGGLKDILPSHNSKRKYRSAIEDLLFDKVVTSGLGTVDEDYKRCTGGYDIADLVCAQYYNGIMVLPGVANDDKMTMYTASLAGGITLGALGGGAVAIPFAVAVQARLNYVALQTDVLNKNQQILANAFNQAIGNITQAFGKVNDAIHQTSQGLATVAKALVKVQDVVNTQGQALSHLTVQLQNNFQAISSSISDIYNRLDPPSADAQVDRLITGRLTALNAFVSQTLTRQAEVRASRQLAKDKVNECVRSQSQRFGFCGNGTHLFSLANAAPNGMIFFHTVLLPTAYETVTAWSGICASDGDRTFGLVVKDVQLTLFRNLDDKFYLTPRTMYQPRAATSSDFVQIEGCDVLFVNATVIDLPSIIPDYIDINQTVQDILENYRPNWTVPELTLDIFNATYLNLTGEIDDLEFRSEKLHNTTVELAILIDNINNTLVNLEWLNRIETYVKWPGYIPEAPRDGQAYVRKDGEWVLLSTFLGGRSSLEGPRFEGKPIPNPLLGLDSTRTGHHHHHH'\n",
    "\n",
    "# uu4_seq = 'DAPHGVTLPHFNTSHNNSKFELNFYNFLQTWDIPPNTETILGGYLPYCDHEDNCGWYNFVYNNKVGPNAKYSYINTQNLNIPNVHGVYFDVREHNSDGVWDQIDRVGLLIAIHGTSHYSLLMVLQDGVEASQPHVAVKICHWNPGNISTYHQFDVNLGDGGQCVFNQRFSLDTVLTANDFYGFQWTDTYVDIYLGGTITKVWVVNDWSVVEASISSHWNALNYGYYIQFVNRTTYYAYNSTGGSNYTHLQLTECHTDYCAGYAKNVFVPIDGKIPEGFSFSNWFLLTDKSTLVQGRVLSSQPVFVQCLRPVPTWSNNTAVVHFKNDVFCPNVTADVLRFNLNFSDTDVYTDSTTDDQLHFTFEDNTTASITCYSSANVTDNQPASGSISHTPFVSNSYLCFANFSHSSVSRQFLGILPPTVREFAFGRDGSIFVNGYKYFSLQPIKSVNFSISSVENYGFWTIAYTNYTDVMVDVNGTVITRLFYCDSPLNRIKCQQLKHELPDGFYSASMLVKKDLPKTFVTMPQFYNWMNVTLHVVLNDIEKKADIILAGAPELASLADIHFEIAQANGSVVNVTSVCVQARQLALFYKYTSLQGLYTYSNLVQLQNYDCPFSPQQFNNYLQFETLCFDVSPAVAGCKWSLVHDVKWRTQFATITVSYKDGAMITTMPKAQLGFQDISNIVKDECTDYNIYGFQGTGIIRSTTSRLVAGLYYTSASGDLLGFKISTTGEIFTVVPCDLTAQAAVINDEIVGAITATNQTDLFEFVNHTWSRSARGSSPSTVNTYTMPQFYYITKWNNGTSSNCTSVITYSSFAICNTGEIKYVNVTHVEIVDDSVGVIKPVSTGNITIPKNFTVAVQAEYVQIQVKPVAVDCAKYVCNGNRHCLNLLTQYTSACQTIENSLNLGARLESLMLNDMITVSDRSLEFATVDKFNTTALGGEKLGGLYFDGLSSLLPPRVGMRSAVEDLLFNKVVTSGLGTVDDDYKKCSAGTDVADLVCAQYYNGIMVLPGVVDYNKMAMYTASLIGGMALGSITSAVAVPFSMQVQARLNYVALQTDVLQENQKILANAFNNAIGNITLALGKVSNAITTVSDGFNSMASALTKIQSVVNQQGEALSHLISQLQKNFQAISSSIAEIYNRLEKVEADAQVDRLITGRLAALNAYVAQTLTQYAEVKASRQLAMEKVNECVKSQSDRYGFCGNGTHLFSLVNSAPDGLLFFHTVLLPTEWEEVTAWSGICVNDTYAYLLKDFDHSIFSYNGTYMVTPRNMFQPRKPQMSDFVQITSCEVTFLNTTHTTFQEIVIDYIDINKTIADMLEQYHSNYTTPELDLQLEIFNQTKLNLTAEIDQLEQRADNLTNIAHELQQYIDNLNKTIVDLEWLNRIETYVKWPGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGGRSSLEGPRFEGKPIPNPLLGLDSTRTGHHHHHH'\n",
    "\n",
    "# fm2p seq\n",
    "# seq = 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPGSASSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQ'\n",
    "\n",
    "# omicron seq\n",
    "# seq = 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHVISGTNGTKRFDNPVLPFNDGVYFASIEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLDHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPIIVREPEDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNLAPFFTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKVSGNYNYLYRLFRKSNLKPFERDISTEIYQAGNKPCNGVAGFNCYFPLRSYSFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLKGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEYVNNSYECDIPIGAGICASYQTQTKSHGSASSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLKRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKYFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFKGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNHNAQALNTLVKQLSSKFGAISSVLNDIFSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# uu4 seq\n",
    "# seq = 'MDAMKRGLCCVLLLCGAVFVSPSASDAPHGVTLPHFNTSHNNSKFELNFYNFLQTWDIPPNTETILGGYLPYCDHEDNCGWYNFVYNNKVGPNAKYSYINTQNLNIPNVHGVYFDVREHNSDGVWDQIDRVGLLIAIHGTSHYSLLMVLQDGVEASQPHVAVKICHWNPGNISTYHQFDVNLGDGGQCVFNQRFSLDTVLTANDFYGFQWTDTYVDIYLGGTITKVWVVNDWSVVEASISSHWNALNYGYYIQFVNRTTYYAYNSTGGSNYTHLQLTECHTDYCAGYAKNVFVPIDGKIPEGFSFSNWFLLTDKSTLVQGRVLSSQPVFVQCLRPVPTWSNNTAVVHFKNDVFCPNVTADVLRFNLNFSDTDVYTDSTTDDQLHFTFEDNTTASITCYSSANVTDNQPASGSISHTPFVSNSYLCFANFSHSSVSRQFLGILPPTVREFAFGRDGSIFVNGYKYFSLQPIKSVNFSISSVENYGFWTIAYTNYTDVMVDVNGTVITRLFYCDSPLNRIKCQQLKHELPDGFYSASMLVKKDLPKTFVTMPQFYNWMNVTLHVVLNDIEKKADIILAGAPELASLADIHFEIAQANGSVVNVTSVCVQARQLALFYKYTSLQGLYTYSNLVQLQNYDCPFSPQQFNNYLQFETLCFDVSPAVAGCKWSLVHDVKWRTQFATITVSYKDGAMITTMPKAQLGFQDISNIVKDECTDYNIYGFQGTGIIRSTTSRLVAGLYYTSASGDLLGFKISTTGEIFTVVPCDLTAQAAVINDEIVGAITATNQTDLFEFVNHTWSRSARGSSPSTVNTYTMPQFYYITKWNNGTSSNCTSVITYSSFAICNTGEIKYVNVTHVEIVDDSVGVIKPVSTGNITIPKNFTVAVQAEYVQIQVKPVAVDCAKYVCNGNRHCLNLLTQYTSACQTIENSLNLGARLESLMLNDMITVSDRSLEFATVDKFNTTALGGEKLGGLYFDGLSSLLPPRVGMRSAVEDLLFNKVVTSGLGTVDDDYKKCSAGTDVADLVCAQYYNGIMVLPGVVDYNKMAMYTASLIGGMALGSITSAVAVPFSMQVQARLNYVALQTDVLQENQKILANAFNNAIGNITLALGKVSNAITTVSDGFNSMASALTKIQSVVNQQGEALSHLISQLQKNFQAISSSIAEIYNRLEKVEADAQVDRLITGRLAALNAYVAQTLTQYAEVKASRQLAMEKVNECVKSQSDRYGFCGNGTHLFSLVNSAPDGLLFFHTVLLPTEWEEVTAWSGICVNDTYAYLLKDFDHSIFSYNGTYMVTPRNMFQPRKPQMSDFVQITSCEVTFLNTTHTTFQEIVIDYIDINKTIADMLEQYHSNYTTPELDLQLEIFNQTKLNLTAEIDQLEQRADNLTNIAHELQQYIDNLNKTIVDLEWLNRIETYVKWPGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGGRSSLEGPRFEGKPIPNPLLGLDSTRTGHHHHHH' # Please paste the pure aa. seq into '' (case insensitive)\n",
    "\n",
    "# P1 (Gamma) seq\n",
    "# seq = 'MFVFLVLLPLVSSQCVNFTNRTQLPSAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNYPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLSEFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGTIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVKGFNCYFPLQSYGFQPTYGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEYVNNSYECDIPIGAGICASYQTQTNSPGSASSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAAIKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# SA (Beta) seq\n",
    "# seq = 'MFVFLVLLPLVSSQCVNFTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFANPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRGLPQGFSALEPLVDLPIGINITRFQTLHISYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVKGFNCYFPLQSYGFQPTYGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPGSASSVASQSIIAYTMSLGVENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# KAPPA\n",
    "# seq = 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLDVYYHKNNKSWMKSEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSTPCNGVQGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPGSASSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAHEKNFTTAPAICHDGKAHFPREGVFVSNGTDWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# DELTA \n",
    "# seq = 'MFVFLVLLPLVSSQCVNLRTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLDVYYHKNNKSWMESGVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSRGSASSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQNVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# pedv ns seq\n",
    "# seq = 'MDAMKRGLCCVLLLCGAVFVSPSASQDVTRCSAKTNFRRFFSKFNVQAPAVVVLGGYLPIGENQGVNSTWYCAGQHPTASGVHGIFVSHIRGGHGFEIGISQEPFDPSGYQLYLHKATNGNTNATARLRICQFPSIKTLGPTANNDVTTGRNCLFNKAIPAHMSEHSVVGITWDNDRVTVFSDKIYYFYFKNDWSRVATKCYNSGGCAMQYVYEPTYYMLNVTSAGEDGISYQPCTANCIGYAANVFATEPNGHIPEGFSFNNWFLLSNDSTLVHGKVVSNQPLLVNCLLAIPKIYGLGQFFSFNQTIDGVCNGAAVQRAPEALRFNINDTSVILAEGSIVLHTALGTNFSFVCSNSSNPHLATFAIPLGATQVPYYCFLKVDTYNSTVYKFLAVLPPTVREIVITKYGDVYVNGFGYLHLGLLDAVTINFTGHGTDDDVSGFWTIASTNFVDALIEVQGTAIQRILYCDDPVSQLKCSQVAFDLDDGFYPISSRNLLSHEQPISFVTLPSFNDHSFVNITVSASFGGHSGANLIASDTTINGFSSFCVDTRQFTISLFYNVTNSYGYVSNSQDSNCPFTLQSVNDYLSFSKFCVSTSLLASACTIDLFGYPEFGSGVKFTSLYFQFTKGELITGTPKPLEGVTDVSFMTLDVCTKYTIYGFKGEGIITLTNSSFLAGVYYTSDSGQLLPFKNVTSGAVYSVTPCSFSEQAAYVDDDIVGVISSLSSSTFNSTRELPGFFYHSNDGSNCTEPVLVYSNIGVCKSGSIGYVPSQSGQVKIAPTVTENISIPTNFSMSIKTEYLQLYNTPVSVDCATYVCNGNSRCKQLLTQYTAACKTIESALQLSARLESVEVNSMLTISEEALQLATISSFNGDGYNFTNVLGVSVYDPASGRVVQKRSFIEDLLFNKVVTNGLGTVDEDYKRCSNGRSVADLVCAQYYSGVMVLPGVVDAEKLHMYSASLIGGMVLGGFTSAAALPFSYAVQARLNYLALQTDVLQRNQQLLAESFNSAIGNITSAFESVKEAISQTSKGLNTVAHALTKVQEVVNSQGAALTQLTVQLQHNFQAISSSIDDIYSRLDILSADVQVDRLITGRLSALNAFVAQTLTKYTEVQASRKLAQQKVNECVKSQSQRYGFCGGDGEHIFSLVQAAPQGLLFLHTVLVPSDFVDVIAIAGLCVNDEIALTLREPGLVLFTHELQNHTATEYFVSSRRMFEPRKPTVSDFVQIESCVVTYVNLTRDQLPDVIPDYIDVNKTLDEILASLPNRTGPSLPLDVFNATYLNLTGEIADLEQRSESLRNTTEELQSLIYNINNTLVDLEWLNRVETYIKWP'\n",
    "\n",
    "# pedv ns 2\n",
    "# seq = 'MKSLTYFWLFLPVLSTLSLPQDVTRCSAKTNFRRFFSKFNVQAPAVVVLGGYLPIGENQGVNSTWYCAGQHPTASGVHGIFVSHIRGGHGFEIGISQEPFDPSGYQLYLHKATNGNTNATARLRICQFPSIKTLGPTANNDVTIGRNCLFNKAIPAHMSEHSVVGITWDNDRVTVFSDKIYYFYFKNDWSRVATKCYNSGGCAMQYVYEPTYYMLNVTSAGEDGISYQPCTANCIGYAANVFATEPNGHIPEGFSFNNWFLLSNDSTLVHGKVVSNQPLLVNCLLAIPKIYGLGQFFSFNQTIDGVCNGAAVQRAPEALRFNINDTSVILAEGSIVLHTALGTNFSFVCSNSSNPHLATFAIPLGATQVPYYCFFKVDTYNSTVYKFLAVLPPTVREIVITKYGDVYVNGFGYLHLGLLDAVTINFTGHGTDDDVSGFWTIASTNFVDALIEVQGTAIQRILYCDDPVSQLKCSQVAFDLDDGFYPFSSRNLLSHEQPISFVTLPSFNAHSFVNITVSASFGGHSGANLIASDTTINGFSSFCVDTRQFTISLSYNVTNSYGYVSNSQDSNCPFTLQSVNDYLSFSKFCVSTSLLASACTIDLFGYPEFGSGVKFTSLYFQFTKGELITGTPKPLEGVTDVSFMTLDVCTKYTIYGFKGEGIITLTNSSFLAGVYYTSDSGQLLAFKNVTSGAVYSVTPCSFSEQAAYVDDDIVGVISSLSSSTFNSTRELPGFFYHSNDGSNCTEPVLVYSNIGVCKSGSIGYVPSQSGQVKIAPTVTGNISIPTNFSMSIRTEYLQLYNTPVSVDCATYVCNGNSRCKQLLTQYTAACKTIESALQLSARLESVEVNSMLTISEEALQLATISSFNGDGYNFTNVLGVSVYDPARGRVVQKRSFIEDLLFNKVVTNGLGTVDEDYKRCSNGRSVADLVCAQYYSGVMVLPGVVDAEKLHMYSASLIGGMVLGGFTAAAALPFSYAVQARLNYLALQTDVLQRNQQLLAESFNSAIGNITSAFESVKEASSQTSRGLNTVAHALTKVQEVVNSQGAALTQLTVQLQHNFQAISSSIDDIYSRLDILSADVQVDRLITGRLSALNAFVAQTLTKYTEVQASRKLAQQKVNECVKSQSQRYGFCGGDGEHIFSLVQAAPQGLLFLHTVLVPSDFVDVIAIAGLCVNDEIALTLREPGLVLFTHELQNHTATEYFVSSRRMFEPRKPTVSDFVQIESCVVTYVNLTRDQLPDVIPDYIDVNKTRDEILASLPNRTGPSLPLDVFNATYLNLTGEIADLEQRSESLRNTTEELQSLIYNINNTLVDLEWLNRVETYIKWPWWVWLIIFIVLIFVVSLLVFCCISTGFCGCFGCCCACFSGCCRGPRLQPYEVFEKVHVQ'\n",
    "\n",
    "# pedv os seq\n",
    "# seq = 'MDAMKRGLCCVLLLCGAVFVSPSASDVTRCQSTINFRRFFSKFNVQAPAVVVLGGYLPSMNSSSWYCGTGLETASGVHGIFLSYIDSGQGFEIGISQEPFDPSGYQLYLHKATNGNQDAIARLRICQFPNNKTLGPSVNDVTTGRNCLFNKAIPAYMQDGKNIIVGITWDNDRVTVFADKIYHFYLKNEWSRVATRCYNKRSCAMQYVYTPTYYMLNVTSAGEDGIYYSLCTANCIGYAVNVFATDSNGHIPEGFSFNNWFLLSNDSTLLHGKVVSNQPLLVNCLLAIPKIYGLGQFFSFNQTMDGACNGVAAQRAPEALRFNINDTSVILAEGSIVLHTALGTNLSFVCSNSSDPHLSTFAIPLGATQVPYYCFLKVDTYNSTVYKFLAVLPPTVREIVITKYGDVYVNGFGYLHLGLLDAVTINFTGHGTDDDVSGFWTIASTNFVDALIEVQGTAIERILYCDDPVSQLKCSQVAFDLDDGFYPISSRNLLSHEQPISFVTLPSFNDHSFVNITVSASFGGHSGANVIASDTTINGFSSFCVDTRQFTISLFYNVTNIYGYVSTSQGSNCPFTLQSVNDYLSFSKFCVSTSLLASACTIDLFGYPDFGSGVKLTSLYFQFTKGELITGTPKPLQGVTDVSFMTLDVCTKYTIYGFKGEGVITLTNSSFLAGVYYTSDSGQLLAFKNVTSGAVYSVTPCSFSEQAAYVDDDIVGVISSLSNSTFNSTRELPGFFYHSNDGSNCTEPVLVYSNIGVCKSGSIGYVPSQSGQVKIAPTVTGNISIPTNFSMSIRTEYLQLYNTPVSVDCATYVCNGNSRCKQLLTQYTAACKTIESALQLSARLESVEVNSMLTISEEALQLATVSSFNGDGYNFTNVLGVSVYDPASGRVVQKRSFIEDLLFNKVVTNGLGTVDEDYKRCSKGRSVADLVCAQYYSGVMVLPGVVDAEKLHMYSASLIGGMVLGGFTAAAALPFSYAVQARLNYLALQTDVLQRNQQLLAESFNSAIGNITSAFESVKEAISQTSKGLNTVAHALTKVQEVVNSQGAALTQLTVQLQHNFQAISSSIDDIYSRLDSLSADVQVDRLITGRLSALNAFVAQTLTKYTEVQASRKLAQQKVNECVKSQSQRYGFCGGDGEHIFSLVQAAPQGLLFLHTVLVPGDFVNVIAIAGLCVNDEIALTLREPGLVLFTHELQNYTATEYFVSSRRMFEPRKPTFSDFVQIESCVVTYVNLTRDQLPDVIPDYIDVNKTLDEILASLPNRTGPSLPLDVFNATYLNLTGEIADLEQRSESLRNTTEELQSLIYNINNTLVDLEWLNRVETYIKWPGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGGRSSLEGPRFEGKPIPNPLLGLDSTRTGHHHHHH'\n",
    "\n",
    "# pedv os mut seq\n",
    "# seq = 'DVTRCQSTINFRRFFSKFNVQAPAVVVLGGYLPSMNSSSWYCGTGLETASGVHGIFLSYIDSGQGFEIGISQEPFDPSGYQLYLHKATNGNQDAIARLRICQFPNNKTLGPSVNDVTTGRNCLFNKAIPAYMQDGKNIIVGITWDNDRVTVFADKIYHFYLKNEWSRVATRCYNKRSCAMQYVYTPTYYMLNVTSAGEDGIYYSLCTANCIGYAVNVFATDSNGHIPEGFSFNNWFLLSNDSTLLHGKVVSNQPLLVNCLLAIPKIYGLGQFFSFNQTMDGACNGVAAQRAPEALRFNINDTSVILAEGSIVLHTALGTNLSFVCSNSSDPHLSTFAIPLGATQVPYYCFLKVDTYNSTVYKFLAVLPPTVREIVITKYGDVYVNGFGYLHLGLLDAVTINFTGHGTDDDVSGFWTIASTNFVDALIEVQGTAIERILYCDDPVSQLKCSQVAFDLDDGFYPISSRNLLSHEQPISFVTLPSFNDHSFVNITVSASFGGHSGANVIASDTTINGFSSFCVDTRQFTISLFYNVTNIYGYVSTSQGSNCPFTLQSVNDYLSFSKFCVSTSLLASACTIDLFGYPDFGSGVKLTSLYFQFTKGELITGTPKPLQGVTDVSFMTLDVCTKYTIYGFKGEGVITLTNSSFLAGVYYTSDSGQLLAFKNVTSGAVYSVTPCSFSEQAAYVDDDIVGVISSLSSSTFNSTRELPGFFYHSNDGSNCTEPVLVYSNIGVCKSGSIGYVPSQSGQVKIAPTVTGNISIPTNFSMSIRTEYLQLYNTPVSVDCATYVCNGNSRCKQLLTQYTAACKTIESALQLSARLESVEVNSMLTISEEALQLATVSSFNGDGYNFTNVLGVSVYDPASGRVVQKRSFIEDLLFNKVVTNGLGTVDEDYKRCSKGRSVADLVCAQYYSGVMVLPGVVDAEKLHMYSASLIGGMVLGGFTAAAALPFSYAVQARLNYLALQTDVLQRNQQLLAESFNSAIGNITSAFESVKEAISQTSKGLNTVAHALTKVQEVVNSQGAALTQLTVQLQHNFQAISSSIDDIYSRLDSLSADVQVDRLITGRLSALNAFVAQTLTKYTEVQASRKLAQQKVNECVKSQSQRYGFCGGDGEHIFSLVQAAPQGLLFLHTVLVPGDFVNVIAIAGLCVNDEIALTLREPGLVLFTHELQNYTATEYFVSSRRMFEPRKPTFSDFVQIESCVVTYVNLTRDQLPDVIPDYIDVNKTLDEILASLPNRTGPSLPLDVFNATYLNLTGEIADLEQRSESLRNTTEELQSLIYNINNTLVDLEWLNRVETYIKWPGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# pedv pt52\n",
    "# seq = 'LPQDVTRCSAKTNFRRFFSKFNVQAPAVVVLGGYLPIGENQGVNSTWYCAGQHPTASGVHGIFVSHIRGGHGFEIGISQEPFDPSGYQLYLHKATNGNTNATARLRICQFPSIKTLGPTANNDVTIGRNCLFNKAIPAHMSEHSVVGITWDNDRVTVFSDKIYYFYFKNDWSRVATKCYNSGGCAMQYVYEPTYYMLNVTSAGEDGISYQPCTANCIGYAANVFATEPNGHIPEGFSFNNWFLLSNDSTLVHGKVVSNQPLLVNCLLAIPKIYGLGQFFSFNQTIDGVCNGAAVQRAPEALRFNINDTSVILAEGSIVLHTALGTNFSFVCSNSSNPHLATFAIPLGATQVPYYCFFKVDTYNSTVYKFLAVLPPTVREIVITKYGDVYVNGFGYLHLGLLDAVTINFTGHGTDDDVSGFWTIASTNFVDALIEVQGTAIQRILYCDDPVSQLKCSQVAFDLDDGFYPFSSRNLLSHEQPISFVTLPSFNAHSFVNITVSASFGGHSGANLIASDTTINGFSSFCVDTRQFTISLSYNVTNSYGYVSNSQDSNCPFTLQSVNDYLSFSKFCVSTSLLASACTIDLFGYPEFGSGVKFTSLYFQFTKGELITGTPKPLEGVTDVSFMTLDVCTKYTIYGFKGEGIITLTNSSFLAGVYYTSDSGQLLAFKNVTSGAVYSVTPCSFSEQAAYVDDDIVGVISSLSSSTFNSTRELPGFFYHSNDGSNCTEPVLVYSNIGVCKSGSIGYVPSQSGQVKIAPTVTGNISIPTNFSMSIRTEYLQLYNTPVSVDCATYVCNGNSRCKQLLTQYTAACKTIESALQLSARLESVEVNSMLTISEEALQLATISSFNGDGYNFTNVLGVSVYDPARGRVVQKRSFIEDLLFNKVVTNGLGTVDEDYKRCSNGRSVADLVCAQYYSGVMVLPGVVDAEKLHMYSASLIGGMVLGGFTAAAALPFSYAVQARLNYLALQTDVLQRNQQLLAESFNSAIGNITSAFESVKEASSQTSRGLNTVAHALTKVQEVVNSQGAALTQLTVQLQHNFQAISSSIDDIYSRLDPPSADVQVDRLITGRLSALNAFVAQTLTKYTEVQASRKLAQQKVNECVKSQSQRYGFCGGDGEHIFSLVQAAPQGLLFLHTVLVPSDFVDVIAIAGLCVNDEIALTLREPGLVLFTHELQNHTATEYFVSSRRMFEPRKPTVSDFVQIESCVVTYVNLTRDQLPDVIPDYIDVNKTRDEILASLPNRTGPSLPLDVFNATYLNLTGEIADLEQRSESLRNTTEELQSLIYNINNTLVDLEWLNRVETYIKWPEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# MERS_S_fm2P_inHouse\n",
    "# seq = 'MDSWFILVLLGSGLICVSASYVDVGPDSVKSACIEVDIQQTFFDKTWPRPIDVSKADGIIYPQGRTYSNITITYQGLFPYQGDHGDMYVYSAGHATGTTPQKLFVANYSQDVKQFANGFVVRIGAAANSTGTVIISPSTSATIRKIYPAFMLGSSVGNFSDGKMGRFFNHTLVLLPDGCGTLLRAFYCILEPRSGNHCPAGNSYTSFATYHTPATDCSDGNYNRNASLNSFKEYFNLRNCTFMYTYNITEDEILEWFGITQTAQGVHLFSSRYVDLYGGNMFQFATLPVYDTIKYYSIIPHSIRSIQSDRKAWAAFYVYKLQPLTFLLDFSVDGYIRRAIDCGFNDLSQLHCSYESFDVESGVYSVSSFEAKPSGSVVEQAEGVECDFSPLLSGTPPQVYNFKRLVFTNCNYNLTKLLSLFSVNDFTCSQISPAAIASNCYSSLILDYFSYPLSMKSDLSVSSAGPISQFNYKQSFSNPTCLILATVPHNLTTITKPLKYSYINKCSRLLSDDRTEVPQLVNANQYSPCVSIVPSTVWEDGDYYRKQLSPLEGGGWLVASGSTVAMTEQLQMGFGITVQYGTDTNSVCPKLEFANDTKIASQLGNCVEYSLYGVSGRGVFQNCTAVGVRQQRFVYDAYQNLVGYYSDDGNYYCLRACVSVPVSVIYDKETKTHATLFGSVACEHISSTMSQYSRSTRSMLKRRDSTYGPLQTPVGCVLGLVNSSLFVEDCKLPLGQSLCALPDTPSTLTPASVGSVPGEMRLASIAFNHPIQVDQLNSSYFKLSIPTNFSFGVTQEYIQTTIQKVTVDCKQYVCNGFQKCEQLLREYGQFCSKINQALHGANLRQDDSVRNLFASVKSSQSSPIIPGFGGDFNLTLLEPVSISTGSRSARSAIEDLLFDKVTIADPGYMQGYDDCMQQGPASARDLICAQYVAGYKVLPPLMDVNMEAAYTSSLLGSIAGVGWTAGLSSFAAIPFAQSIFYRLNGVGITQQVLSENQKLIANKFNQALGAMQTGFTTTNEAFQKVQDAVNNNAQALSKLASELSNTFGAISASIGDIIQRLDPPEQDAQIDRLINGRLTTLNAFVAQQLVRSESAALSAQLAKDKVNECVKAQSKRSGFCGQGTHIVSFVVNAPNGLYFMHVGYYPSNHIEVVSAYGLCDAANPTNCIAPVNGYFIKTNNTRIVDEWSYTGSSFYAPEPITSLNTKYVAPQVTYQNISTNLPPPLLGNSTGIDFQDELDEFFKNVSTSIPNFGSLTQINTTLLDLTYEMLSLQQVVKALNESYIDLKELGNYTYEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# SARS_S_2P_inHouse \n",
    "# seq = 'MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEIFRSDTLYLTQDLFLPFYSNVTGFHTINHTFDNPVIPFKDGIYFAATEKSNVVRGWVFGSTMNNKSQSVIIINNSTNVVIRACNFELCDNPFFAVSKPMGTQTHTMIFDNAFNCTFEYISDAFSLDVSEKSGNFKHLREFVFKNKDGFLYVYKGYQPIDVVRDLPSGFNTLKPIFKLPLGINITNFRAILTAFSPAQDTWGTSAAAYFVGYLKPTTFMLKYDENGTITDAVDCSQNPLAELKCSVKSFEIDKGIYQTSNFRVVPSGDVVRFPNITNLCPFGEVFNATKFPSVYAWERKKISNCVADYSVLYNSTFFSTFKCYGVSATKLNDLCFSNVYADSFVVKGDDVRQIAPGQTGVIADYNYKLPDDFMGCVLAWNTRNIDATSTGNYNYKYRYLRHGKLRPFERDISNVPFSPDGKPCTPPALNCYWPLNDYGFYTTTGIGYQPYRVVVLSFELLNAPATVCGPKLSTDLIKNQCVNFNFNGLTGTGVLTPSSKRFQPFQQFGRDVSDFTDSVRDPKTSEILDISPCSFGGVSVITPGTNASSEVAVLYQDVNCTDVSTAIHADQLTPAWRIYSTGNNVFQTQAGCLIGAEHVDTSYECDIPIGAGICASYHTVSLLRSTSQKSIVAYTMSLGADSSIAYSNNTIAIPTNFSISITTEVMPVSMAKTSVDCNMYICGDSTECANLLLQYGSFCTQLNRALSGIAAEQDRNTREVFAQVKQMYKTPTLKYFGGFNFSQILPDPLKPTKRSFIEDLLFNKVTLADAGFMKQYGECLGDINARDLICAQKFNGLTVLPPLLTDDMIAAYTAALVSGTATAGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKQIANQFNKAISQIQESLTTTSTALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQAAPHGVVFLHVTYVPSQERNFTTAPAICHEGKAYFPREGVFVFNGTSWFITQRNFFSPQIITTDNTFVSGNCDVVIGIINNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# HKU1\n",
    "# seq = 'MFLIIFILPTTLAVIGDFNCTNSFINDYNKTIPRISEDVVDVSLGLGTYYVLNRVYLNTTLLFTGYFPKSGANFRDLALKGSIYLSTLWYKPPFLSDFNNGIFSKVKNTKLYVNNTLYSEFSTIVIGSVFVNTSYTIVVQPHNGILEITACQYTMCEYPHTVCKSKGSIRNESWHIDSSEPLCLFKKNFTYNVSADWLYFHFYQERGVFYAYYADVGMPTTFLFSLYLGTILSHYYVMPLTCNAISSNTDNETLEYWVTPLSRRQYLLNFDEHGVITNAVDCSSSFLSEIQCKTQSFAPNTGVYDLSGFTVKPVATVYRRIPNLPDCDIDNWLNNVSVPSPLNWERRIFSNCNFNLSTLLRLVHVDSFSCNNLDKSKIFGSCFNSITVDKFAIPNRRRDDLQLGSSGFLQSSNYKIDISSSSCQLYYSLPLVNVTINNFNPSSWNRRYGFGSFNLSSYDVVYSDHCFSVNSDFCPCADPSVVNSCAKSKPPSAICPAGTKYRHCDLDTTLYVKNWCRCSCLPDPISTYSPNTCPQKKVVVGIGEHCPGLGINEEKCGTQLNHSSCFCSPDAFLGWSFDSCISNNRCNIFSNFIFNGINSGTTCSNDLLYSNTEISTGVCVNYDLYGITGQGIFKEVSAAYYNNWQNLLYDSNGNIIGFKDFLTNKTYTILPCYSGRVSAAFYQNSSSPALLYRNLKCSYVLNNISFISQPFYFDSYLGCVLNAVNLTSYSVSSCDLRMGSGFCIDYALPSSGGSGSGISSPYRFVTFEPFNVSFVNDSVETVGGLFEIQIPTNFTIAGHEEFIQTSSPKVTIDCSAFVCSNYAACHDLLSEYGTFCDNINSILNEVNDLLDITQLQVANALMQGVTLSSNLNTNLHSDVDNIDFKSLLGCLGSQCGSSSRSLLEDLLFNKVKLSDVGFVEAYNNCTGGSEIRDLLCVQSFNGIKVLPPILSETQISGYTTAATVAAMFPPWSAAAGVPFSLNVQYRINGLGVTMDVLNKNQKLIANAFNKALLSIQNGFTATNSALAKIQSVVNANAQALNSLLQQLFNKFGAISSSLQEILSRLDPPEAQVQIDRLINGRLTALNAYVSQQLSDITLIKAGASRAIEKVNECVKSQSPRINFCGNGNHILSLVQNAPYGLLFIHFSYKPTSFKTVLVSPGLCLSGDRGIAPKQGYFIKQNDSWMFTGSSYYYPEPISDKNVVFMNSCSVNFTKAPFIYLNNSIPNLSDFEAELSLWFKNHTSIAPNLTFNSHINATFLDLYYEMNVIQESIKSLNEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# OC43\n",
    "# seq = 'MGILPSPGMPALLSLVSLLSVLLMGCVAETGTVIGDLKCTSDNINDKDTGPPPISTDTVDVTNGLGTYYVLDRVYLNTTLFLNGYYPTSGSTYRNMALKGSVLLSRLWFKPPFLSDFINGIFAKVKNTKVIKDRVMYSEFPAITIGSTFVNTSYSVVVQPRTINSTQDGDNKLQGLLEVSVCQYNMCEYPQTICHPNLGNHRKELWHLDTGVVSCLYKRNFTYDVNADYLYFHFYQEGGTFYAYFTDTGVVTKFLFNVYLGMALSHYYVMPLTCNSKLTLEYWVTPLTSRQYLLAFNQDGIIFNAVDCMSDFMSEIKCKTQSIAPPTGVYELNGYTVQPIADVYRRKPNLPNCNIEAWLNDKSVPSPLNWERKTFSNCNFNMSSLMSFIQADSFTCNNIDAAKIYGMCFSSITIDKFAIPNGRKVDLQLGNLGYLQSFNYRIDTTATSCQLYYNLPAANVSVSRFNPSTWNKRFGFIEDSVFKPRPAGVLTNHDVVYAQHCFKAPKNFCPCKLNGSCVGSGPGKNNGIGTCPAGTNYLTCDNLCTPDPITFTGTYKCPQTKSLVGIGEHCSGLAVKSDYCGGNSCTCRPQAFLGWSADSCLQGDKCNIFANFILHDVNSGLTCSTDLQKANTDIILGVCVNYDLYGILGQGIFVEVNATYYNSWQNLLYDSNGNLYGFRDYITNRTFMIRSCYSGRVSAAFHANSSEPALLFRNIKCNYVFNNSLTRQLQPINYFDSYLGCVVNAYNSTAISVQTCDLTVGSGYCVDYSKNGGSGGAITTGYRFTNFEPFTVNSVNDSLEPVGGLYEIQIPSEFTIGNMVEFIQTSSPKVTIDCAAFVCGDYAACKSQLVEYGSFCDNINAILTEVNELLDTTQLQVANSLMNGVTLSTKLKDGVNFNVDDINFSPVLGCLGSECSKASSRSAIEDLLFDKVKLSDVGFVEAYNNCTGGAEIRDLICVQSYKGIKVLPPLLSENQFSGYTLAATSASLFPPWTAAAGVPFYLNVQYRINGLGVTMDVLSQNQKLIANAFNNALYAIQEGFDATNSALVKIQAVVNANAEALNNLLQQLSNRFGAISASLQEILSRLDPPEAEAQIDRLINGRLTALNAYVSQQLSDSTLVKFSAAQAMEKVNECVKSQSSRINFCGNGNHIISLVQNAPYGLYFIHFSYVPTKYVTARVSPGLCIAGDRGIAPKSGYFVNVNNTWMYTGSGYYYPEPITENNVVVMSTCAVNYTKAPYVMLNTSIPNLPDFKEELDQWFKNQTSVAPDLSLDYINVTFLDLLGSGRENLYFQGGGGSGYIPEAPRDGQAYVRKDGEWVLLSTFLGHHHHHHHHGLNDIFEAQKIEWHE'\n",
    "\n",
    "# inh-NL63-S-2P\n",
    "# seq = 'MKLFLILLVLPLASCFFTCNSNANLSMLQLGVPDNSSTIVTGLLPTHWICANQSTSVYSANGFFYIDVGNHRSAFALHTGYYDVNQYYIYVTNEIGLNASVTLKICKFGINTTFDFLSNSSSSFDCIVNLLFTEQLGAPLGITISGETVRLHLYNVTRTFYVPAAYKLTKLSVKCYFNYSCVFSVVNATVTVNVTTHNGRVVNYTVCDDCNGYTDNIFSVQQDGRIPNGFPFNNWFLLTNGSTLVDGVSRLYQPLRLTCLWPVPGLKSSTGFVYFNATGSDVNCNGYQHNSVADVMRYNLNFSANSVDNLKSGVIVFKTLQYDVLFYCSNSSSGVLDTTIPFGPSSQPYYCFINSTINTTHVSTFVGVLPPTVREIVVARTGQFYINGFKYFDLGFIEAVNFNVTTASATDFWTVAFATFVDVLVNVSATKIQNLLYCDSPFEKLQCEHLQFGLQDGFYSANFLDDNVLPETYVALPIYYQHTDINFTATASFGGSCYVCKPHQVNISLNGNTSVCVRTSHFSIRYIYNRVKSGSPGDSSWHIYLKSGTCPFSFSKLNNFQKFKTICFSTVAVPGSCNFPLEATWHYTSYTIVGALYVTWSEGNSITGVPYPVSGIREFSNLVLNNCTKYNIYDYVGTGIIRSSNQSLAGGITYVSNSGNLLGFKNVSTGNIFIVTPCNQPDQVAVYQQSIIGAMTAVNESRYGLQNLLQLPNFYYVSNGGNNCTTAVMTYSNFGICADGSLIPVRLRNSSDNGISAIITANLSIPSNWTTSVQVEYLQITSIPIVVDCATYVCNGNPRCKNLLKQYTSACKTIEDALRLSAHLETNDVSSMLTFDSNAFSLANVTSFGDYNLSSVLPQRNIHSSRIAGRSALEDLLFSKVVTSGLGTVDVDYKSCTKGLSIADLACAQYYNGIMVLPGVADAERMAMYTGSLIGGMVLGGLTSAAAIPFSLALQARLNYVALQTDVLQENQKILAASFNKAINNIVASFSSVNDAITQTAEAIHTVTIALNKIQDVVNQQGSALNHLTSQLRHNFQAISNSIQAIYDRLDPPQADQQVDRLITGRLAALNAFVSQVLNKYTEVRSSRRLAQQKINECVKSQSNRYGFCGNGTHIFSIVNSAPDGLLFLHTVLLPTDYKNVKAWSGICVDGIYGYVLRQPNLVLYSDNGVFRVTSRVMFQPRLPVLSDFVQIYNCNVTFVNISRVELHTVIPDYVDVNKTLQEFAQNLPKYVKPNFDLTPFNLTYLNLSSELKQLEAKTASLFQTTVELQGLIDQINSTYVDLKLLNRFENEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# inh-229E-S-2P\n",
    "# seq = 'MFVLLVAYALLHIAGCQTTNGTNTSHSVCNGCVGHSENVFAVESGGYIPSNFSFNNWFLLTNTSSVVDGVVRSFQPLLLNCLWSVSGSQFTTGFVYFNGTGRGACKGFYSNASSDVIRYNINFEENLRRGTILFKTSYGAVVFYCTNNTLVSGDAHIPSGTVLGNFYCFVNTTIGNETTSAFVGALPKTVREFVISRTGHFYINGYRYFSLGDVEAVNFNVTNAATIVCTVALASYADVLVNVSQTAIANIIYCNSVINRLRCDQLSFDVPDGFYSTSPIQPVELPMSIVSLPVYHKHTFIVLHVKFEHQRGPGKCYNCRPSVINITLANFNETKGPLCVDTSHFTTQFVDNVKLARWSASINTGNCPFSFGKVNNFVKFGSVCFSLKDIPGGCAMPIMANLVNHKSHNIGSLYVSWSDGDVITGVPKPVEGVSSFMNVTLNKCTKYNIYDVSGVGVIRISNDTFLNGITYTSTSGNLLGFKDVTNGTIYSITPCNPPDQLVVYQQAVVGAMLSENFTSYGFSNVVEMPKFFYASNGTYNCTDAVLTYSSFGVCADGSIIAVQPRNVSYDSVSAIVTANLSIPSNWTTSVQVEYLQITSKPIVVDCSTYVCNGNVRCVELLKQYTSACKTIEDALRNSAMLESADVSEMLTFDKKAFTLANVSSFGDYNLSSVIPSLPRSGSRVAGRSAIEDILFSKLVTSGLGTVDADYKKCTKGLSIADLACAQYYNGIMVLPGVADAERMAMYTGSLIGGIALGGLTSAASIPFSLAIQSRLNYVALQTDVLQENQKILAASFNKAMTNIVDAFTGVNDAITQTSQALQTVATALNKIQDVVNQQGNSLNHLTSQLRQNFQAISSSIQAIYDRLDPPQADQQVDRLITGRLAALNVFVSHTLTKYTEVRASRQLAQQKVNECVKSQSKRYGFCGNGTHIFSLVNAAPEGLVFLHTVLLPTQYKDVEAWSGLCVDGINGYVLRQPNLALYKEGNYYRITSRIMFEPRIPTIADFVQIENCNVTFVNISRSELQTIVPEYIDVNKTLQELSYKLPNYTVPDLVVEQYNQTILNLTSEISTLENKSAELNYTVQKLQTLIDNINSTLVDLKWLNRVETYIKWPWEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# caltech-229E-S-2P (change to native signal peptide)\n",
    "# seq = 'GTQTTNGLNTSYSVCNGCVGYSENVFAVESGGYIPSDFAFNNWFLLTNTSSVVDGVVRSFQPLLLNCLWSVSGLRFTTGFVYFNGTGRGDCKGFSSDVLSDVIRYNLNFEENLRRGTILFKTSYGVVVFYCTNNTLVSGDAHIPFGTVLGNFYCFVNTTIGTETTSAFVGALPKTVREFVISRTGHFYINGYRYFTLGNVEAVNFNVTTAETTDFFTVALASYADVLVNVSQTSIANIIYCNSVINRLRCDQLSFYVPDGFYSTSPIQSVELPVSIVSLPVYHKHMFIVLYVDFKPQSGGGKCFNCYPAGVNITLANFNETKGPLCVDTSHFTTKYVAVYANVGRWSASINTGNCPFSFGKVNNFVKFGSVCFSLKDIPGGCAMPIVANWAYSKYYTIGTLYVSWSDGDGITGVPQPVEGVSSFMNVTLDKCTKYNIYDVSGVGVIRVSNDTFLNGITYTSTSGNLLGFKDVTKGTIYSITPCNPPDQLVVYQQAVVGAMLSENFTSYGFSNVVELPKFFYASNGTYNCTDAVLTYSSFGVCADGSIIAVQPRNVSYDSVSAIVTANLSIPSNWTISVQVEYLQITSTPIVVDCSTYVCNGNVRCVELLKQYTSACKTIEDALRNSARLESADVSEMLTFDKKAFTLANVSSFGDYNLSSVIPSLPTSGSRVAGRSAIEDILFSKIVTSGLGTVDADYKNCTKGLSIADLACAQYYNGIMVLPGVADAERMAMYTGSLIGGIALGGLTSAVSIPFSLAIQARLNYVALQTDVLQENQKILAASFNKAMTNIVDAFTGVNDAITQTSQALQTVATALNKIQDVVNQQGNSLNHLTSQLRQNFQAISSSIQAIYDRLDPPQADQQVDRLITGRLAALNVFVSHTLTKYTEVRASRQLAQQKVNECVKSQSKRYGFCGNGTHIFSIVNAAPEGLVFLHTVLLPTQYKDVEAWSGLCVDGTNGYVLRQPNLALYKEGNYYRITSRIMFEPRIPTMADFVQIENCNVTFVNISRSELQTIVPEYIDVNKTLQELSYKLPNYTVPDLVVEQYNQTILNLTSEISTLENKSAELNYTVQKLQTLIDNINSTLVDLKWLNRVETYIKGSGRENLYFQGGGGSGYIPEAPRDGQAYVRKDGEWVLLSTFLGHHHHHHHHGLNDIFEAQKIEWHE'\n",
    "# ace2 v1\n",
    "# seq = 'MSSSSWLLLSLVAVTAAQSTIEEQAKTFLDKFNAEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLQVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTPGFWENSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYLAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYADGSGGSGSGGSKGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKRHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK'\n",
    "\n",
    "# ace2 v2\n",
    "# seq = 'MSSSSWLLLSLVAVTAAQSTIEEQAKYFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTTAQMYPLQEIQNLTVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTQGFWEYSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYLAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYADGSGGSGSGGSKGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKRHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK'\n",
    "\n",
    "# ace2 v3\n",
    "# seq = 'MSSSSWLLLSLVAVTAAQSTIEEQVKYFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLQVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTPGFWENSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYLAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYADGSGGSGSGGSKGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKRHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK'\n",
    "\n",
    "# ace2 v4\n",
    "# seq = 'MSSSSWLLLSLVAVTAAQSTIEEQAKTFLDKFNAEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTTAQMYPLQEIQNLTVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTQGFWEYSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYLAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYADGSGGSGSGGSKGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKRHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK'\n",
    "\n",
    "# ace2 v5\n",
    "# seq = 'MSSSSWLLLSLVAVTAAQSTIEEQVKTFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLQVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTQGFWENSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYLAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYADGSGGSGSGGSKGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKRHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK'\n",
    "\n",
    "# ace2 v6\n",
    "# seq = 'MSSSSWLLLSLVAVTAAQSTIEEQAKYFLDKFNHEAEDLFYLSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTTAQMYPLQEIQNLQVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTPGFWEYSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYLAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYADGSGGSGSGGSKGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKRHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK'\n",
    "\n",
    "# ace2 wt\n",
    "# seq = 'MSSSSWLLLSLVAVTAAQSTIEEQAKTFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLTVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTQGFWENSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYAAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYADGSGGSGSGGSKGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKRHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITHGMDELYK' \n",
    "\n",
    "# SARS-CoV-2_Spike_Omicron_fm_HexaPro\n",
    "# seq = 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHVISGTNGTKRFDNPVLPFNDGVYFASIEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLDHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPIIVREPEDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNLAPFFTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKVSGNYNYLYRLFRKSNLKPFERDISTEIYQAGNKPCNGVAGFNCYFPLRSYSFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLKGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEYVNNSYECDIPIGAGICASYQTQTKSHGSASSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLKRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKYFGGFNFSQILPDPSKPSKRSPIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFKGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGPALQIPFPMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTPSALGKLQDVVNHNAQALNTLVKQLSSKFGAISSVLNDIFSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# SARS_CoV2_S_Omicron\n",
    "# seq = 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHVISGTNGTKRFDNPVLPFNDGVYFASIEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLDHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPIIVREPEDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFDEVFNATRFASVYAWNRKRISNCVADYSVLYNLAPFFTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGNIADYNYKLPDDFTGCVIAWNSNKLDSKVSGNYNYLYRLFRKSNLKPFERDISTEIYQAGNKPCNGVAGFNCYFPLRSYSFRPTYGVGHQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLKGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQGVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEYVNNSYECDIPIGAGICASYQTQTKSHGSASSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLKRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKYFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFKGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNHNAQALNTLVKQLSSKFGAISSVLNDIFSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQEFGSGGYIPEAPRDGQAYVRKDGEWVLLSTFLKGQDNSADIQHSGRPLESRGPFEQKLISEEDLNMHTGHHHHHH'\n",
    "\n",
    "# Wuhan nCoV S-fm2P\n",
    "# seq = 'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPGSASSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQ'\n",
    "## ADJUSTABLE PARAMETERS\n",
    "# HCD: light colors\n",
    "lightgreen_hex = '#ccffcc' \n",
    "lightblue_hex = '#cce6ff'\n",
    "lightorange_hex = '#ffebcc'\n",
    "# ETD: normal colors\n",
    "normalgreen_hex = '#99ff99'\n",
    "normalblue_hex = '#99ccff'\n",
    "normalorange_hex = '#ffd699' \n",
    "# GlycanSource B+P, B/P: deep colors\n",
    "darkgreen_hex = '#66ff66' \n",
    "darkblue_hex = '#66b3ff'\n",
    "# byos colors\n",
    "lightpink_hex = '#ffb6c1'\n",
    "deeppink_hex = '#ff1493'\n",
    "yellow_hex = '#ffff66' \n",
    "# BYONIC RT TOLERANCE FOR UNIQUEPEP FILE <min.>, SET TO np.Inf TO CANCEL THIS CRITERION (COUNT PSM)\n",
    "unique_byonic_rt = 3\n",
    "# PGLYCO RT TOLERANCE FOR UNIQUEPEP FILE <sec.>, SET TO np.Inf TO CANCEL THIS CRITERION (COUNT PSM)\n",
    "unique_pglyco_rt = 180\n",
    "\n",
    "# BYONIC RT TOLERANCE FOR NGLYCOPEP FILE <min.>, SET TO np.Inf TO CANCEL THIS CRITERION (COUNT PSM)\n",
    "nglyco_byonic_rt = np.Inf\n",
    "# PGLYCO RT TOLERANCE FOR NGLYCOPEP FILE <sec.>, SET TO np.Inf TO CANCEL THIS CRITERION (COUNT PSM)\n",
    "nglyco_pglyco_rt = np.Inf\n",
    "\n",
    "# SCAN DIFFERENCE <scan num.> (ASSIGN PAIR)\n",
    "byonic_scandif = 5\n",
    "# PLOTTING CHOICES (whether to plot xicauc(byos)/int(byos)/mono(pglyco)/isotope(pglyco))\n",
    "# if you do not want to plot anything, please set all the parameters to 'no'.\n",
    "export_xicauc = 'yes' # set this to 'no' if byos file is not present\n",
    "export_int = 'no' # set this to 'no' if byos file is not present \n",
    "export_mono = 'no' # set this to 'no' if pglyco file is not present\n",
    "export_isotope = 'yes' # set this to 'no' if pglyco file is not present\n",
    "# glycan category version (v1: nx, v2: unocuppied/oligoman/complex/complex+sia, v3: nx w/ man4&below-man9, v4: nx w/ man4&below-man9 & fucosylation)\n",
    "plot_v1 = 'yes'\n",
    "plot_v2 = 'yes'\n",
    "plot_v3 = 'no'\n",
    "plot_v4 = 'no'\n",
    "# color hybrid yellow or not (default: n3 as hybrid)\n",
    "colorHybrid = True # True/False # only for v3/v4\n",
    "# TopN\n",
    "topN = 5\n",
    "# BYONIC SCORE CUTOFF (default=200)\n",
    "BYONIC_SCORE_CUTOFF = 200\n",
    "# PGLYCO PRECURSOR MZ ROUNDING DECIMAL\n",
    "RoundTo = 1\n",
    "# ROUNDING FOR MODS NUMBERS\n",
    "ModsRoundTo = 4\n",
    "# pass in the modification numbers in list (all the reuslts from byonic will be divided by the nums in this lst to find the most probable modification)\n",
    "# the reuslts in byonic are calculated from the passed-in nums, so should be completely divided if it's the correct mods\n",
    "mods_name = [] # IF NO MODS, LEAVE IT AS []. PLEASE PASS IN W/ THE SAME ORDER AS MODS_NUM (CAN ONLY PASS IN THE FOLLOWING CHOICES: 'SO3', 'Phospho', 'KDN', CASE-SENSITIVE)\n",
    "mods_num = [] # IF NO MODS, LEAVE IT AS []. PLEASE PASS IN W/ THE SAME ORDER AS MODS_NAME\n",
    "# ALLOW ATYPICAL N-GLYCOSYLATION SEQUON (e.g. N-X-C, the atypical sequons can only be detected by pglyco for the time being)\n",
    "allow_atypical_sequon = 'no' # yes / no\n",
    "\n",
    "############################### PLEASE DO NOT ALTER ANYTHING BELOW ###############################\n",
    "# AUXILIARY FUNCTIONS\n",
    "def get_key(val):\n",
    "    # construct relation btw mods_name & mods_num\n",
    "    mods_NameToNum = dict(zip(mods_name, mods_num))\n",
    "    for key, value in mods_NameToNum.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "def move_df(df, move_col, insert_left_col):\n",
    "    move_df = df[move_col]\n",
    "    df.drop(labels=[move_col], axis=1, inplace = True)\n",
    "    df.insert(df.columns.get_loc(insert_left_col) + 1, move_col, move_df)\n",
    "def findNPosBySequon(seq):\n",
    "#     pattern = '(?i)(N[ARNDBCEQZGHILKMFSTWYV]T)|(N[ARNDBCEQZGHILKMFSTWYV]S)' # case insensitive\n",
    "    if allow_atypical_sequon == 'yes':\n",
    "        pattern = '(?=((?i)(N[ARNDBCEQZGHILKMFSTWYV]T)|(N[ARNDBCEQZGHILKMFSTWYV]S)|(N[ARNDBCEQZGHILKMFSTWYV]C)))' # case insensive & able to find overlapping sequons\n",
    "    else:\n",
    "        pattern = '(?=((?i)(N[ARNDBCEQZGHILKMFSTWYV]T)|(N[ARNDBCEQZGHILKMFSTWYV]S)))'\n",
    "    result = [(m.start(0)+1, seq[m.start(0):m.start(0)+3]) for m in re.finditer(pattern, seq, overlapped = True)]\n",
    "    return result # [(site, 'sequon'), ...(...)]\n",
    "def findPotentialOPos(seq):\n",
    "    # find o pos by st\n",
    "    opos = [m.start(0)+1 for m in re.finditer(r'(?i)(s)|(t)', seq)]\n",
    "    return opos\n",
    "def findUnionOnly(val): # for final major glycoform table\n",
    "    color = 'red'\n",
    "    weight = 'bold'\n",
    "    bg_color = 'WhiteSmoke'\n",
    "    return f'color: {color}; font-weight: {weight}; background-color: {bg_color}'\n",
    "def sort_intstr_col(df, col_to_sort):\n",
    "    # accepts int & str mixed type col, no other datatype is allowed\n",
    "    lst = df[col_to_sort].tolist()\n",
    "    lst.sort(key=lambda v: (isinstance(v, str), v))\n",
    "    sorter = list(set(lst))\n",
    "    # reindex the df with .loc by the new sorted lst\n",
    "    df = df.set_index(col_to_sort).loc[lst]\n",
    "#     df.drop_duplicates(inplace=True)\n",
    "#     df.reset_index(inplace=True)\n",
    "    df = df.drop_duplicates().reset_index()\n",
    "#     df[col_to_sort] = df[col_to_sort].astype(\"category\")\n",
    "#     df[col_to_sort].cat.set_categories(sorter, inplace=True)\n",
    "#     df = df.sort_values([col_to_sort]).reset_index(drop=True)\n",
    "    return df\n",
    "# get export filename based on input combo\n",
    "def export_filename(byonicfile = '', byosfile = '', pglycofile = ''):\n",
    "    names = [byonicfile, byosfile, pglycofile]\n",
    "    names = [n for n in names if n != '']\n",
    "    names = '_'.join(names)\n",
    "    return names\n",
    "# define glycansource function\n",
    "def glycansource(df, colname):\n",
    "    # glycan comprison: only present in byonic -> b, only present in pglyco -> p, both the same -> b+p, not the same -> b/p\n",
    "    conditions = [\n",
    "        (df['rounded_FinalGlycans[Byonic]'] != -1) & (df['GlycanComposition_ByonicStyle[pGlyco]'] == -1),\n",
    "        (df['rounded_FinalGlycans[Byonic]'] == -1) & (df['GlycanComposition_ByonicStyle[pGlyco]'] != -1),\n",
    "        (df['rounded_FinalGlycans[Byonic]'] != -1) & (df['GlycanComposition_ByonicStyle[pGlyco]'] != -1) & (df['rounded_FinalGlycans[Byonic]'] == df['GlycanComposition_ByonicStyle[pGlyco]']),\n",
    "        (df['rounded_FinalGlycans[Byonic]'] != -1) & (df['GlycanComposition_ByonicStyle[pGlyco]'] != -1) & (df['rounded_FinalGlycans[Byonic]'] != df['GlycanComposition_ByonicStyle[pGlyco]'])]\n",
    "    choices = ['B', 'P', 'B=P', 'B≠P'] \n",
    "    glycan_source = np.select(conditions, choices, -1) \n",
    "    df.insert(df.columns.get_loc(colname) + 1 , 'GlycanSource', glycan_source , True)\n",
    "# define mask function\n",
    "def threshold_masks_colorind(df):\n",
    "    global b_hcd_mask, p_hcd_mask, both_hcd_mask, b_etd_mask, p_etd_mask, both_etd_mask\n",
    "    global b_glycansource_mask, p_glycansource_mask, byos_exclusiveOr_mask, byos_and_mask, byos_bothsame_mask\n",
    "    global lightgreen_ind, lightblue_ind, lightorange_ind, normalgreen_ind, normalblue_ind, normalorange_ind, deepgreen_ind, deepblue_ind, lightpink_ind, deeppink_ind, yellow_ind  \n",
    "\n",
    "    if byonicfile != '' and byosfile != '' and pglycofile != '': # bbp all present\n",
    "        # HCD \n",
    "        b_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['Score[Byonic]'] > BYONIC_SCORE_CUTOFF) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001) & ((df['PepScore[pGlyco]'] <= 5) | (df['GlyScore[pGlyco]'] <= 4))\n",
    "        p_hcd_mask = (df['FragmentType[pGlyco]'] == 'hcd') & ((df['Score[Byonic]'] <= BYONIC_SCORE_CUTOFF) | (df['PEP\\r\\n2D[Byonic]'].abs() >= 0.001)) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)    \n",
    "        both_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['FragmentType[pGlyco]'] == 'hcd') & (df['Score[Byonic]'] > BYONIC_SCORE_CUTOFF) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)\n",
    "        # ETD: remember byonic etd does not need threshold, so we only need to make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        b_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1) & ((df['PepScore[pGlyco]'] <= 5) | (df['GlyScore[pGlyco]'] <= 4)) \n",
    "        p_etd_mask = (df['FragmentType[pGlyco]'] == 'ethcd') & (df['Score[Byonic]'] == -1) & (df['PEP\\r\\n2D[Byonic]'] == -1) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)    \n",
    "        both_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['FragmentType[pGlyco]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)\n",
    "        # (HCD OR ETD) & (B+P OR B/P) & passes threshold: parts of lightblue/blue & lightgreen/green will become deep colors\n",
    "        b_glycansource_mask = ((df['GlycanSource'] == 'B=P') ^ (df['GlycanSource'] == 'B≠P')) & ((b_hcd_mask) ^ (b_etd_mask)) & (~((p_hcd_mask) ^ (p_etd_mask))) # hcd exclusive or etd & ~(p)\n",
    "        p_glycansource_mask = ((df['GlycanSource'] == 'B=P') ^ (df['GlycanSource'] == 'B≠P')) & ((p_hcd_mask) ^ (p_etd_mask)) & (~((b_hcd_mask) ^ (b_etd_mask))) # hcd exclusive or etd & ~(b)   \n",
    "        # comparison between byonic & byos\n",
    "        byos_exclusiveOr_mask = (df['Calc.MH[Byos]'] != -1) & (df['Calc.\\r\\nMH[Byonic]'] != -1) & ((df['Calc.MH[Byos]'].round(decimals=2) != df['Calc.\\r\\nMH[Byonic]'].round(decimals=2))^(df['PureSequence[Byos]'] != df['PureSequence[Byonic]']))\n",
    "        byos_and_mask = (df['Calc.MH[Byos]'] != -1) & (df['Calc.\\r\\nMH[Byonic]'] != -1) & (df['Calc.MH[Byos]'].round(decimals=2) != df['Calc.\\r\\nMH[Byonic]'].round(decimals=2)) & (df['PureSequence[Byos]'] != df['PureSequence[Byonic]'])\n",
    "        byos_bothsame_mask = (df['Calc.MH[Byos]'] != -1) & (df['Calc.\\r\\nMH[Byonic]'] != -1) & (df['Calc.MH[Byos]'].round(decimals=2) == df['Calc.\\r\\nMH[Byonic]'].round(decimals=2)) & (df['PureSequence[Byos]'] == df['PureSequence[Byonic]'])\n",
    "        # record df color indices\n",
    "        lightgreen_ind = df.loc[b_hcd_mask].index.tolist()\n",
    "        df.loc[b_hcd_mask, 'ColorCode'] = 'lightgreen(%s)'%lightgreen_hex\n",
    "        \n",
    "        lightblue_ind = df.loc[p_hcd_mask].index.tolist()\n",
    "        df.loc[p_hcd_mask, 'ColorCode'] = 'lightblue(%s)'%lightblue_hex\n",
    "        \n",
    "        lightorange_ind = df.loc[both_hcd_mask].index.tolist()\n",
    "        df.loc[both_hcd_mask, 'ColorCode'] = 'lightorange(%s)'%lightorange_hex\n",
    "        \n",
    "        normalgreen_ind = df.loc[b_etd_mask].index.tolist()\n",
    "        df.loc[b_etd_mask, 'ColorCode'] = 'normalgreen(%s)'%normalgreen_hex\n",
    "        \n",
    "        normalblue_ind = df.loc[p_etd_mask].index.tolist()\n",
    "        df.loc[p_etd_mask, 'ColorCode'] = 'normalblue(%s)'%normalblue_hex\n",
    "            \n",
    "        normalorange_ind = df.loc[both_etd_mask].index.tolist()\n",
    "        df.loc[both_etd_mask, 'ColorCode'] = 'normalorange(%s)'%normalorange_hex\n",
    "        \n",
    "        deepgreen_ind = df.loc[b_glycansource_mask].index.tolist()\n",
    "        df.loc[b_glycansource_mask, 'ColorCode'] = 'deepgreen(%s)'%darkgreen_hex\n",
    "        \n",
    "        deepblue_ind = df.loc[p_glycansource_mask].index.tolist()\n",
    "        df.loc[p_glycansource_mask, 'ColorCode'] = 'deepblue(%s)'%darkblue_hex\n",
    "        \n",
    "        lightpink_ind = df.loc[byos_exclusiveOr_mask].index.tolist()\n",
    "        \n",
    "        deeppink_ind = df.loc[byos_and_mask].index.tolist()\n",
    "        \n",
    "        yellow_ind = df.loc[byos_bothsame_mask].index.tolist()\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile != '': # byonic + pglyco\n",
    "        # HCD \n",
    "        b_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['Score[Byonic]'] > BYONIC_SCORE_CUTOFF) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001) & ((df['PepScore[pGlyco]'] <= 5) | (df['GlyScore[pGlyco]'] <= 4))\n",
    "        p_hcd_mask = (df['FragmentType[pGlyco]'] == 'hcd') & ((df['Score[Byonic]'] <= BYONIC_SCORE_CUTOFF) | (df['PEP\\r\\n2D[Byonic]'].abs() >= 0.001)) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)    \n",
    "        both_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['FragmentType[pGlyco]'] == 'hcd') & (df['Score[Byonic]'] > BYONIC_SCORE_CUTOFF) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)\n",
    "        # ETD: remember byonic etd does not need threshold, so we only need ot make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        b_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1) & ((df['PepScore[pGlyco]'] <= 5) | (df['GlyScore[pGlyco]'] <= 4)) \n",
    "        p_etd_mask = (df['FragmentType[pGlyco]'] == 'ethcd') & (df['Score[Byonic]'] == -1) & (df['PEP\\r\\n2D[Byonic]'] == -1) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)    \n",
    "        both_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['FragmentType[pGlyco]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)\n",
    "        # (HCD OR ETD) & (B+P OR B/P) & passes threshold: parts of lightblue/blue & lightgreen/green will become deep colors\n",
    "        b_glycansource_mask = ((df['GlycanSource'] == 'B=P') ^ (df['GlycanSource'] == 'B≠P')) & ((b_hcd_mask) ^ (b_etd_mask)) & (~((p_hcd_mask) ^ (p_etd_mask))) # hcd exclusive or etd & ~(p)\n",
    "        p_glycansource_mask = ((df['GlycanSource'] == 'B=P') ^ (df['GlycanSource'] == 'B≠P')) & ((p_hcd_mask) ^ (p_etd_mask)) & (~((b_hcd_mask) ^ (b_etd_mask))) # hcd exclusive or etd & ~(b)   \n",
    "        # record df color indices\n",
    "        lightgreen_ind = df.loc[b_hcd_mask].index.tolist()\n",
    "        df.loc[b_hcd_mask, 'ColorCode'] = 'lightgreen(%s)'%lightgreen_hex\n",
    "        \n",
    "        lightblue_ind = df.loc[p_hcd_mask].index.tolist()\n",
    "        df.loc[p_hcd_mask, 'ColorCode'] = 'lightblue(%s)'%lightblue_hex\n",
    "        \n",
    "        lightorange_ind = df.loc[both_hcd_mask].index.tolist()\n",
    "        df.loc[both_hcd_mask, 'ColorCode'] = 'lightorange(%s)'%lightorange_hex\n",
    "        \n",
    "        normalgreen_ind = df.loc[b_etd_mask].index.tolist()\n",
    "        df.loc[b_etd_mask, 'ColorCode'] = 'normalgreen(%s)'%normalgreen_hex\n",
    "        \n",
    "        normalblue_ind = df.loc[p_etd_mask].index.tolist()\n",
    "        df.loc[p_etd_mask, 'ColorCode'] = 'normalblue(%s)'%normalblue_hex\n",
    "            \n",
    "        normalorange_ind = df.loc[both_etd_mask].index.tolist()\n",
    "        df.loc[both_etd_mask, 'ColorCode'] = 'normalorange(%s)'%normalorange_hex\n",
    "        \n",
    "        deepgreen_ind = df.loc[b_glycansource_mask].index.tolist()\n",
    "        df.loc[b_glycansource_mask, 'ColorCode'] = 'deepgreen(%s)'%darkgreen_hex\n",
    "        \n",
    "        deepblue_ind = df.loc[p_glycansource_mask].index.tolist()\n",
    "        df.loc[p_glycansource_mask, 'ColorCode'] = 'deepblue(%s)'%darkblue_hex\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile == '': # only byonic\n",
    "        # HCD \n",
    "        b_hcd_mask = (df['Fragment\\r\\nType'] == 'hcd') & (df['Score'] > BYONIC_SCORE_CUTOFF) & (df['PEP\\r\\n2D'].abs() < 0.001)\n",
    "        # ETD: remember byonic etd does not need threshold, so we only need ot make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        b_etd_mask = (df['Fragment\\r\\nType'] == 'ethcd') & (df['Score'] != -1) & (df['PEP\\r\\n2D'] != -1) \n",
    "        # record df color indices\n",
    "        lightgreen_ind = df.loc[b_hcd_mask].index.tolist()\n",
    "        df.loc[b_hcd_mask, 'ColorCode'] = 'lightgreen(%s)'%lightgreen_hex\n",
    "        \n",
    "        normalgreen_ind = df.loc[b_etd_mask].index.tolist()\n",
    "        df.loc[b_etd_mask, 'ColorCode'] = 'normalgreen(%s)'%normalgreen_hex\n",
    "    elif byonicfile == '' and byosfile == '' and pglycofile != '': # only pglyco\n",
    "        # HCD \n",
    "        p_hcd_mask = (df['FragmentType'] == 'hcd') & (df['PepScore'] > 5) & (df['GlyScore'] > 4)    \n",
    "        # ETD: remember byonic etd does not need threshold, so we only need ot make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        p_etd_mask = (df['FragmentType'] == 'ethcd') & (df['PepScore'] > 5) & (df['GlyScore'] > 4)    \n",
    "        # record df color indices\n",
    "        lightblue_ind = df.loc[p_hcd_mask].index.tolist()\n",
    "        df.loc[p_hcd_mask, 'ColorCode'] = 'lightblue(%s)'%lightblue_hex\n",
    "        \n",
    "        normalblue_ind = df.loc[p_etd_mask].index.tolist()\n",
    "        df.loc[p_etd_mask, 'ColorCode'] = 'normalblue(%s)'%normalblue_hex\n",
    "    elif byonicfile != '' and byosfile != '' and pglycofile == '': # byonic + byos\n",
    "        # HCD \n",
    "        b_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['Score[Byonic]'] > BYONIC_SCORE_CUTOFF) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001)\n",
    "        # ETD: remember byonic etd does not need threshold, so we only need ot make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        b_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1)\n",
    "        # comparison between byonic & byos\n",
    "        byos_exclusiveOr_mask = (df['Calc.MH[Byos]'] != -1) & (df['Calc.\\r\\nMH[Byonic]'] != -1) & ((df['Calc.MH[Byos]'].round(decimals=2) != df['Calc.\\r\\nMH[Byonic]'].round(decimals=2))^(df['PureSequence[Byos]'] != df['PureSequence[Byonic]']))\n",
    "        byos_and_mask = (df['Calc.MH[Byos]'] != -1) & (df['Calc.\\r\\nMH[Byonic]'] != -1) & (df['Calc.MH[Byos]'].round(decimals=2) != df['Calc.\\r\\nMH[Byonic]'].round(decimals=2)) & (df['PureSequence[Byos]'] != df['PureSequence[Byonic]'])\n",
    "        byos_bothsame_mask = (df['Calc.MH[Byos]'] != -1) & (df['Calc.\\r\\nMH[Byonic]'] != -1) & (df['Calc.MH[Byos]'].round(decimals=2) == df['Calc.\\r\\nMH[Byonic]'].round(decimals=2)) & (df['PureSequence[Byos]'] == df['PureSequence[Byonic]'])\n",
    "        # record df color indices\n",
    "        lightgreen_ind = df.loc[b_hcd_mask].index.tolist()\n",
    "        df.loc[b_hcd_mask, 'ColorCode'] = 'lightgreen(%s)'%lightgreen_hex\n",
    "        \n",
    "        normalgreen_ind = df.loc[b_etd_mask].index.tolist()\n",
    "        df.loc[b_etd_mask, 'ColorCode'] = 'normalgreen(%s)'%normalgreen_hex\n",
    "        \n",
    "        lightpink_ind = df.loc[byos_exclusiveOr_mask].index.tolist()\n",
    "        \n",
    "        deeppink_ind = df.loc[byos_and_mask].index.tolist()\n",
    "        \n",
    "        yellow_ind = df.loc[byos_bothsame_mask].index.tolist()\n",
    "def bg_color(x):\n",
    "    if byonicfile != '' and byosfile != '' and pglycofile != '': # bbp all present\n",
    "        # byonic & pglyco colors\n",
    "        # HCD: light colors\n",
    "        c1 = 'background-color: %s'%lightgreen_hex \n",
    "        c2 = 'background-color: %s'%lightblue_hex \n",
    "        c3 = 'background-color: %s'%lightorange_hex \n",
    "        # ETD: normal colors\n",
    "        c4 = 'background-color: %s'%normalgreen_hex \n",
    "        c5 = 'background-color: %s'%normalblue_hex \n",
    "        c6 = 'background-color: %s'%normalorange_hex \n",
    "        # GlycanSource B+P, B/P: deep colors\n",
    "        c7 = 'background-color: %s'%darkgreen_hex \n",
    "        c8 = 'background-color: %s'%darkblue_hex \n",
    "        # byos colors\n",
    "        c9 = 'background-color: %s'%lightpink_hex \n",
    "        c10 = 'background-color: %s'%deeppink_hex\n",
    "        c11 = 'background-color: %s'%yellow_hex \n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns)    \n",
    "        # byonic & byos coloring range\n",
    "        bb_range = [col for col in df1.columns.tolist() if '[Byos]' in col]\n",
    "        # byonic & pglyco coloring range\n",
    "        bp_range = [col for col in df1.columns.tolist() if '[Byonic]' in col or '[pGlyco]' in col]\n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[b_hcd_mask, bp_range] = c1\n",
    "        print('<Color Summary>\\n%s rows will be colored light green (%s).'%(len(df1.loc[b_hcd_mask, bp_range]), lightgreen_hex))\n",
    "        df1.loc[p_hcd_mask, bp_range] = c2 \n",
    "        print('%s rows will be colored light blue (%s).'%(len(df1.loc[p_hcd_mask, bp_range]), lightblue_hex))\n",
    "        df1.loc[both_hcd_mask, bp_range] = c3\n",
    "        print('%s rows will be colored light orange (%s).'%(len(df1.loc[both_hcd_mask, bp_range]), lightorange_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[b_etd_mask, bp_range] = c4\n",
    "        print('%s rows will be colored green (%s).'%(len(df1.loc[b_etd_mask, bp_range]), normalgreen_hex))\n",
    "        df1.loc[p_etd_mask, bp_range] = c5\n",
    "        print('%s rows will be colored blue (%s).'%(len(df1.loc[p_etd_mask, bp_range]), normalblue_hex))\n",
    "        df1.loc[both_etd_mask, bp_range] = c6\n",
    "        print('%s rows will be colored orange (%s).'%(len(df1.loc[both_etd_mask, bp_range]), normalorange_hex))\n",
    "        # GlycanSource B+P, B/P: deep colors (c7-c8)\n",
    "        df1.loc[b_glycansource_mask, bp_range] = c7\n",
    "        print('%s rows will be colored dark green (%s).'%(len(df1.loc[b_glycansource_mask, bp_range]), darkgreen_hex))\n",
    "        df1.loc[p_glycansource_mask, bp_range] = c8\n",
    "        print('%s rows will be colored dark blue (%s).'%(len(df1.loc[p_glycansource_mask, bp_range]), darkblue_hex))\n",
    "        # byos colors (c9-c11)\n",
    "        df1.loc[byos_exclusiveOr_mask, bb_range] = c9\n",
    "        print('%s rows will be colored light pink (%s).'%(len(df1.loc[byos_exclusiveOr_mask, bb_range]), lightpink_hex))\n",
    "        df1.loc[byos_and_mask, bb_range] = c10\n",
    "        print('%s rows will be colored deep pink (%s).'%(len(df1.loc[byos_and_mask, bb_range]), deeppink_hex))\n",
    "        df1.loc[byos_bothsame_mask, bb_range] = c11\n",
    "        print('%s rows will be colored yellow (%s).'%(len(df1.loc[byos_bothsame_mask, bb_range]), yellow_hex))\n",
    "        \n",
    "        bp_white = len(df1) - (len(df1.loc[b_hcd_mask, bp_range]) + len(df1.loc[p_hcd_mask, bp_range]) \\\n",
    "                          + len(df1.loc[both_hcd_mask, bp_range]) + len(df1.loc[b_etd_mask, bp_range]) + len(df1.loc[p_etd_mask, bp_range]) \\\n",
    "                          + len(df1.loc[both_etd_mask, bp_range]))\n",
    "        bb_white = len(df1) - (len(df1.loc[byos_exclusiveOr_mask, bb_range]) + len(df1.loc[byos_and_mask, bb_range]) + len(df1.loc[byos_bothsame_mask, bb_range]))\n",
    "        print('%s rows will be colorless in byonic & pglyco data.'%bp_white)\n",
    "        print('%s rows will be colorless in byos data (absent data in certain scans).'%bb_white)\n",
    "        return df1\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile != '': # byonic + pglyco\n",
    "        # byonic & pglyco colors\n",
    "        # HCD: light colors\n",
    "        c1 = 'background-color: %s'%lightgreen_hex \n",
    "        c2 = 'background-color: %s'%lightblue_hex \n",
    "        c3 = 'background-color: %s'%lightorange_hex \n",
    "        # ETD: normal colors\n",
    "        c4 = 'background-color: %s'%normalgreen_hex \n",
    "        c5 = 'background-color: %s'%normalblue_hex \n",
    "        c6 = 'background-color: %s'%normalorange_hex \n",
    "        # GlycanSource B+P, B/P: deep colors\n",
    "        c7 = 'background-color: %s'%darkgreen_hex \n",
    "        c8 = 'background-color: %s'%darkblue_hex\n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns) \n",
    "        # byonic & pglyco coloring range\n",
    "        bp_range = [col for col in df1.columns.tolist() if '[Byonic]' in col or '[pGlyco]' in col]\n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[b_hcd_mask, bp_range] = c1\n",
    "        print('<Color Summary>\\n%s rows will be colored light green (%s).'%(len(df1.loc[b_hcd_mask, bp_range]), lightgreen_hex))\n",
    "        df1.loc[p_hcd_mask, bp_range] = c2 \n",
    "        print('%s rows will be colored light blue (%s).'%(len(df1.loc[p_hcd_mask, bp_range]), lightblue_hex))\n",
    "        df1.loc[both_hcd_mask, bp_range] = c3\n",
    "        print('%s rows will be colored light orange (%s).'%(len(df1.loc[both_hcd_mask, bp_range]), lightorange_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[b_etd_mask, bp_range] = c4\n",
    "        print('%s rows will be colored green (%s).'%(len(df1.loc[b_etd_mask, bp_range]), normalgreen_hex))\n",
    "        df1.loc[p_etd_mask, bp_range] = c5\n",
    "        print('%s rows will be colored blue (%s).'%(len(df1.loc[p_etd_mask, bp_range]), normalblue_hex))\n",
    "        df1.loc[both_etd_mask, bp_range] = c6\n",
    "        print('%s rows will be colored orange (%s).'%(len(df1.loc[both_etd_mask, bp_range]), normalorange_hex))\n",
    "        # GlycanSource B+P, B/P: deep colors (c7-c8)\n",
    "        df1.loc[b_glycansource_mask, bp_range] = c7\n",
    "        print('%s rows will be colored dark green (%s).'%(len(df1.loc[b_glycansource_mask, bp_range]), darkgreen_hex))\n",
    "        df1.loc[p_glycansource_mask, bp_range] = c8\n",
    "        print('%s rows will be colored dark blue (%s).'%(len(df1.loc[p_glycansource_mask, bp_range]), darkblue_hex))\n",
    "        \n",
    "        bp_white = len(df1) - (len(df1.loc[b_hcd_mask, bp_range]) + len(df1.loc[p_hcd_mask, bp_range]) \\\n",
    "                          + len(df1.loc[both_hcd_mask, bp_range]) + len(df1.loc[b_etd_mask, bp_range]) + len(df1.loc[p_etd_mask, bp_range]) \\\n",
    "                          + len(df1.loc[both_etd_mask, bp_range]))\n",
    "        print('%s rows will be colorless in byonic & pglyco data.'%bp_white)\n",
    "        return df1\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile == '': # only byonic\n",
    "        # byonic colors\n",
    "        # HCD: light colors\n",
    "        c1 = 'background-color: %s'%lightgreen_hex\n",
    "        # ETD: normal colors\n",
    "        c4 = 'background-color: %s'%normalgreen_hex\n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns) \n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[b_hcd_mask, :] = c1\n",
    "        print('<Color Summary>\\n%s rows will be colored light green (%s).'%(len(df1.loc[b_hcd_mask, :]), lightgreen_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[b_etd_mask, :] = c4\n",
    "        print('%s rows will be colored green (%s).'%(len(df1.loc[b_etd_mask, :]), normalgreen_hex))\n",
    "        \n",
    "        bp_white = len(df1) - (len(df1.loc[b_hcd_mask, :]) + len(df1.loc[b_etd_mask, :]))\n",
    "        print('%s rows will be colorless in byonic data.'%bp_white)\n",
    "        return df1\n",
    "    elif byonicfile == '' and byosfile == '' and pglycofile != '': # only pglyco\n",
    "        # pglyco colors\n",
    "        # HCD: light colors\n",
    "        c2 = 'background-color: %s'%lightblue_hex\n",
    "        # ETD: normal colors\n",
    "        c5 = 'background-color: %s'%normalblue_hex\n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns) \n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[p_hcd_mask, :] = c2 \n",
    "        print('%s rows will be colored light blue (%s).'%(len(df1.loc[p_hcd_mask, :]), lightblue_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[p_etd_mask, :] = c5\n",
    "        print('%s rows will be colored blue (%s).'%(len(df1.loc[p_etd_mask, :]), normalblue_hex))\n",
    "        \n",
    "        bp_white = len(df1) - (len(df1.loc[p_hcd_mask, :]) + len(df1.loc[p_etd_mask, :]))\n",
    "        print('%s rows will be colorless in byonic & pglyco data.'%bp_white)\n",
    "        return df1\n",
    "    elif byonicfile != '' and byosfile != '' and pglycofile == '': # byonic + byos\n",
    "        # byonic colors\n",
    "        # HCD: light colors\n",
    "        c1 = 'background-color: %s'%lightgreen_hex\n",
    "        # ETD: normal colors\n",
    "        c4 = 'background-color: %s'%normalgreen_hex\n",
    "        # byos colors\n",
    "        c9 = 'background-color: %s'%lightpink_hex \n",
    "        c10 = 'background-color: %s'%deeppink_hex\n",
    "        c11 = 'background-color: %s'%yellow_hex\n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns)    \n",
    "        # byonic & byos coloring range\n",
    "        bb_range = [col for col in df1.columns.tolist() if '[Byos]' in col]\n",
    "        # byonic & pglyco coloring range\n",
    "        bp_range = [col for col in df1.columns.tolist() if '[Byonic]' in col]\n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[b_hcd_mask, bp_range] = c1\n",
    "        print('<Color Summary>\\n%s rows will be colored light green (%s).'%(len(df1.loc[b_hcd_mask, bp_range]), lightgreen_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[b_etd_mask, bp_range] = c4\n",
    "        print('%s rows will be colored green (%s).'%(len(df1.loc[b_etd_mask, bp_range]), normalgreen_hex))\n",
    "        # byos colors (c9-c11)\n",
    "        df1.loc[byos_exclusiveOr_mask, bb_range] = c9\n",
    "        print('%s rows will be colored light pink (%s).'%(len(df1.loc[byos_exclusiveOr_mask, bb_range]), lightpink_hex))\n",
    "        df1.loc[byos_and_mask, bb_range] = c10\n",
    "        print('%s rows will be colored deep pink (%s).'%(len(df1.loc[byos_and_mask, bb_range]), deeppink_hex))\n",
    "        df1.loc[byos_bothsame_mask, bb_range] = c11\n",
    "        print('%s rows will be colored yellow (%s).'%(len(df1.loc[byos_bothsame_mask, bb_range]), yellow_hex))\n",
    "        bp_white = len(df1) - (len(df1.loc[b_hcd_mask, bp_range]) + len(df1.loc[b_etd_mask, bp_range]))\n",
    "        bb_white = len(df1) - (len(df1.loc[byos_exclusiveOr_mask, bb_range]) + len(df1.loc[byos_and_mask, bb_range]) + len(df1.loc[byos_bothsame_mask, bb_range]))\n",
    "        print('%s rows will be colorless in byonic & pglyco data.'%bp_white)\n",
    "        print('%s rows will be colorless in byos data (absent data in certain scans).'%bb_white)\n",
    "        return df1\n",
    "\n",
    "def v3(df): # for v3\n",
    "    n = [int(lst[0]) if lst!=[] else 0 for lst in df['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "    h = [int(lst[0]) if lst!=[] else 0 for lst in df['Glycans ↓'].str.findall(r'Hex\\((\\d+)\\)').tolist()]\n",
    "    nxhy = [(n[i], h[i]) for i in range(len(n))]\n",
    "    # nxhy_fix = ['N(%s)'%(t[0]) if t[0]!=2 else 'N(2)H(5) ↓' if t[0]==2 and t[1]<=5 else 'N(2)H(9) ↑' if t[0]==2 and t[1]>=9 else 'N(%s)H(%s)'%(t[0], t[1]) for t in nxhy]\n",
    "    nxhy_fix = ['N(2)H(5) ↓' if t[0]==2 and t[1]<=5 else 'N(2)H(9) ↑' if t[0]==2 and t[1]>=9 else 'N(%s)H(%s)'%(t[0], t[1]) if t[0]==2 and 5<t[1]<9 else 'N(%s)'%(t[0]) for t in nxhy]\n",
    "    df['N(x)H(y)'] = nxhy_fix\n",
    "    nxhy_fix_order = sorted(list(set(nxhy_fix)))\n",
    "    nxhy_fix_order = sorted(nxhy_fix_order, key=lambda x: int(re.findall(r'[0-9]+', x)[0]))\n",
    "    return df, nxhy_fix_order\n",
    "\n",
    "def v4(df): # for v4 (add ' ' to align hexnac number)\n",
    "    f = [int(lst[0]) if lst!=[] else 0 for lst in df['Glycans ↓'].str.findall(r'Fuc\\((\\d+)\\)').tolist()]\n",
    "    n = [int(lst[0]) if lst!=[] else 0 for lst in df['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "    h = [int(lst[0]) if lst!=[] else 0 for lst in df['Glycans ↓'].str.findall(r'Hex\\((\\d+)\\)').tolist()]\n",
    "    fnxhy = [(f[i], n[i], h[i]) for i in range(len(n))]\n",
    "    # fnxhy_fix = [' N(%s)'%(t[1]) if t[1]!=2 and t[0]==0 else ' N(2)H(5) ↓' if t[1]==2 and t[2]<=5 and t[0]==0 else ' N(2)H(9) ↑' if t[1]==2 and t[2]>=9 and t[0]==0 else ' N(%s)H(%s)'%(t[1], t[2]) if t[1]==2 and t[0]==0 else 'FN(%s)'%(t[1]) for t in fnxhy]\n",
    "    fnxhy_fix = [' N(2)H(5) ↓' if t[1]==2 and t[2]<=5 and t[0]==0 else ' N(2)H(9) ↑' if t[1]==2 and t[2]>=9 and t[0]==0 else ' N(%s)H(%s)'%(t[1], t[2]) if t[1]==2 and 5<t[2]<9 and t[0]==0 else ' N(%s)'%(t[1]) if t[1]!=2 and t[0]==0 else 'FN(%s)'%(t[1]) for t in fnxhy]\n",
    "    df['(F)N(x)H(y)'] = fnxhy_fix\n",
    "    fnxhy_fix_order = sorted(list(set(fnxhy_fix)))\n",
    "    fnxhy_fix_order = sorted(fnxhy_fix_order, key=lambda x: int(re.findall(r'[0-9]+', x)[0]))\n",
    "    return df, fnxhy_fix_order\n",
    "\n",
    "# PLOTTING FUNC\n",
    "def plot_clustered_stacked(dfall, nsum, labels=None, title='', neugc_exist=None, detailedHighMan=False, fucosylation=False, hybrid=colorHybrid, tickW=2, tickL=15, spineW=2, xlabelsize=15, ticklabelsize=15, xlabel_rotation=90, xlabelpad=5, legend_fontsize=15, legend_handleL=3, hatch_lineW=1, bar_labelpad=0, bar_labelfontsize=7):\n",
    "    # NOTE THE DEFAULT STYLE OF THIS FUNC IS V1/V2 (V1: original Yu-Chun version, V2: original Yu-Chun version, V3: detailedHighMan=True,fucosylation=False, hybrid=TorF(color or not) / V4: detailedHighMan=True,fucosylation=True, hybrid=TorF(color or not))\n",
    "    # Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot\n",
    "    # labels is a list of the names of the dataframe, used for the legend\n",
    "    # title is a string for the title of the plot\n",
    "    # H is the hatch used for identification of the different dataframe\n",
    "    n_df = len(dfall)\n",
    "    n_col = len(dfall[0].columns) \n",
    "    n_ind = len(dfall[0].index)\n",
    "    k = dfall[0].columns.tolist()\n",
    "    \n",
    "    # colormaps\n",
    "    gw = plt.cm.gray(np.linspace(0, 1, 5))[-2:]\n",
    "    single_p = plt.cm.Purples(np.linspace(0, 1, 10))[5]\n",
    "    single_b = plt.cm.Blues(np.linspace(0, 1, 10))[5]\n",
    "    single_r = plt.cm.Reds(np.linspace(0, 1, 5))[3]\n",
    "    single_g = plt.cm.Greens(np.linspace(0, 1, 4))[2]\n",
    "\n",
    "    if neugc_exist is None: # this section caters to v1/v3/v4 plotting\n",
    "        # extract the largest n number in col to determine the color dict range\n",
    "        # so that the color-nnumber relation is locked\n",
    "        # n_max = ast.literal_eval(re.findall(r'N\\((\\d+)\\)', k[-1])[0])\n",
    "        n_max = 12 # default to 12 to make sure the gradients are the same across dif plots\n",
    "        b = plt.cm.Blues(np.linspace(0, 1, n_max))[2:] # can be more than N(10) # for v1 & v3\n",
    "        if fucosylation == True: # Reds for fucosylation \n",
    "            fuc = plt.cm.Reds(np.linspace(0, 1, n_max+2))[2:] # just like complex having unlimited range\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if detailedHighMan == True:\n",
    "            highman_g = plt.cm.Greens(np.linspace(0, 1, 8))[2:7] # man5&below-man9&above\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if hybrid == True: \n",
    "            hybrid_y = plt.cm.spring(np.linspace(0, 1, 6))[-1] # only n3(orange). fn3 will be colored red also for clarity\n",
    "            hybrid_b = plt.cm.Blues(np.linspace(0, 1, n_max))[3:] # n3 will be colored orange, so blue starts from n4\n",
    "        else:\n",
    "            pass \n",
    "\n",
    "    # combine them and build a new colormap\n",
    "    if neugc_exist == True: # v2, complex+sia in red\n",
    "        colors = np.vstack((gw, single_g, single_b, single_r)) \n",
    "        # construct 1 to 1 color dict\n",
    "        n = ['N(0)', 'N(1)', 'OligoMannose', 'Complex', 'Complex+Sia'] # limited categories\n",
    "        c = [colors[i] for i in range(len(n))]\n",
    "        nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "    elif neugc_exist == False: # v2, complex+sia in purple\n",
    "        colors = np.vstack((gw, single_g, single_b, single_p)) \n",
    "        # construct 1 to 1 color dict\n",
    "        n = ['N(0)', 'N(1)', 'OligoMannose', 'Complex', 'Complex+Sia'] # limited categories\n",
    "        c = [colors[i] for i in range(len(n))]\n",
    "        nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "    else: # v1/v3/v4\n",
    "        if detailedHighMan == False and fucosylation == False: # v1\n",
    "            colors = np.vstack((gw, single_g, b)) # b is unlimited cmap determined by n_max\n",
    "            # construct 1 to 1 color dict\n",
    "            n = ['N(%s)'%i for i in range(n_max+1)] # e.g. N(0)-N(10), can be more than 11 cols # unlimited categories\n",
    "            c = [colors[i] for i in range(len(n))]\n",
    "            nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "        elif detailedHighMan == True and fucosylation == False: # v3\n",
    "            if hybrid == True:\n",
    "                colors = np.vstack((gw, highman_g, hybrid_y, hybrid_b)) # b is unlimited cmap determined by n_max\n",
    "                # construct 1 to 1 color dict\n",
    "                n = ['N(%s)'%i for i in range(n_max+1) if i!=2]\n",
    "                highman = ['N(2)H(%s) ↓'%(i) if i==5 else 'N(2)H(%s) ↑'%(i) if i==9 else 'N(2)H(%s)'%(i) for i in range(5, 10, 1)]\n",
    "                n[2:2] = highman\n",
    "                c = [colors[i] for i in range(len(n))]\n",
    "                nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "            else:\n",
    "                colors = np.vstack((gw, highman_g, b)) # b is unlimited cmap determined by n_max\n",
    "                # construct 1 to 1 color dict\n",
    "                n = ['N(%s)'%i for i in range(n_max+1) if i!=2]\n",
    "                highman = ['N(2)H(%s) ↓'%(i) if i==5 else 'N(2)H(%s) ↑'%(i) if i==9 else 'N(2)H(%s)'%(i) for i in range(5, 10, 1)]\n",
    "                n[2:2] = highman\n",
    "                c = [colors[i] for i in range(len(n))]\n",
    "                nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "        elif detailedHighMan == True and fucosylation == True: # v4\n",
    "            if hybrid == True:\n",
    "                colors = np.vstack((gw, highman_g, hybrid_y, hybrid_b, fuc)) # b & cyans are unlimited cmap determined by n_max\n",
    "                # construct 1 to 1 color dict\n",
    "                n = [' N(%s)'%i for i in range(n_max+1) if i!=2]\n",
    "                highman = [' N(2)H(%s) ↓'%(i) if i==5 else ' N(2)H(%s) ↑'%(i) if i==9 else ' N(2)H(%s)'%(i) for i in range(5, 10, 1)]\n",
    "                n[2:2] = highman\n",
    "                # append fucosylation for cyans colormap\n",
    "                f = ['FN(%s)'%i for i in range(1, n_max+1)]\n",
    "                n.extend(f)\n",
    "                c = [colors[i] for i in range(len(n))]\n",
    "                nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "            else:\n",
    "                colors = np.vstack((gw, highman_g, b, fuc)) # b & cyans are unlimited cmap determined by n_max\n",
    "                # construct 1 to 1 color dict\n",
    "                n = [' N(%s)'%i for i in range(n_max+1) if i!=2]\n",
    "                highman = [' N(2)H(%s) ↓'%(i) if i==5 else ' N(2)H(%s) ↑'%(i) if i==9 else ' N(2)H(%s)'%(i) for i in range(5, 10, 1)]\n",
    "                n[2:2] = highman\n",
    "                # append fucosylation for cyans colormap\n",
    "                f = ['FN(%s)'%i for i in range(1, n_max+1)]\n",
    "                n.extend(f)\n",
    "                c = [colors[i] for i in range(len(n))]\n",
    "                nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "\n",
    "    # make tick & spine thick.\n",
    "    fig, axe = plt.subplots()\n",
    "    axes = plt.gca()\n",
    "    axes.xaxis.set_tick_params(width=tickW, length=tickL)\n",
    "    axes.yaxis.set_tick_params(width=tickW, length=tickL)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        axes.spines[axis].set_linewidth(spineW)\n",
    "        \n",
    "    # start plotting\n",
    "    bar_label = [string.ascii_uppercase[i] for i in range(n_df)]\n",
    "    bar_label_cnt = 0\n",
    "    for df in dfall : # for each data frame\n",
    "        if 'norm' in labels[0]: # add edge to the bar\n",
    "            axe = df.plot(kind='bar', stacked=True, ax=axe, legend=False, grid=False, figsize =(20, 10), edgecolor = 'k')  # make bar plots\n",
    "        else: # sum: no edge for clarity\n",
    "            axe = df.plot(kind='bar', stacked=True, ax=axe, legend=False, grid=False, figsize =(20, 10))  # make bar plots\n",
    "    # get the y aixs range\n",
    "    ymin, ymax = axes.get_ylim()\n",
    "    # get the handles we want to modify in each site, h: 44 barcontainers, l: 4 full N(x) cols\n",
    "    h,l = axe.get_legend_handles_labels() \n",
    "    # print('h:%s\\n'%h) 44 <BarContainer object of 29 artists> \n",
    "    for i in range(0, n_df * n_col, n_col): # len(h) = n_col * n_df -> 0, 11, 22, 33\n",
    "        k_cnt = 0 # iterate thru k for rect color fix\n",
    "        for j, pa in enumerate(h[i:i+n_col]): # each pa.patches contains 29 <matplotlib.patches.Rectangle object>\n",
    "            # print('pa.patches:%s\\n'%pa.patches)\n",
    "            rect_cnt = 0\n",
    "            for rect in pa.patches: # each rect here is one single N(X) small rect of one single xicauc(int...etc) big rect. Note this loops thru the small rects spanning dif n-sites (iterate thru 29 small rects)\n",
    "                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))    \n",
    "                rect.set_width(1 / float(n_df + 1))\n",
    "                axe.text(rect.get_x(), nsum[bar_label_cnt][rect_cnt] + bar_labelpad, bar_label[bar_label_cnt], ha='left', va='bottom')\n",
    "                rect.set_facecolor(nc_dict[k[k_cnt]]) # use this to fix rect color & legend\n",
    "                rect_cnt += 1\n",
    "            k_cnt += 1\n",
    "        bar_label_cnt += 1\n",
    "    \n",
    "    axe.tick_params(axis='both', labelsize=ticklabelsize)\n",
    "    axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.)\n",
    "    axe.set_xticklabels(df.index, rotation = xlabel_rotation, fontweight=\"bold\") \n",
    "    axe.set_xlabel(df.index.name, fontweight=\"bold\", fontsize = xlabelsize, labelpad = xlabelpad)\n",
    "    axe.ticklabel_format(axis='y')\n",
    "    axe.yaxis.offsetText.set_fontsize(30)\n",
    "    axe.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "    for label in axe.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    axe.set_title(title)\n",
    "    \n",
    "    # legend properties\n",
    "    params = {'legend.fontsize': legend_fontsize, 'legend.handlelength': legend_handleL, 'hatch.linewidth': hatch_lineW}\n",
    "    legend_properties = {'weight':'bold'}\n",
    "    plt.rcParams.update(params)\n",
    "    \n",
    "    # Add invisible data to add another legend \n",
    "    l1 = axe.legend(h[:n_col], l[:n_col], prop=legend_properties, loc=[1.01, 0.5])\n",
    "    \n",
    "    legend_elements = [] # for df legend (xicauc, int.. are from dif. df) \n",
    "    if labels is not None:      \n",
    "        for i in range(n_df):\n",
    "            label = '%s: %s'%(bar_label[i], labels[i])\n",
    "            each_bullet = Patch(label = label)\n",
    "            legend_elements.append(each_bullet)\n",
    "        plt.legend(handles=legend_elements, handlelength = 0, prop=legend_properties, loc=[1.01, 0.1]) # set handleL=0 to hide Patch\n",
    "    axe.add_artist(l1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def ModifiedGlycanTypeAnalysis(df, glycans_col): # this modified version is only for single sites (from quant)\n",
    "    N = df[glycans_col].str.findall(r'HexNAc\\((\\d+)\\)')\n",
    "    N = [[sum(list(map(int, i)))] if type(i) == list else np.nan for i in N]\n",
    "    df['hexnac'] = N\n",
    "\n",
    "    H = df[glycans_col].str.findall(r'Hex\\((\\d+)\\)')\n",
    "    H = [[sum(list(map(int, i)))] if type(i) == list else np.nan for i in H]\n",
    "    df['hex'] = H\n",
    "\n",
    "    F = df[glycans_col].str.findall(r'Fuc\\((\\d+)\\)')\n",
    "    F = [[sum(list(map(int, i)))] if type(i) == list else np.nan for i in F]\n",
    "    df['fuc'] = F\n",
    "\n",
    "    NA = df[glycans_col].str.findall(r'NeuAc\\((\\d+)\\)')\n",
    "    NA = [[sum(list(map(int, i)))] if type(i) == list else np.nan for i in NA]\n",
    "    df['neuac'] = NA\n",
    "\n",
    "    NG = df[glycans_col].str.findall(r'NeuGc\\((\\d+)\\)')\n",
    "    NG = [[sum(list(map(int, i)))] if type(i) == list else np.nan for i in NG]\n",
    "    df['neugc'] = NG\n",
    "\n",
    "    df['glycancode'] = df['hexnac'] + df['hex'] + df['fuc'] + df['neuac'] + df['neugc']\n",
    "    df.loc[(df[glycans_col] == 'Unoccupied'), 'glycancode'] = 'Unoccupied'\n",
    "\n",
    "    # extract numbers in each glyco composition gp\n",
    "    df['hexnac'] = [i[0] if type(i) == list else i for i in df['hexnac']]\n",
    "    df['hex'] = [i[0] if type(i) == list else i for i in df['hex']]\n",
    "    df['hex-hexnac'] = df['hex']-df['hexnac']\n",
    "    df['fuc'] = [i[0] if type(i) == list else i for i in df['fuc']]\n",
    "    df['neuac'] = [i[0] if type(i) == list else i for i in df['neuac']]\n",
    "    df['neugc'] = [i[0] if type(i) == list else i for i in df['neugc']]\n",
    "\n",
    "    # HIGHMAN (24000~29000)\n",
    "    df.loc[(df['hexnac']==2)&(df['hex']<=9)&(df['hex']>=4), 'GlycanTypeAnalysis'] = 'Man'\n",
    "    df['GlycanTypeAnalysis'] = df['GlycanTypeAnalysis'] + df['hex'].astype('Int64').astype(str)\n",
    "    # ONLY CORE\n",
    "    df.loc[(df['hexnac']==2)&(df['hex']==3), 'GlycanTypeAnalysis'] = 'Only core!'\n",
    "    # THE CORE IS NOT COMPLETE\n",
    "    df.loc[(df['hexnac']<2)|(df['hex']<3), 'GlycanTypeAnalysis'] = 'The core is not complete!' # any one of them is below 23000 composition could happen\n",
    "    # PRECURSOR (>29000)\n",
    "    df.loc[(df['hexnac']==2)&(df['hex']>9), 'GlycanTypeAnalysis'] = 'Potential N-glycan precursor'\n",
    "    # SINGLE COMPLEX & HYBRID (REMEMBER TO CONSIDER FUCOSE)\n",
    "    # single complex no f\n",
    "    df.loc[((df['hexnac']==3)&(df['hex-hexnac']<2)&(df['fuc']==0)), 'GlycanTypeAnalysis'] = 'A1' \n",
    "    df.loc[((df['hexnac']==4)&(df['hex-hexnac']<2)&(df['fuc']==0)), 'GlycanTypeAnalysis'] = 'A2/A1B' \n",
    "    df.loc[((df['hexnac']==5)&(df['hex-hexnac']<2)&(df['fuc']==0)), 'GlycanTypeAnalysis'] = 'A3/A2B' \n",
    "    df.loc[((df['hexnac']>=6)&(df['hex-hexnac']<2)&(df['fuc']==0)), 'GlycanTypeAnalysis'] = 'A4/A3B' \n",
    "    # single complex w/ f \n",
    "    df.loc[((df['hexnac']==3)&(df['hex-hexnac']<2)&(df['fuc']!=0)), 'GlycanTypeAnalysis'] = 'FA1' \n",
    "    df.loc[((df['hexnac']==4)&(df['hex-hexnac']<2)&(df['fuc']!=0)), 'GlycanTypeAnalysis'] = 'FA2/FA1B' \n",
    "    df.loc[((df['hexnac']==5)&(df['hex-hexnac']<2)&(df['fuc']!=0)), 'GlycanTypeAnalysis'] = 'FA3/FA2B' \n",
    "    df.loc[((df['hexnac']>=6)&(df['hex-hexnac']<2)&(df['fuc']!=0)), 'GlycanTypeAnalysis'] = 'FA4/FA3B' \n",
    "    # single hybrid no f\n",
    "    df.loc[((df['hexnac']>=3)&(df['hex-hexnac']>=2)&(df['fuc']==0)), 'GlycanTypeAnalysis'] = 'Hybrid' \n",
    "    # single hybrid w/ f\n",
    "    df.loc[((df['hexnac']>=3)&(df['hex-hexnac']>=2)&(df['fuc']!=0)), 'GlycanTypeAnalysis'] = 'Fhybrid' \n",
    "    # UNOCCUPIED\n",
    "    df.loc[(df[glycans_col]=='Unoccupied'), 'GlycanTypeAnalysis'] = 'Unoccupied'\n",
    "    # DROP REDUNDANT COLS\n",
    "    df = df.drop(['glycancode', 'hexnac', 'hex', 'fuc', 'neuac', 'neugc', 'hex-hexnac'], axis = 1) \n",
    "    # MOVE RESULT\n",
    "    move_df(df, 'GlycanTypeAnalysis', glycans_col)\n",
    "    # APPLY 4 MAJOR CLASSES (HIGHMAN/HYBRID/COMPLEX/UNOCCUPIED) BASED ON THE DETAILED GLYCAN TYPE ANALYSIS ABOVE\n",
    "    # delete man4 & below-core structure (just like danny's version of bar/pie charts)\n",
    "    df = df.loc[(df['GlycanTypeAnalysis']!='Only core!')&(df['GlycanTypeAnalysis']!='The core is not complete!')&(df['GlycanTypeAnalysis']!='Potential N-glycan precursor')&(df['GlycanTypeAnalysis']!='Man4')]\n",
    "    df.loc[(df['GlycanTypeAnalysis'].str.contains('Man')),'Classes'] = 'HighMannose'\n",
    "    df.loc[(df['GlycanTypeAnalysis'].str.contains('hybrid', case=False)),'Classes'] = 'Hybrid'\n",
    "    df.loc[(df['GlycanTypeAnalysis'].str.contains('A|B')),'Classes'] = 'Complex'\n",
    "    df.loc[(df['GlycanTypeAnalysis'].str.contains('Unoccupied')),'Classes'] = 'Unoccupied'\n",
    "    return df\n",
    "\n",
    "def normalizer(df, site_col): \n",
    "    # calculate the sum within each n-site, then normalize xicauc/ int/ mono/ iso by these sum\n",
    "    if \"sumpersite_xicauc\" in df.columns.tolist() and \"sumpersite_int\" in df.columns.tolist():\n",
    "        df['sumpersite_xicauc'] = df.groupby(site_col)['e_sum_XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        df['sumpersite_int'] = df.groupby(site_col)['f_sum_Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        # change the real absent data back to -1 (also make sure divide by 0 won't appen)\n",
    "        df.loc[df['a_norm_XIC\\r\\nAUC[Byos]'] == -1, ['sumpersite_xicauc', 'sumpersite_int']] = -1 \n",
    "        # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "        df['a_norm_XIC\\r\\nAUC[Byos]'] = df['e_sum_XIC\\r\\nAUC[Byos]']/df['sumpersite_xicauc']\n",
    "        df['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = df['f_sum_Apex Int.\\r\\n(Posit)[Byos]']/df['sumpersite_int']\n",
    "        # change the real absent data back to -1\n",
    "        df.loc[df['sumpersite_xicauc'] == -1, ['a_norm_XIC\\r\\nAUC[Byos]']] = -1\n",
    "        df.loc[df['sumpersite_int'] == -1, ['b_norm_Apex Int.\\r\\n(Posit)[Byos]']] = -1\n",
    "        # clean off cols\n",
    "        df = df.drop(['sumpersite_xicauc', 'sumpersite_int'], axis=1)\n",
    "    if \"sumpersite_mono\" in df.columns.tolist() and \"sumpersite_iso\" in df.columns.tolist():\n",
    "        df['sumpersite_mono'] = df.groupby(site_col)['g_sum_MonoArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        df['sumpersite_iso'] = df.groupby(site_col)['h_sum_IsotopeArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        # change the real absent data back to -1 (also make sure divide by 0 won't appen)\n",
    "        df.loc[df['c_norm_MonoArea[pGlyco]'] == -1, ['sumpersite_mono', 'sumpersite_iso']] = -1\n",
    "        # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "        df['c_norm_MonoArea[pGlyco]'] = df['g_sum_MonoArea[pGlyco]']/df['sumpersite_mono']\n",
    "        df['d_norm_IsotopeArea[pGlyco]'] = df['h_sum_IsotopeArea[pGlyco]']/df['sumpersite_iso']\n",
    "        # change the real absent data back to -1\n",
    "        df.loc[df['sumpersite_mono'] == -1, ['c_norm_MonoArea[pGlyco]']] = -1\n",
    "        df.loc[df['sumpersite_iso'] == -1, ['d_norm_IsotopeArea[pGlyco]']] = -1\n",
    "        # clean off cols\n",
    "        df = df.drop(['sumpersite_mono', 'sumpersite_iso'], axis=1)\n",
    "    # # change the real absent data back to -1 (also make sure divide by 0 won't appen)\n",
    "    # df.loc[df['c_norm_MonoArea[pGlyco]'] == -1, ['sumpersite_mono', 'sumpersite_iso']] = -1\n",
    "    # df.loc[df['a_norm_XIC\\r\\nAUC[Byos]'] == -1, ['sumpersite_xicauc', 'sumpersite_int']] = -1 \n",
    "    # # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "    # df['a_norm_XIC\\r\\nAUC[Byos]'] = df['e_sum_XIC\\r\\nAUC[Byos]']/df['sumpersite_xicauc']\n",
    "    # df['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = df['f_sum_Apex Int.\\r\\n(Posit)[Byos]']/df['sumpersite_int']\n",
    "    # df['c_norm_MonoArea[pGlyco]'] = df['g_sum_MonoArea[pGlyco]']/df['sumpersite_mono']\n",
    "    # df['d_norm_IsotopeArea[pGlyco]'] = df['h_sum_IsotopeArea[pGlyco]']/df['sumpersite_iso']\n",
    "    # # change the real absent data back to -1\n",
    "    # df.loc[df['sumpersite_xicauc'] == -1, ['a_norm_XIC\\r\\nAUC[Byos]']] = -1\n",
    "    # df.loc[df['sumpersite_int'] == -1, ['b_norm_Apex Int.\\r\\n(Posit)[Byos]']] = -1 \n",
    "    # df.loc[df['sumpersite_mono'] == -1, ['c_norm_MonoArea[pGlyco]']] = -1\n",
    "    # df.loc[df['sumpersite_iso'] == -1, ['d_norm_IsotopeArea[pGlyco]']] = -1    \n",
    "    # clean off cols\n",
    "    # df = df.drop(['sumpersite_xicauc', 'sumpersite_int', 'sumpersite_mono', 'sumpersite_iso'], axis=1)\n",
    "    return df\n",
    "\n",
    "def findMajorClass(df, site_col, glycan_col): # select the major class from highman/hybrid/complex/unoccupied \n",
    "    # REMEMBER TO SWITCH TO ISOTOPE AREA IF XICAUC ARE ALL -1 (MISSING DATA)\n",
    "    # return a df only w/ major class data within each nsite\n",
    "    if \"a_norm_XIC\\r\\nAUC[Byos]\" in df.columns.tolist(): \n",
    "        df['xicauc_class_sum'] = df.groupby([site_col, 'Classes'])['a_norm_XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        df.loc[(df['xicauc_class_sum']!=0), 'mix_quant_sum'] = df['xicauc_class_sum']\n",
    "        if \"d_norm_IsotopeArea[pGlyco]\" in df.columns.tolist(): # both are present. But pglyco can find sites that are not found by byonic\n",
    "            df['isotope_class_sum'] = df.groupby([site_col, 'Classes'])['d_norm_IsotopeArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "            df.loc[(df['xicauc_class_sum']==0), 'mix_quant_sum'] = df['isotope_class_sum']\n",
    "    if \"d_norm_IsotopeArea[pGlyco]\" in df.columns.tolist() and \"a_norm_XIC\\r\\nAUC[Byos]\" not in df.columns.tolist(): # only pglyco \n",
    "        df['isotope_class_sum'] = df.groupby([site_col, 'Classes'])['d_norm_IsotopeArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        df.loc[(df['isotope_class_sum']!=0), 'mix_quant_sum'] = df['isotope_class_sum']\n",
    "    # df.loc[(df['xicauc_class_sum']!=0), 'mix_quant_sum'] = df['xicauc_class_sum']\n",
    "    # df.loc[(df['xicauc_class_sum']==0), 'mix_quant_sum'] = df['isotope_class_sum']\n",
    "    if \"xicauc_class_sum\" in df.columns.tolist():\n",
    "        df = df.drop(['xicauc_class_sum'], axis=1)\n",
    "    if \"isotope_class_sum\" in df.columns.tolist():\n",
    "        df = df.drop(['isotope_class_sum'], axis=1)\n",
    "    major_class = df.loc[df.groupby([site_col])['mix_quant_sum'].idxmax()]['Classes'].tolist()\n",
    "    site = sorted(list(set(df[site_col].tolist())))\n",
    "    \n",
    "    major_class_cnt = 0\n",
    "    for each_site in site:\n",
    "        df.loc[(df[site_col]==each_site)&(df['Classes']==major_class[major_class_cnt]), 'mkr'] = 'pass'\n",
    "        major_class_cnt += 1\n",
    "\n",
    "    df = df.loc[(df['mkr']=='pass')].drop(['mkr', 'mix_quant_sum', 'Classes'], axis=1)\n",
    "    return df\n",
    "\n",
    "# scantime grouping function\n",
    "def ScantimeGp(df, gp_by = [], score_col = '', rt_col = '', software = '', purpose = ''):\n",
    "    # copy df to avoid altering df info\n",
    "    mock_df = df.copy()\n",
    "    \n",
    "    rnd = 1\n",
    "    # record original cols\n",
    "    col = mock_df.columns.tolist()\n",
    "    # start grouping\n",
    "    # 1st run\n",
    "    mock_df['to_subtract1'] = mock_df.loc[(mock_df.groupby(gp_by)[score_col].idxmax()), rt_col]\n",
    "    mock_df['to_subtract_fillna1'] = mock_df.groupby(gp_by)['to_subtract1'].transform(lambda x: x.fillna(x.mean()))\n",
    "    mock_df['rt_dif1'] = (mock_df[rt_col] - mock_df['to_subtract_fillna1']).abs()\n",
    "    # if re_dif < 3, then reset the dif to 0\n",
    "    if software == '[Byonic]' and purpose == 'forUnique':\n",
    "        mock_df['rt_dif_reset1'] = ['same1' if dif < unique_byonic_rt else dif for dif in mock_df['rt_dif1']]\n",
    "    elif software == '[pGlyco]' and purpose == 'forUnique':\n",
    "        mock_df['rt_dif_reset1'] = ['same1' if dif < unique_pglyco_rt else dif for dif in mock_df['rt_dif1']]\n",
    "    elif software == '[Byonic]' and purpose == 'forNglyco':\n",
    "        mock_df['rt_dif_reset1'] = ['same1' if dif < nglyco_byonic_rt else dif for dif in mock_df['rt_dif1']]\n",
    "    elif software == '[pGlyco]' and purpose == 'forNglyco':\n",
    "        mock_df['rt_dif_reset1'] = ['same1' if dif < nglyco_pglyco_rt else dif for dif in mock_df['rt_dif1']]\n",
    "    rnd += 1\n",
    "\n",
    "    while mock_df[mock_df.columns.tolist()[-1]].apply(lambda x: isinstance(x, float)).sum() != 0:\n",
    "        mock_df['to_subtract%s'%rnd] = mock_df.loc[(mock_df.loc[(mock_df['rt_dif_reset%s'%(rnd-1)]!='same%s'%(rnd-1))&(mock_df['rt_dif_reset%s'%(rnd-1)]!='')].groupby(gp_by)[score_col].idxmax()), rt_col]\n",
    "        mock_df['to_subtract_fillna%s'%rnd] = mock_df.loc[(mock_df['rt_dif_reset%s'%(rnd-1)]!='same%s'%(rnd-1))&(mock_df['rt_dif_reset%s'%(rnd-1)]!='')].groupby(gp_by)['to_subtract%s'%rnd].transform(lambda x: x.fillna(x.mean()))\n",
    "        mock_df['rt_dif%s'%rnd] = (mock_df[rt_col] - mock_df['to_subtract_fillna%s'%rnd]).abs()\n",
    "\n",
    "        if software == '[Byonic]' and purpose == 'forUnique':\n",
    "            mock_df['rt_dif_reset%s'%rnd] = ['same%s'%rnd if dif < unique_byonic_rt else dif for dif in mock_df['rt_dif%s'%rnd]]\n",
    "        elif software == '[pGlyco]' and purpose == 'forUnique':\n",
    "            mock_df['rt_dif_reset%s'%rnd] = ['same%s'%rnd if dif < unique_pglyco_rt else dif for dif in mock_df['rt_dif%s'%rnd]]\n",
    "        elif software == '[Byonic]' and purpose == 'forNglyco':\n",
    "            mock_df['rt_dif_reset%s'%rnd] = ['same%s'%rnd if dif < nglyco_byonic_rt else dif for dif in mock_df['rt_dif%s'%rnd]]\n",
    "        elif software == '[pGlyco]' and purpose == 'forNglyco':\n",
    "            mock_df['rt_dif_reset%s'%rnd] = ['same%s'%rnd if dif < nglyco_pglyco_rt else dif for dif in mock_df['rt_dif%s'%rnd]]\n",
    "            \n",
    "        mock_df['rt_dif_reset%s'%rnd] = mock_df['rt_dif_reset%s'%rnd].fillna('')\n",
    "        rnd += 1\n",
    "        \n",
    "    for i in range(1, rnd):\n",
    "        mock_df.loc[(mock_df['rt_dif_reset%s'%i].str.contains('same')==True), f'rt_dif_reset_{purpose}{software}'] = mock_df['rt_dif_reset%s'%i]\n",
    "\n",
    "    mock_df = mock_df.loc[:, [c for c in mock_df.columns if c in col]+[f'rt_dif_reset_{purpose}{software}']]\n",
    "\n",
    "    return mock_df\n",
    "\n",
    "# PREPROCESSING FUNCTIONS\n",
    "def pglyco_preprocessor(pglycofile):\n",
    "    if pglycofile != '':\n",
    "        # read in pglyco as df\n",
    "        pglyco_df = pd.read_excel('%s.xlsx'%pglycofile, header = 0)\n",
    "        pglyco_df = pglyco_df.fillna('N/A')\n",
    "        pglyco_df = pglyco_df.sort_values(by=['Scan'])\n",
    "        pglyco_df = pglyco_df.reset_index(drop = True)\n",
    "\n",
    "        # output column name\n",
    "        print('Original pglyco columns:\\n%s\\n'%pglyco_df.columns)\n",
    "\n",
    "        # replace _x000D_ w/ \\r if exists\n",
    "        fixed_colname = [i.replace('_x000D_', '\\r') if '_x000D_' in i else i for i in pglyco_df.columns]\n",
    "        pglyco_df.columns = fixed_colname\n",
    "        print('Fixed pglyco columns:\\n%s\\n'%pglyco_df.columns)\n",
    "\n",
    "        # record original data size\n",
    "        print('Original pglyco data size:\\nrow: %s\\ncol: %s\\n'%(pglyco_df.shape[0], pglyco_df.shape[1]))\n",
    "        \n",
    "        # due to some unknown error in pglyco, we need to reject the rows w/ ETDScan before HCD scan number (because etd should happen after hcd).\n",
    "        if 'ETDScan' in pglyco_df.columns.tolist():\n",
    "            pglyco_df = pglyco_df.loc[(pglyco_df['ETDScan']>pglyco_df['Scan'])^(pglyco_df['ETDScan']==-1)]\n",
    "            \n",
    "        # check if prosites are correct (pglyco might assign wrong nsite due to intrinsic bug)\n",
    "        if seq != '':\n",
    "            # potential nsites\n",
    "            result = findNPosBySequon(seq)\n",
    "            nsite = [t[0] for t in result]\n",
    "            # potential osites\n",
    "            osite = findPotentialOPos(seq)\n",
    "            # find union of n&osites\n",
    "            nosites = list(set.union(set(nsite), set(osite)))\n",
    "            prosite = pglyco_df['ProSites'].tolist()\n",
    "            site_error = np.setdiff1d(prosite,nosites)\n",
    "            if len(site_error)!= 0: # print out wrong site & terminate processing for file checking\n",
    "                sys.exit(f'Wrong N/O site (site: {list(site_error)}) detected! Preprocessing terminated for file checking.\\nPredicted N-sites: {nsite};\\nPredicted O-sites: {osite}')\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # change J back to N as column named peptide(J-->N)\n",
    "        pglyco_df['Peptide'] = pglyco_df['Peptide'].str.replace('J','N')\n",
    "\n",
    "        # analyze sequon in pglyco file\n",
    "        pglyco_sequon = pglyco_df['Peptide'].str.findall('(?i)(N[ARNDBCEQZGHILKMFSTWYV]T)|(N[ARNDBCEQZGHILKMFSTWYV]S)').tolist()\n",
    "        pglyco_sequon_lst = []\n",
    "        for t in pglyco_sequon:\n",
    "            t = str(t)\n",
    "            res = re.findall('[ARNDBCEQZGHILKMFSTWYVP]', t)\n",
    "            res = ''.join(res)\n",
    "            res = textwrap.wrap(res, 3)\n",
    "            if res == []:\n",
    "                pglyco_sequon_lst.append('N/A')\n",
    "            elif len(res) == 1:\n",
    "                pglyco_sequon_lst.append(res[0])\n",
    "            else:\n",
    "                pglyco_sequon_lst.append(res)\n",
    "\n",
    "        pglyco_sequon_lst = [tuple(i) if type(i) == list else i for i in pglyco_sequon_lst]\n",
    "        pglyco_df.insert(pglyco_df.columns.get_loc('Peptide') + 1 , 'Sequon', pglyco_sequon_lst , True)\n",
    "\n",
    "        # extract compenents numbers\n",
    "        pglyco_df['N'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'N\\((\\d+)\\)')]\n",
    "        pglyco_df['H'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'H\\((\\d+)\\)')]\n",
    "        pglyco_df['F'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'F\\((\\d+)\\)')]\n",
    "        pglyco_df['X'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'X\\((\\d+)\\)')]\n",
    "        pglyco_df['A'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'A\\((\\d+)\\)')]\n",
    "        pglyco_df['G'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'G\\((\\d+)\\)')]\n",
    "        pglyco_df['HA'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'HA\\((\\d+)\\)')]\n",
    "        pglyco_df['HS'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'HS\\((\\d+)\\)')]\n",
    "        pglyco_df['MN'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'MN\\((\\d+)\\)')]\n",
    "        pglyco_df['KDN'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'KDN\\((\\d+)\\)')]\n",
    "        pglyco_df['pH'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'pH\\((\\d+)\\)')]\n",
    "        pglyco_df['aH'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'aH\\((\\d+)\\)')]\n",
    "        pglyco_df['PG'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'PG\\((\\d+)\\)')]\n",
    "        pglyco_df['sH'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'sH\\((\\d+)\\)')]\n",
    "        pglyco_df['sN'] = [0 if i==[] else int(i[0]) for i in pglyco_df['GlycanComposition'].str.findall(r'sN\\((\\d+)\\)')]\n",
    "\n",
    "        # add back the modified glycans\n",
    "        pglyco_df['H'] += pglyco_df['aH']\n",
    "        pglyco_df['H'] += pglyco_df['sH']\n",
    "        pglyco_df['H'] += pglyco_df['pH']\n",
    "        pglyco_df['N'] += pglyco_df['sN']\n",
    "        pglyco_df['s(H+N)'] = pglyco_df['sH'] + pglyco_df['sN']\n",
    "\n",
    "        # convert to final symbols (str)\n",
    "        pglyco_df['N'] = ['' if i==0 else 'HexNAc(%s)'%(i) for i in pglyco_df['N']]\n",
    "        pglyco_df['H'] = ['' if i==0 else 'Hex(%s)'%(i) for i in pglyco_df['H']]\n",
    "        pglyco_df['s(H+N)'] = ['' if i==0 else 'SO3(%s)'%(i) for i in pglyco_df['s(H+N)']]\n",
    "        pglyco_df['aH'] = ['' if i==0 else ' %s'%(np.round(17.02654007*i, ModsRoundTo)) for i in pglyco_df['aH']]\n",
    "        pglyco_df['pH'] = ['' if i==0 else 'Phospho(%s)'%(i) for i in pglyco_df['pH']]\n",
    "        pglyco_df['F'] = ['' if i==0 else 'Fuc(%s)'%(i) for i in pglyco_df['F']]\n",
    "        pglyco_df['A'] = ['' if i==0 else 'NeuAc(%s)'%(i) for i in pglyco_df['A']]\n",
    "        pglyco_df['G'] = ['' if i==0 else 'NeuGc(%s)'%(i) for i in pglyco_df['G']]\n",
    "        pglyco_df['X'] = ['' if i==0 else 'Pent(%s)'%(i) for i in pglyco_df['X']]\n",
    "        pglyco_df['HA'] = ['' if i==0 else ' %s'%(np.round(176.032088*i, ModsRoundTo)) for i in pglyco_df['HA']]\n",
    "        pglyco_df['HS'] = ['' if i==0 else ' %s'%(np.round(161.0688002*i, ModsRoundTo)) for i in pglyco_df['HS']]\n",
    "        pglyco_df['MN'] = ['' if i==0 else ' %s'%(np.round(275.1004901*i, ModsRoundTo)) for i in pglyco_df['MN']]\n",
    "        pglyco_df['KDN'] = ['' if i==0 else 'KDN(%s)'%(i) for i in pglyco_df['KDN']]\n",
    "        pglyco_df['PG'] = ['' if i==0 else ' %s'%((299.12296*i, ModsRoundTo)) for i in pglyco_df['PG']]\n",
    "\n",
    "        # combine mods to mimic byonic format\n",
    "        pglyco_df['GlycanComposition_ByonicStyle'] = pglyco_df['N']+pglyco_df['H']+pglyco_df['F']+pglyco_df['X']+pglyco_df['A']+pglyco_df['G']\\\n",
    "                                                +pglyco_df['s(H+N)']+pglyco_df['pH']+pglyco_df['KDN']+pglyco_df['aH']+pglyco_df['HA']+pglyco_df['HS']+pglyco_df['MN']+pglyco_df['PG']\n",
    "\n",
    "        pglyco_df = pglyco_df.drop(['N','H','F','X','A','G','HA','HS','MN','KDN','pH','aH','PG','sH','sN','s(H+N)'], axis=1)\n",
    "        move_df(pglyco_df, 'GlycanComposition_ByonicStyle', 'GlycanComposition')\n",
    "\n",
    "        # if the etdscan is not -1, duplicate the row and change the duplicated scan to etdscan (micmic byonic format)\n",
    "        pglyco_df.insert(pglyco_df.columns.get_loc('Scan') + 1 , 'FragmentType', 'hcd' , True) # insert 'fragment type' col\n",
    "        if 'ETDScan' in pglyco_df.columns.tolist():\n",
    "            row_to_duplicate = pglyco_df[pglyco_df['ETDScan'] != -1].copy() # missing ETDScan in pglyco is represented as -1\n",
    "            row_to_duplicate['FragmentType'] = 'ethcd'\n",
    "            row_to_duplicate['Scan'] = row_to_duplicate['ETDScan']\n",
    "            pglyco_df = pd.concat([pglyco_df, row_to_duplicate]) # duplicate w/ index\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # rounding precursor mz col to the desired decimal\n",
    "        pglyco_df['rounded_PrecursorMZ'] = pglyco_df.round({'PrecursorMZ': RoundTo})['PrecursorMZ']\n",
    "        move_df(pglyco_df, 'rounded_PrecursorMZ', 'PrecursorMZ')\n",
    "\n",
    "        pglyco_df = pglyco_df.sort_values(by = ['Scan']) # sort by scan directly, the duplicated ethcd rows can be separated from hcd rows\n",
    "        print('----- pGlyco data preprocessing completed. -----\\n')\n",
    "        return pglyco_df\n",
    "\n",
    "def byonic_preprocessor(byonicfile):\n",
    "    if byonicfile != '':\n",
    "        byonic_df = pd.read_excel('%s.xlsx'%byonicfile, header = 0)\n",
    "        byonic_df = byonic_df.fillna('N/A')\n",
    "        print('Original byonic columns:\\n%s\\n'%byonic_df.columns)\n",
    "        # replace _x000D_ w/ \\r if exists\n",
    "        fixed_colname = [i.replace('_x000D_', '\\r') if '_x000D_' in i else i for i in byonic_df.columns]\n",
    "        byonic_df.columns = fixed_colname\n",
    "        print('Fixed byonic columns:\\n%s\\n'%byonic_df.columns)\n",
    "        # record original data size\n",
    "        print('Original byonic data size:\\nrow: %s\\ncol: %s\\n'%(byonic_df.shape[0], byonic_df.shape[1]))\n",
    "        # extract 'scan' from 'scan #' in byonic file & add a 'Scan' column\n",
    "        byonic_scan = byonic_df['Scan #'].tolist()\n",
    "        byonic_scan_lst = []\n",
    "        for scan in byonic_scan:\n",
    "            scan = scan.split(' ')[-1].split('=')[-1]\n",
    "            scan = int(scan)\n",
    "            byonic_scan_lst.append(scan)\n",
    "        byonic_df.insert(byonic_df.columns.get_loc('Scan\\r\\nTime') + 1 , 'Scan', byonic_scan_lst , True)\n",
    "        byonic_df = byonic_df.sort_values(by = ['Scan'])\n",
    "        byonic_df = byonic_df.reset_index(drop = True)\n",
    "        # add 'PureSequence' column to byonic file\n",
    "        if 'Sequence\\r\\n(unformatted)' in byonic_df.columns: # deal w/ dif byonic version\n",
    "            byonic_seq = byonic_df['Sequence\\r\\n(unformatted)'].str[2:-2].str.findall('(?i)[-ARNDBCEQZGHILKMFSTWYVP]').tolist()\n",
    "            \n",
    "            new_byonic_seq = []\n",
    "            for lst in byonic_seq:\n",
    "                minus_pos = [m.start(0) for m in re.finditer('[-]', ''.join(lst))]\n",
    "                delete_minus_pos = [i for i in minus_pos if i!=0]\n",
    "                lst = [i for j, i in enumerate(lst) if j not in delete_minus_pos]\n",
    "                new_byonic_seq.append(lst)\n",
    "            \n",
    "            byonic_seq = [''.join(each_pure) for each_pure in new_byonic_seq]\n",
    "            byonic_df.insert(byonic_df.columns.get_loc('Sequence\\r\\n(unformatted)') + 1 , 'PureSequence', byonic_seq , True)\n",
    "            \n",
    "            byonic_seq_forSequonNsite = byonic_df['Sequence\\r\\n(unformatted)'].str.findall('(?i)[-ARNDBCEQZGHILKMFSTWYVP]').tolist()\n",
    "            \n",
    "            new_byonic_seq_forSequonNsite = []\n",
    "            for lst in byonic_seq_forSequonNsite:\n",
    "                minus_pos = [m.start(0) for m in re.finditer('[-]', ''.join(lst))]\n",
    "                delete_minus_pos = [i for i in minus_pos if i!=0]\n",
    "                lst = [i for j, i in enumerate(lst) if j not in delete_minus_pos]\n",
    "                new_byonic_seq_forSequonNsite.append(lst)\n",
    "                \n",
    "            byonic_seq_forSequonNsite = [''.join(each_pure) for each_pure in new_byonic_seq_forSequonNsite]\n",
    "            byonic_seq_forSequonNsite = pd.Series(byonic_seq_forSequonNsite) # preserve aa outside dots\n",
    "        elif 'Sequence' in byonic_df.columns:\n",
    "            byonic_seq = byonic_df['Sequence'].str[2:-2].str.findall('(?i)[-ARNDBCEQZGHILKMFSTWYVP]').tolist()\n",
    "            \n",
    "            new_byonic_seq = []\n",
    "            for lst in byonic_seq:\n",
    "                minus_pos = [m.start(0) for m in re.finditer('[-]', ''.join(lst))]\n",
    "                delete_minus_pos = [i for i in minus_pos if i!=0]\n",
    "                lst = [i for j, i in enumerate(lst) if j not in delete_minus_pos]\n",
    "                new_byonic_seq.append(lst)\n",
    "            \n",
    "            byonic_seq = [''.join(each_pure) for each_pure in new_byonic_seq]\n",
    "            byonic_df.insert(byonic_df.columns.get_loc('Sequence') + 1 , 'PureSequence', byonic_seq , True)\n",
    "            \n",
    "            byonic_seq_forSequonNsite = byonic_df['Sequence'].str.findall('(?i)[-ARNDBCEQZGHILKMFSTWYVP]').tolist()\n",
    "            \n",
    "            new_byonic_seq_forSequonNsite = []\n",
    "            for lst in byonic_seq_forSequonNsite:\n",
    "                minus_pos = [m.start(0) for m in re.finditer('[-]', ''.join(lst))]\n",
    "                delete_minus_pos = [i for i in minus_pos if i!=0]\n",
    "                lst = [i for j, i in enumerate(lst) if j not in delete_minus_pos]\n",
    "                new_byonic_seq_forSequonNsite.append(lst)\n",
    "                \n",
    "            byonic_seq_forSequonNsite = [''.join(each_pure) for each_pure in new_byonic_seq_forSequonNsite]\n",
    "            byonic_seq_forSequonNsite = pd.Series(byonic_seq_forSequonNsite)\n",
    "        else:\n",
    "            sys.exit('Please check if sequence column name has changed. This app will stop.') \n",
    "        # # CHECK IF N GLYCAN IS SEARCHED   \n",
    "        # if sum(byonic_df['Mods\\r\\n(variable)'].str.contains('NGlycan')==True) > 0:   \n",
    "        # add 'Sequon' & 'N-site' column to byonic file\n",
    "        byonic_sequon_lst = []\n",
    "        n_site_lst = []\n",
    "        pureseq_cnt = 0 # this is byonic_seq_forSequonNsite\n",
    "        pos = byonic_df['Pos.'].tolist()\n",
    "        pos_cnt = 0\n",
    "        byonic_sequon = byonic_seq_forSequonNsite.str.findall('(?=((?i)(N[ARNDBCEQZGHILKMFSTWYV]T)|(N[ARNDBCEQZGHILKMFSTWYV]S)))').tolist()\n",
    "        for t in byonic_sequon:\n",
    "            t = [tuple(set(i)) for i in t]\n",
    "            t = str(t)\n",
    "            res = re.findall('(?i)[ARNDBCEQZGHILKMFSTWYVP]', t)\n",
    "            res = ''.join(res)\n",
    "            res = textwrap.wrap(res, 3)\n",
    "            if res == []:\n",
    "                byonic_sequon_lst.append('N/A')\n",
    "                n_site_lst.append('N/A')\n",
    "                pureseq_cnt += 1\n",
    "                pos_cnt += 1\n",
    "            elif len(res) == 1: # single sequon -> single n-site\n",
    "                byonic_sequon_lst.append(res[0])\n",
    "                regex = re.compile(r'(' + '|'.join(res) + r')')\n",
    "                each_n_site_pos = [m.start() for m in regex.finditer(byonic_seq_forSequonNsite[pureseq_cnt])][0]\n",
    "                each_n_site = pos[pos_cnt] -1 + each_n_site_pos # -1 to fix the 'dots problem'\n",
    "                n_site_lst.append(each_n_site)\n",
    "                pureseq_cnt += 1\n",
    "                pos_cnt += 1\n",
    "            else: # non-single sequon\n",
    "                byonic_sequon_lst.append(res)\n",
    "                regex = re.compile(r'(' + '|'.join(res) + r')')\n",
    "                each_n_site_pos = [m.start() for m in regex.finditer(byonic_seq_forSequonNsite[pureseq_cnt], overlapped=True)]\n",
    "                each_n_site = list(pos[pos_cnt] -1 + np.array(each_n_site_pos))\n",
    "                n_site_lst.append(each_n_site)\n",
    "                pureseq_cnt += 1\n",
    "                pos_cnt += 1\n",
    "        # convert lists within list to tuple for later usage ('cos lists are unhashable, which may cause some problems later)\n",
    "        byonic_sequon_lst = [tuple(i) if type(i) == list else i for i in byonic_sequon_lst]\n",
    "        n_site_lst = [tuple(i) if type(i) == list else i for i in n_site_lst]\n",
    "        byonic_df.insert(byonic_df.columns.get_loc('PureSequence') + 1 , 'Sequon', byonic_sequon_lst , True)\n",
    "        byonic_df.insert(0, 'N-site(SequonBased)', n_site_lst , True)\n",
    "        # ONLY FOR HCD//ETD FILES: add N/A col 'Pair' for later modification (pair: cal.m/z same, cal.m same, pureseq same, scan difference <= 5, hcd before ethcd)\n",
    "        if 'ethcd' in byonic_df['Fragment\\r\\nType'].tolist():\n",
    "            byonic_df.insert(byonic_df.columns.get_loc('Scan\\r\\nTime') + 1 , 'Pair', 'N/A' , True)\n",
    "            potential_pair = byonic_df[byonic_df.duplicated(subset=['Calc.\\r\\nm/z', 'Calc.\\r\\nMH', 'PureSequence'], keep=False)].sort_values(['Calc.\\r\\nm/z'])\n",
    "            # print(potential_pair)\n",
    "            mz_gp = sorted(list(set(potential_pair['Calc.\\r\\nm/z'].tolist())))\n",
    "            pair_cnt = 0\n",
    "            all_hcd_ind = []\n",
    "            all_etd_ind = []\n",
    "            for i in mz_gp:\n",
    "                gp = potential_pair[potential_pair['Calc.\\r\\nm/z'] == i][potential_pair.duplicated(subset=['Calc.\\r\\nMH', 'PureSequence'], keep=False)]\n",
    "                gp = gp.sort_values(['Scan'])\n",
    "                # skip the gp w/o ethcd & find pairs: last criterion -> scan dif <= 5\n",
    "                if 'hcd' in gp['Fragment\\r\\nType'].tolist() and 'ethcd' in gp['Fragment\\r\\nType'].tolist():\n",
    "                    # from hcd find the nearest ethcd below\n",
    "                    pair_candidate = gp[(gp['Fragment\\r\\nType'] == 'hcd') & (gp['Fragment\\r\\nType'].shift(-1) == 'ethcd') & (gp['Scan'].shift(-1) - gp['Scan'] <= byonic_scandif)]\n",
    "                    hcd_iloc = [gp.index.get_loc(ind) for ind in pair_candidate.index] # get the positions of the hcd in pairs in gp df\n",
    "                    etd_iloc = list(np.array(hcd_iloc) + 1)\n",
    "                    hcd_ind = pair_candidate.index.tolist()\n",
    "                    etd_ind = [gp.index[i] for i in etd_iloc] \n",
    "                    all_hcd_ind.extend(hcd_ind)\n",
    "                    all_etd_ind.extend(etd_ind)\n",
    "                else:\n",
    "                    pass\n",
    "            all_hcd_ind.sort()\n",
    "            all_etd_ind.sort()\n",
    "            byonic_df['Pair'].iloc[all_hcd_ind] = ['pair%s'%(i+1) for i in range(len(all_hcd_ind))]\n",
    "            byonic_df['Pair'].iloc[all_etd_ind] = ['pair%s'%(i+1) for i in range(len(all_etd_ind))]\n",
    "        else:\n",
    "            pass \n",
    "\n",
    "        if byonic_df['Glycans'].str.contains(r'\\d+\\.\\d+').sum() > 0:\n",
    "\n",
    "            # record the starting cols\n",
    "            ori_col = byonic_df.columns.tolist()\n",
    "\n",
    "            byonic_df['GlycansModNum'] = byonic_df['Glycans'].str.replace('; ', ' ')\n",
    "            byonic_df['GlycansModNum'] = ['N/A' if i==[] else np.array([float(j) for j in i]) if len(i)>1 else float(i[0]) for i in byonic_df['GlycansModNum'].str.findall(r'\\d+\\.\\d+')]\n",
    "            \n",
    "            if mods_name != [] and mods_num != []:\n",
    "                # start finding the possible mods\n",
    "                for num in mods_num:\n",
    "                    byonic_df['/%s'%(get_key(num))] = byonic_df['GlycansModNum'].apply(lambda x: list(x/num) if type(x)==np.ndarray else x/num if type(x)==float else None)\n",
    "                    byonic_df['/%s'%(get_key(num))] = byonic_df['/%s'%(get_key(num))].apply(lambda x: '' if x is not None and type(x)==float and x.is_integer()==False else '%s(%s)'%(get_key(num), int(x)) if x is not None and type(x)==float and x.is_integer()==True else np.char.array(['' if j.is_integer()==False else '%s(%s)'%(get_key(num), int(j)) for j in x]) if x is not None and type(x)==list else '')\n",
    "\n",
    "                byonic_df['final'] = byonic_df[['/%s'%(name) for name in mods_name]].sum(axis=1)\n",
    "            else:\n",
    "                byonic_df['final'] = ''\n",
    "\n",
    "            byonic_df['PureGlycans'] = byonic_df['Glycans'].str.replace(r' \\d+\\.\\d+', '', regex=True).to_frame()\n",
    "            byonic_df['PureGlycans'] = [i[0] if len(i)==1 else np.char.array(i) for i in byonic_df['PureGlycans'].str.split(';')]\n",
    "\n",
    "            byonic_df['FinalGlycans'] = byonic_df['PureGlycans'] + byonic_df['final']\n",
    "            byonic_df['FinalGlycans'] = [';'.join(list(i)) if type(i)==np.chararray else i for i in byonic_df['FinalGlycans']]\n",
    "\n",
    "            # retrieve the mods numbers in glycans if needed\n",
    "            byonic_df['GlycansModNum'] = byonic_df.round({'GlycansModNum': ModsRoundTo})['GlycansModNum'] # round mods numbers for later comparison\n",
    "            byonic_df.loc[(byonic_df['Glycans'].str.contains(r'\\d+\\.\\d+')==True)&(byonic_df['final'].apply(lambda x: len(x)==0 or all(v=='' for v in x))), 'FinalGlycans'] = byonic_df['Glycans']\n",
    "\n",
    "            # round all the remaining mods numbers to 4 decimals in the final glycans col\n",
    "            byonic_df['rounded_GlycansModNum(1)'] = ['' if i==[] else ' '+ np.char.array((np.round(np.array([float(v) for v in i]), ModsRoundTo)).astype(str)) for i in byonic_df['FinalGlycans'].str.findall(r' \\d+\\.\\d+')]\n",
    "            byonic_df.loc[(byonic_df['rounded_GlycansModNum(1)'].apply(lambda x: len(x)!=0)), 'rounded_GlycansModNum(2)'] = byonic_df['PureGlycans'] + byonic_df['rounded_GlycansModNum(1)']\n",
    "            byonic_df.loc[(byonic_df['rounded_GlycansModNum(2)'].isnull()), 'rounded_FinalGlycans'] = byonic_df['FinalGlycans']\n",
    "            byonic_df.loc[~(byonic_df['rounded_GlycansModNum(2)'].isnull()), 'rounded_FinalGlycans'] = byonic_df['rounded_GlycansModNum(2)']\n",
    "            byonic_df['rounded_FinalGlycans'] = ['; '.join(i) if type(i)==np.chararray else i for i in byonic_df['rounded_FinalGlycans']]\n",
    "\n",
    "            # preserve only FinalGlycans & rounded_FinalGlycans\n",
    "            byonic_df = byonic_df[ori_col + ['FinalGlycans', 'rounded_FinalGlycans']] \n",
    "\n",
    "            move_df(byonic_df, 'FinalGlycans', 'Glycans')\n",
    "            move_df(byonic_df, 'rounded_FinalGlycans', 'FinalGlycans')\n",
    "        else:\n",
    "            byonic_df['rounded_FinalGlycans'] = byonic_df['Glycans']\n",
    "            move_df(byonic_df, 'rounded_FinalGlycans', 'Glycans')\n",
    "            \n",
    "        print('----- Byonic data preprocessing completed. -----\\n')\n",
    "        return byonic_df\n",
    "\n",
    "def byos_preprocessor(byosfile):\n",
    "    if byosfile != '':\n",
    "        byos_df = pd.read_excel('%s.xlsx'%byosfile, header = 0)\n",
    "        # output column name\n",
    "        print('Original byos columns:\\n%s\\n'%byos_df.columns)\n",
    "        # replace _x000D_ w/ \\r if exists\n",
    "        fixed_colname = [i.replace('_x000D_', '\\r') if '_x000D_' in i else i for i in byos_df.columns]\n",
    "        byos_df.columns = fixed_colname\n",
    "        print('Fixed byos columns:\\n%s\\n'%byos_df.columns)\n",
    "        # add calc.MH col to the right side of byos calc.M col\n",
    "        byos_df['Calc.MH'] = byos_df['Calc.M'] + 1.0073\n",
    "        # extract needed columns: Scan Number(s)(Posit), MS Alias name, XIC area summed, XIC AUC, Apex Int.(Posit), Calc.M, Sequence\n",
    "        byos_df = byos_df[['Scan Number(s)\\r\\n(Posit)', 'Glycans', 'MS2 Search\\r\\nAlias name', 'XIC area\\r\\nsummed', 'XIC\\r\\nAUC', 'Apex Int.\\r\\n(Posit)', 'Calc.M', 'Calc.MH', 'Sequence']]\n",
    "        byos_df = byos_df.fillna('N/A')\n",
    "        # output extracted column name\n",
    "        print('Extracted byos columns:\\n%s\\n'%byos_df.columns)\n",
    "        # drop the row w/ multiple scan numbers (data type would be str)\n",
    "        byos_df = byos_df[byos_df['Scan Number(s)\\r\\n(Posit)'].apply(lambda x: isinstance(x, int))]\n",
    "        # sort byos by scan\n",
    "        byos_df = byos_df.sort_values(by=['Scan Number(s)\\r\\n(Posit)'])\n",
    "        byos_df = byos_df.reset_index(drop = True)\n",
    "        # add 'PureSequence' col\n",
    "        byos_df['Sequence'] = byos_df['Sequence'].str.upper()\n",
    "        byos_df['PureSequence'] = byos_df['Sequence'].str[2:-2]\n",
    "        # display(HTML(byos_df.to_html()))\n",
    "        print('----- Byos data preprocessing completed. -----\\n')\n",
    "        return byos_df\n",
    "\n",
    "# MAIN PROCESSING FUNC\n",
    "def main():\n",
    "    # TIMESTAMP\n",
    "    start_time = time.time()\n",
    "    # CURRENT DATE\n",
    "    date = datetime.now().strftime('%Y%m%d')\n",
    "    # PREPARE EXPORT FILENAME\n",
    "    filename = export_filename(byonicfile, byosfile, pglycofile)\n",
    "    # FILE PREPROCESSING\n",
    "    byonic_df = byonic_preprocessor(byonicfile)\n",
    "    byos_df =  byos_preprocessor(byosfile)\n",
    "    pglyco_df = pglyco_preprocessor(pglycofile)\n",
    "    # INPUT COMBO CONTROL FLOW\n",
    "    if byonicfile != '' and byosfile != '' and pglycofile != '': # bbp all present\n",
    "        print('----- Start combining Byonic & Byos & pGlyco. -----\\n')\n",
    "        # combined data based on 'Scan'\n",
    "        byonic_scanasid = byonic_df.copy()\n",
    "        new_byonic_col = [n + '[Byonic]' if n != 'Scan' else n for n in byonic_scanasid.columns]\n",
    "        byonic_scanasid.columns = new_byonic_col\n",
    "        pglyco_scanasid = pglyco_df.copy()\n",
    "        new_pglyco_col = [n + '[pGlyco]' if n != 'Scan' else n for n in pglyco_scanasid.columns]\n",
    "        pglyco_scanasid.columns = new_pglyco_col\n",
    "        byos_scanasid = byos_df.copy()\n",
    "        new_byos_col = [n + '[Byos]' if n != 'Scan Number(s)\\r\\n(Posit)' else n for n in byos_scanasid.columns]\n",
    "        byos_scanasid.columns = new_byos_col\n",
    "        byonic_scanasid = byonic_scanasid.set_index('Scan')\n",
    "        pglyco_scanasid = pglyco_scanasid.set_index('Scan')\n",
    "        byos_scanasid = byos_scanasid.set_index('Scan Number(s)\\r\\n(Posit)')\n",
    "        # align scan & concat (all align on row to make row number all the same)\n",
    "        a1, a2 = byonic_scanasid.align(pglyco_scanasid, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        a1, a3 = a1.align(byos_scanasid, join = 'outer', axis = 0) # row: a1 = a2 = a3\n",
    "        a2, a3 = a2.align(byos_scanasid, join = 'outer', axis = 0) # row: a2 = a1 = a3\n",
    "        all_combined_df = pd.concat([a1,a3,a2], axis = 1)\n",
    "        all_combined_df.index.name = 'Scan'\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        all_combined_df = all_combined_df.fillna(-1)\n",
    "        move_df(all_combined_df, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        ## result post-processing \n",
    "        glycansource(all_combined_df, 'Scan')\n",
    "        print('\\nCombined data shape:\\nrow --> %s, column --> %s'%(all_combined_df.shape[0], all_combined_df.shape[1]))\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > BYONIC_SCORE_CUTOFF & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "        byonic_colored_id = list(set(lightgreen_ind + normalgreen_ind + lightorange_ind + normalorange_ind + deepgreen_ind)) # byonic pass threshold (include below-threshold ethcd w/o pair) \n",
    "        byonic_colored_id_for_pairfile = byonic_colored_id.copy()\n",
    "        pglyco_colored_id = list(set(lightblue_ind + normalblue_ind + lightorange_ind + normalorange_ind + deepblue_ind)) # pglyco pass threshold\n",
    "        pglyco_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in pglyco_colored_id]\n",
    "        ## analyze PSM (need to pass threshold)\n",
    "        # need to record the ind of below-threshold ethcd w/o pair in advance (will be excluded later, so we should not count PSM as well)\n",
    "        # so here we are forced to find pair in advance (since we are forced to list psm in all file)\n",
    "        if 'Pair[Byonic]' in all_combined_df.columns.tolist(): # pair is to identify etd with pass-threshold hcd pair for later rescue\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair[Byonic]': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id]\n",
    "            pair_df = pair_df[pair_df['Pair[Byonic]'].str.contains('pair')]\n",
    "#             pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            if 'ethcd' in all_combined_df['Fragment\\r\\nType[Byonic]'].tolist(): \n",
    "                hcd_pair_num = set(pair_df.loc[(pair_df['Fragment\\r\\nType[Byonic]']=='hcd'), 'Pair[Byonic]'].tolist())\n",
    "                pair_df.drop(pair_df[(pair_df['Fragment\\r\\nType[Byonic]']=='ethcd')&(~(pair_df['Pair[Byonic]'].isin(hcd_pair_num)))].index, inplace=True)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if 'ethcd' in all_combined_df['Fragment\\r\\nType[Byonic]'].tolist(): # if etd data is present (i.e. have pair)\n",
    "            byonic_excluded_ethcd_ind =  all_combined_df.loc[((all_combined_df['Fragment\\r\\nType[Byonic]'] == 'ethcd')&((all_combined_df['Score[Byonic]'] <= BYONIC_SCORE_CUTOFF)|(all_combined_df['PEP\\r\\n2D[Byonic]'].abs() >= 0.001))&(~(all_combined_df['Pair[Byonic]'].isin(pair_df['Pair[Byonic]']))))].index.tolist()\n",
    "            byonic_pass_id = [i for i in byonic_colored_id if i not in byonic_excluded_ethcd_ind]\n",
    "            byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_pass_id] \n",
    "        else: # all hcd, all in (cause here all the hcd are above threshold, i.e. all colored)\n",
    "            byonic_pass_id = byonic_colored_id \n",
    "            byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_pass_id] \n",
    "\n",
    "        # using groupby size function to count psm & add psm columns (new criterion: add fragment type, RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif.)\n",
    "        # byonic & byos\n",
    "        all_combined_df = all_combined_df.astype({'N-site(SequonBased)[Byonic]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        b_df_pass = all_combined_df.loc[byonic_pass_id]\n",
    "        b_df_pass_forUnique = ScantimeGp(b_df_pass, gp_by = ['Fragment\\r\\nType[Byonic]', 'N-site(SequonBased)[Byonic]',  'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]'], score_col = 'Score[Byonic]', rt_col = 'Scan\\r\\nTime[Byonic]', software = '[Byonic]', purpose = 'forUnique')\n",
    "        b_df_pass_forNglyco = ScantimeGp(b_df_pass, gp_by = ['N-site(SequonBased)[Byonic]',  'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]'], score_col = 'Score[Byonic]', rt_col = 'Scan\\r\\nTime[Byonic]', software = '[Byonic]', purpose = 'forNglyco')\n",
    "        byonic_psm = b_df_pass_forNglyco.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset_forNglyco[Byonic]'])['N-site(SequonBased)[Byonic]'].transform('size')\n",
    "        \n",
    "        all_combined_df.loc[(byonic_pass_id), 'PSM[Byonic]'] = byonic_psm\n",
    "        move_df(all_combined_df, 'PSM[Byonic]', 'N-site(SequonBased)[Byonic]')\n",
    "        all_combined_df.loc[(byonic_pass_id), 'rt_dif_reset_forUnique[Byonic]'] = b_df_pass_forUnique['rt_dif_reset_forUnique[Byonic]']\n",
    "        all_combined_df.loc[(byonic_pass_id), 'rt_dif_reset_forNglyco[Byonic]'] = b_df_pass_forNglyco['rt_dif_reset_forNglyco[Byonic]']\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == 'N/A'), 'PSM[Byonic]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[byonic_belowthreshold_id, 'PSM[Byonic]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == '-1'), 'PSM[Byonic]'] = -1 # if site is '-1', then psm set to -1\n",
    "        # pglyco\n",
    "        all_combined_df = all_combined_df.astype({'ProSites[pGlyco]': 'int'})\n",
    "        all_combined_df = all_combined_df.astype({'ProSites[pGlyco]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        p_df_pass = all_combined_df.loc[pglyco_colored_id]\n",
    "        p_df_pass_forUnique = ScantimeGp(p_df_pass, gp_by = ['FragmentType[pGlyco]', 'ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]'], score_col = 'PepScore[pGlyco]', rt_col = 'RT[pGlyco]', software = '[pGlyco]', purpose = 'forUnique')\n",
    "        p_df_pass_forNglyco = ScantimeGp(p_df_pass, gp_by = ['ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]'], score_col = 'PepScore[pGlyco]', rt_col = 'RT[pGlyco]', software = '[pGlyco]', purpose = 'forNglyco')\n",
    "        \n",
    "        pglyco_psm = p_df_pass_forNglyco.groupby(['ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]'])['ProSites[pGlyco]'].transform('size')\n",
    "        all_combined_df.loc[(pglyco_colored_id), 'PSM[pGlyco]'] = pglyco_psm\n",
    "        move_df(all_combined_df, 'PSM[pGlyco]', 'ProSites[pGlyco]')\n",
    "        all_combined_df.loc[(pglyco_colored_id), 'rt_dif_reset_forUnique[pGlyco]'] = p_df_pass_forUnique['rt_dif_reset_forUnique[pGlyco]']\n",
    "        all_combined_df.loc[(pglyco_colored_id), 'rt_dif_reset_forNglyco[pGlyco]'] = p_df_pass_forNglyco['rt_dif_reset_forNglyco[pGlyco]']\n",
    "        all_combined_df.loc[(all_combined_df['ProSites[pGlyco]'] == 'N/A'), 'PSM[pGlyco]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[pglyco_belowthreshold_id, 'PSM[pGlyco]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['ProSites[pGlyco]'] == '-1'), 'PSM[pGlyco]'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'rt_dif_reset_forUnique[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]'], axis = 1)\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_All_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "        \n",
    "        if 'Pair[Byonic]' in all_combined_df.columns.tolist(): # pair is to identify etd with pass-threshold hcd pair for later rescue\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair[Byonic]': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id_for_pairfile]\n",
    "            pair_df = pair_df[pair_df['Pair[Byonic]'].str.contains('pair')]\n",
    "#             pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            hcd_pair_num = set(pair_df.loc[(pair_df['Fragment\\r\\nType[Byonic]']=='hcd'), 'Pair[Byonic]'].tolist())\n",
    "            pair_df.drop(pair_df[(pair_df['Fragment\\r\\nType[Byonic]']=='ethcd')&(~(pair_df['Pair[Byonic]'].isin(hcd_pair_num)))].index, inplace=True)\n",
    "            threshold_masks_colorind(pair_df)\n",
    "            print('\\n----- Exporting \"_Pair\" file... This may take some time, please wait. -----\\n')\n",
    "            pair_df.style.apply(bg_color, axis=None).to_excel(f'{date}_Pair_{filename}.xlsx', index = False)  \n",
    "            print('\\n----- \"_Pair\" file exported. -----\\n')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        # extract rows included in colored indices list separately\n",
    "        byonicbyos_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[Byonic]' in col or '[Byos]' in col]\n",
    "        pglyco_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[pGlyco]' in col]\n",
    "        simple_byonicbyos = all_forsimple_df.loc[byonic_pass_id, byonicbyos_col_range] # extract colored (pass threshold) rows - below-threshold ethcd w/o pair\n",
    "        simple_pglyco = all_forsimple_df.loc[pglyco_colored_id, pglyco_col_range] # extract colored (pass threshold) rows\n",
    "        \n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != '-1')] # preserve n/a sites for potential o glycan data in unique\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != 'N/A')&(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != '-1')] # for simplified, n-site must exist\n",
    "        \n",
    "        simple_pglyco_forUnique = simple_pglyco[(simple_pglyco['ProSites[pGlyco]'] != '-1')] # preserve n/a sites for potential o glycan data in unique\n",
    "        simple_pglyco_forNglyco = simple_pglyco[(simple_pglyco['ProSites[pGlyco]'] != 'N/A')&(simple_pglyco['ProSites[pGlyco]'] != '-1')] # for simplified, n-site must exist\n",
    "\n",
    "        # for nglycopep\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.loc[simple_pglyco_forNglyco['FragmentType[pGlyco]'] == 'hcd'] # pglyco etd has the same values as hcd, so only let hcd enter unique file\n",
    "        \n",
    "        # clean data by dropping duplicates        \n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.drop_duplicates().reset_index(drop=True)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        simple_pglyco_forUnique = simple_pglyco_forUnique.drop_duplicates().reset_index(drop=True)\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        # HIGHSCORE SELECTION: get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.groupby(['Fragment\\r\\nType[Byonic]', 'N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset_forUnique[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score[Byonic]'].idxmax()]).reset_index(drop=True)\n",
    "        simple_pglyco_forUnique = simple_pglyco_forUnique.groupby(['FragmentType[pGlyco]', 'ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset_forUnique[pGlyco]'], as_index=False).apply(lambda x: x.loc[x['PepScore[pGlyco]'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset_forNglyco[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score[Byonic]'].idxmax()]).reset_index(drop=True)\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.groupby(['ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]'], as_index=False).apply(lambda x: x.loc[x['PepScore[pGlyco]'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan (for unique)\n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.set_index('Scan')\n",
    "        simple_pglyco_forUnique = simple_pglyco_forUnique.set_index('Scan')\n",
    "        a1, a2 = simple_byonicbyos_forUnique.align(simple_pglyco_forUnique, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        id_df_forUnique = pd.concat([a1,a2], axis = 1)\n",
    "        id_df_forUnique.index.name = 'Scan'\n",
    "        id_df_forUnique.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        id_df_forUnique = id_df_forUnique.fillna(-1)\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df_forUnique['Mods\\r\\n(variable)[Byonic]'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df_forUnique['glycan_mods_sum[Byonic]'] = mods_nglycan_sum\n",
    "        id_df_forUnique['PepMS[Byonic]'] = id_df_forUnique['Calc.\\r\\nMH[Byonic]'] - id_df_forUnique['glycan_mods_sum[Byonic]']\n",
    "        id_df_forUnique.loc[(id_df_forUnique['glycan_mods_sum[Byonic]'] == -1), 'PepMS[Byonic]'] = -1\n",
    "        move_df(id_df_forUnique, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        move_df(id_df_forUnique, 'PepMS[Byonic]', 'Fragment\\r\\nType[Byonic]')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forUnique['N-site(SequonBased)[Byonic]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i and i!='N/A' else i for i in id_df_forUnique['N-site(SequonBased)[Byonic]'].tolist()] # convert str back to int & tuple\n",
    "        id_df_forUnique['ProSites[pGlyco]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i and i!='N/A' else i for i in id_df_forUnique['ProSites[pGlyco]'].tolist()] # convert str back to int & tuple\n",
    "        \n",
    "        id_df_forUnique.loc[(id_df_forUnique['N-site(SequonBased)[Byonic]'] == -1), 'mock_site[Byonic]'] = id_df_forUnique['ProSites[pGlyco]']\n",
    "        id_df_forUnique.loc[(id_df_forUnique['N-site(SequonBased)[Byonic]'] != -1), 'mock_site[Byonic]'] = id_df_forUnique['N-site(SequonBased)[Byonic]']\n",
    "        # drop intermediate cols\n",
    "        id_df_forUnique = id_df_forUnique.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'rt_dif_reset_forUnique[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]', 'glycan_mods_sum[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "        glycansource(id_df_forUnique, 'Scan')\n",
    "        move_df(id_df_forUnique, 'mock_site[Byonic]', 'GlycanSource')\n",
    "        col_order = id_df_forUnique.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Charge[pGlyco]')\n",
    "        print('Done sorting by Charge[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PrecursorMH[pGlyco]')\n",
    "        print('Done sorting by PrecursorMH[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PeptideMH[pGlyco]')\n",
    "        print('Done sorting by PeptideMH[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        print('Done sorting by GlycanComposition_ByonicStyle[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Peptide[pGlyco]')\n",
    "        print('Done sorting by Peptide[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'z[Byonic]')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Calc.\\r\\nMH[Byonic]')\n",
    "        print('Done sorting by Calc.MH[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PepMS[Byonic]')\n",
    "        print('Done sorting by PepMS[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'rounded_FinalGlycans[Byonic]')\n",
    "        print('Done sorting by rounded_FinalGlycans[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PureSequence[Byonic]')\n",
    "        print('Done sorting by PureSequence[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'mock_site[Byonic]')\n",
    "        print('Done sorting by mock_site[Byonic] (added during processing)')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forUnique['rounded_FinalGlycans[Byonic]'] = [int(i) if i == '-1' else i for i in id_df_forUnique['rounded_FinalGlycans[Byonic]']]\n",
    "        id_df_forUnique['GlycanComposition_ByonicStyle[pGlyco]'] = [int(i) if i == '-1' else i for i in id_df_forUnique['GlycanComposition_ByonicStyle[pGlyco]']]\n",
    "        id_df_forUnique = id_df_forUnique[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forUnique)\n",
    "        id_df_forUnique.style.apply(bg_color, axis=None).to_excel(f'{date}_UniquePep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_UniquePep\" file exported. -----\\n')\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan (for nglyco)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.set_index('Scan')\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.set_index('Scan')\n",
    "        a1, a2 = simple_byonicbyos_forNglyco.align(simple_pglyco_forNglyco, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        id_df_forNglyco = pd.concat([a1,a2], axis = 1)\n",
    "        id_df_forNglyco.index.name = 'Scan'\n",
    "        id_df_forNglyco.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        id_df_forNglyco = id_df_forNglyco.fillna(-1)\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df_forNglyco['Mods\\r\\n(variable)[Byonic]'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df_forNglyco['glycan_mods_sum[Byonic]'] = mods_nglycan_sum\n",
    "        id_df_forNglyco['PepMS[Byonic]'] = id_df_forNglyco['Calc.\\r\\nMH[Byonic]'] - id_df_forNglyco['glycan_mods_sum[Byonic]']\n",
    "        id_df_forNglyco.loc[(id_df_forNglyco['glycan_mods_sum[Byonic]'] == -1), 'PepMS[Byonic]'] = -1\n",
    "        move_df(id_df_forNglyco, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        move_df(id_df_forNglyco, 'PepMS[Byonic]', 'Fragment\\r\\nType[Byonic]')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forNglyco['N-site(SequonBased)[Byonic]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df_forNglyco['N-site(SequonBased)[Byonic]'].tolist()] # convert str back to int & tuple\n",
    "        id_df_forNglyco['ProSites[pGlyco]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df_forNglyco['ProSites[pGlyco]'].tolist()] # convert str back to int & tuple\n",
    "\n",
    "        id_df_forNglyco.loc[(id_df_forNglyco['N-site(SequonBased)[Byonic]'] == -1), 'mock_site[Byonic]'] = id_df_forNglyco['ProSites[pGlyco]']\n",
    "        id_df_forNglyco.loc[(id_df_forNglyco['N-site(SequonBased)[Byonic]'] != -1), 'mock_site[Byonic]'] = id_df_forNglyco['N-site(SequonBased)[Byonic]']\n",
    "        # drop intermediate cols\n",
    "        id_df_forNglyco = id_df_forNglyco.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'rt_dif_reset_forUnique[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]', 'glycan_mods_sum[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "        glycansource(id_df_forNglyco, 'Scan')\n",
    "        move_df(id_df_forNglyco, 'mock_site[Byonic]', 'GlycanSource')\n",
    "        col_order = id_df_forNglyco.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Charge[pGlyco]')\n",
    "        print('Done sorting by Charge[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PrecursorMH[pGlyco]')\n",
    "        print('Done sorting by PrecursorMH[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PeptideMH[pGlyco]')\n",
    "        print('Done sorting by PeptideMH[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        print('Done sorting by GlycanComposition_ByonicStyle[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Peptide[pGlyco]')\n",
    "        print('Done sorting by Peptide[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'z[Byonic]')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Calc.\\r\\nMH[Byonic]')\n",
    "        print('Done sorting by Calc.MH[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PepMS[Byonic]')\n",
    "        print('Done sorting by PepMS[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'rounded_FinalGlycans[Byonic]')\n",
    "        print('Done sorting by rounded_FinalGlycans[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PureSequence[Byonic]')\n",
    "        print('Done sorting by PureSequence[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'mock_site[Byonic]')\n",
    "        print('Done sorting by mock_site[Byonic] (added during processing)')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forNglyco['rounded_FinalGlycans[Byonic]'] = [int(i) if i == '-1' else i for i in id_df_forNglyco['rounded_FinalGlycans[Byonic]']]\n",
    "        id_df_forNglyco['GlycanComposition_ByonicStyle[pGlyco]'] = [int(i) if i == '-1' else i for i in id_df_forNglyco['GlycanComposition_ByonicStyle[pGlyco]']]\n",
    "        id_df_forNglyco = id_df_forNglyco[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_NglycoPep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forNglyco)\n",
    "        id_df_forNglyco.style.apply(bg_color, axis=None).to_excel(f'{date}_NglycoPep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_NglycoPep\" file exported. -----\\n')\n",
    "\n",
    "        print('----- Start preparing quantification file of N-glycosylation . -----\\n')\n",
    "        # only single sites for quant (quant_df offers important info. for later multiIndex df construction)\n",
    "        quant = id_df_forNglyco[id_df_forNglyco['N-site(SequonBased)[Byonic]'].apply(lambda x: isinstance(x, int))]\n",
    "        # avoid adding values from below-threshold rows: if deepgreen -> change value to -1, if deepblue -> change value to -1.(-1 to make lambda function easier to write)\n",
    "        threshold_masks_colorind(quant)\n",
    "        quant.loc[deepgreen_ind, ['MonoArea[pGlyco]', 'IsotopeArea[pGlyco]']] = -1\n",
    "        quant.loc[deepblue_ind, ['XIC\\r\\nAUC[Byos]', 'Apex Int.\\r\\n(Posit)[Byos]']] = -1\n",
    "        # calculate the sum within each n-site, then normalize xicauc/ int/ mono/ iso by these sum\n",
    "        quant['sumpersite_xicauc'] = quant.groupby(['N-site(SequonBased)[Byonic]'])['XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        quant['sumpersite_int'] = quant.groupby(['N-site(SequonBased)[Byonic]'])['Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        quant['sumpersite_mono'] = quant.groupby(['ProSites[pGlyco]'])['MonoArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        quant['sumpersite_iso'] = quant.groupby(['ProSites[pGlyco]'])['IsotopeArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        # convert all the 'N/A' in byonic glycans to 'Unoccupied'\n",
    "        quant.loc[(quant['rounded_FinalGlycans[Byonic]'] == 'N/A'), ['rounded_FinalGlycans[Byonic]']] = 'Unoccupied'\n",
    "        # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "        quant['e_sum_XIC\\r\\nAUC[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'rounded_FinalGlycans[Byonic]'])['XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['f_sum_Apex Int.\\r\\n(Posit)[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'rounded_FinalGlycans[Byonic]'])['Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['g_sum_MonoArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['MonoArea[pGlyco]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['h_sum_IsotopeArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['IsotopeArea[pGlyco]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['a_norm_XIC\\r\\nAUC[Byos]'] = quant['e_sum_XIC\\r\\nAUC[Byos]']/quant['sumpersite_xicauc']\n",
    "        quant['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = quant['f_sum_Apex Int.\\r\\n(Posit)[Byos]']/quant['sumpersite_int']\n",
    "        quant['c_norm_MonoArea[pGlyco]'] = quant['g_sum_MonoArea[pGlyco]']/quant['sumpersite_mono']\n",
    "        quant['d_norm_IsotopeArea[pGlyco]'] = quant['h_sum_IsotopeArea[pGlyco]']/quant['sumpersite_iso']\n",
    "        # since it's possible to have real 0 from calculation, change the real absent data back to -1 in sum_ & norm_\n",
    "        quant.loc[quant['MonoArea[pGlyco]'] == -1, ['g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'c_norm_MonoArea[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']] = -1\n",
    "        quant.loc[quant['XIC\\r\\nAUC[Byos]'] == -1, ['e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'a_norm_XIC\\r\\nAUC[Byos]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] = -1 \n",
    "        # quant.to_excel('20210714_quant_debug.xlsx', index = False)\n",
    "        # extract the needed cols only & split byonicbyos/pglyco, drop all -1 rows, glycans as index to outer union concat data again\n",
    "        quant_bb = quant[['GlycanSource', 'N-site(SequonBased)[Byonic]', 'rounded_FinalGlycans[Byonic]', 'MS2 Search\\r\\nAlias name[Byos]', 'e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'a_norm_XIC\\r\\nAUC[Byos]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']].rename(columns={'GlycanSource':'GlycanSource[Byonic]'})\n",
    "        quant_p = quant[['GlycanSource', 'ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]', 'g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'c_norm_MonoArea[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']].rename(columns={'GlycanSource':'GlycanSource[pGlyco]'})\n",
    "        quant_bb = quant_bb.loc[quant_bb['N-site(SequonBased)[Byonic]'] != -1]\n",
    "        quant_p = quant_p.loc[quant_p['ProSites[pGlyco]'] != -1]\n",
    "        quant_bb = quant_bb.set_index('rounded_FinalGlycans[Byonic]')\n",
    "        quant_p = quant_p.set_index('GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        a1, a2 = quant_bb.align(quant_p, join = 'outer', axis = 0) \n",
    "        quant_glycanid = pd.concat([a1,a2], axis = 1)\n",
    "        quant_glycanid.index.name = 'Glycans ↓'\n",
    "        quant_glycanid.reset_index(level=0, inplace=True)\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in quant_glycanid['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        quant_glycanid.insert(0 , 'N(x) ↓', nx , True)\n",
    "        move_df(quant_glycanid, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        quant_glycanid = quant_glycanid.drop('MS2 Search\\r\\nAlias name[Byos]', axis = 1)\n",
    "        # change all nan to blank -1\n",
    "        quant_glycanid = quant_glycanid.fillna(-1)\n",
    "        quant_glycanid = quant_glycanid.drop_duplicates() # remember to drop duplicates after splitting & reconcat df\n",
    "        # generate 5 versions: bp_intersection (both sites are present at the same time <intersection>), bp_union (n site union), only b (xicauc/int), only p (mono/isotope)\n",
    "        ## onlyb\n",
    "        onlyb = quant_glycanid.loc[(quant_glycanid['N-site(SequonBased)[Byonic]'] != -1), [col for col in quant_glycanid.columns.tolist() if 'pGlyco' not in col]]\n",
    "        onlyb_forunion = onlyb.copy().drop_duplicates()\n",
    "        onlyb = onlyb.drop('GlycanSource[Byonic]', axis = 1).drop_duplicates()\n",
    "        # clean off all no data rows\n",
    "        onlyb = onlyb.loc[~((onlyb['e_sum_XIC\\r\\nAUC[Byos]']==-1)&(onlyb['f_sum_Apex Int.\\r\\n(Posit)[Byos]']==-1)&(onlyb['a_norm_XIC\\r\\nAUC[Byos]']==-1)&(onlyb['b_norm_Apex Int.\\r\\n(Posit)[Byos]']==-1))]\n",
    "        nx = list(set(onlyb['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        b_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        ## onlyp\n",
    "        onlyp = quant_glycanid.loc[(quant_glycanid['ProSites[pGlyco]'] != -1), [col for col in quant_glycanid.columns.tolist() if 'Byonic' not in col and 'Byos' not in col]]\n",
    "        onlyp_forunion = onlyp.copy().drop_duplicates()\n",
    "        onlyp = onlyp.drop('GlycanSource[pGlyco]', axis = 1).drop_duplicates()\n",
    "        # clean off all no data rows\n",
    "        onlyp = onlyp.loc[~((onlyp['g_sum_MonoArea[pGlyco]']==-1)&(onlyp['h_sum_IsotopeArea[pGlyco]']==-1)&(onlyp['c_norm_MonoArea[pGlyco]']==-1)&(onlyp['d_norm_IsotopeArea[pGlyco]']==-1))]\n",
    "        nx = list(set(onlyp['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        p_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        ## bp_union\n",
    "        onlyb_union = onlyb_forunion.rename(columns={'N-site(SequonBased)[Byonic]':'N-site(Byonic ∪ pGlyco) →', 'GlycanSource[Byonic]':'GlycanSource'}) \n",
    "        onlyp_union = onlyp_forunion.rename(columns={'ProSites[pGlyco]':'N-site(Byonic ∪ pGlyco) →', 'GlycanSource[pGlyco]':'GlycanSource'}) \n",
    "        a1, a2 = onlyb_union.drop('N(x) ↓', axis = 1).align(onlyp_union.drop('N(x) ↓', axis = 1), join='outer', axis = 1) # align col only\n",
    "        bp_union = pd.concat([a1,a2])\n",
    "        bp_union = bp_union.drop('GlycanSource', axis = 1).drop_duplicates().sort_values('Glycans ↓').reset_index(drop = True).fillna(-1)\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in bp_union['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        bp_union.insert(0 , 'N(x) ↓', nx , True)\n",
    "        nx = list(set(bp_union['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        bp_union_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        ## bp_intersection (ignore glycansource, some glycans will be deleted due to this, so we need to normalize again)\n",
    "        # compare glycans from b/p using quant_glycanid df\n",
    "        bp_inter = quant_glycanid.loc[(quant_glycanid['N-site(SequonBased)[Byonic]']==quant_glycanid['ProSites[pGlyco]'])].drop(['GlycanSource[Byonic]', 'GlycanSource[pGlyco]', 'ProSites[pGlyco]'], axis=1).rename(columns={'N-site(SequonBased)[Byonic]':'N-site(Byonic ∪ pGlyco) →'}).drop_duplicates().reset_index(drop=True)\n",
    "        # bp_inter.to_excel('bp_inter.xlsx', index=False)\n",
    "        # normalize again\n",
    "        # calculate the sum within each n-site, then normalize xicauc/ int/ mono/ iso by these sum\n",
    "        bp_inter['sumpersite_xicauc'] = bp_inter.groupby(['N-site(Byonic ∪ pGlyco) →'])['e_sum_XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        bp_inter['sumpersite_int'] = bp_inter.groupby(['N-site(Byonic ∪ pGlyco) →'])['f_sum_Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        bp_inter['sumpersite_mono'] = bp_inter.groupby(['N-site(Byonic ∪ pGlyco) →'])['g_sum_MonoArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        bp_inter['sumpersite_iso'] = bp_inter.groupby(['N-site(Byonic ∪ pGlyco) →'])['h_sum_IsotopeArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        # change the real absent data back to -1\n",
    "        bp_inter.loc[bp_inter['c_norm_MonoArea[pGlyco]'] == -1, ['sumpersite_mono', 'sumpersite_iso']] = -1\n",
    "        bp_inter.loc[bp_inter['a_norm_XIC\\r\\nAUC[Byos]'] == -1, ['sumpersite_xicauc', 'sumpersite_int']] = -1 \n",
    "        # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "        bp_inter['a_norm_XIC\\r\\nAUC[Byos]'] = bp_inter['e_sum_XIC\\r\\nAUC[Byos]']/bp_inter['sumpersite_xicauc']\n",
    "        bp_inter['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = bp_inter['f_sum_Apex Int.\\r\\n(Posit)[Byos]']/bp_inter['sumpersite_int']\n",
    "        bp_inter['c_norm_MonoArea[pGlyco]'] = bp_inter['g_sum_MonoArea[pGlyco]']/bp_inter['sumpersite_mono']\n",
    "        bp_inter['d_norm_IsotopeArea[pGlyco]'] = bp_inter['h_sum_IsotopeArea[pGlyco]']/bp_inter['sumpersite_iso']\n",
    "        # change the real absent data back to -1\n",
    "        bp_inter.loc[bp_inter['sumpersite_xicauc'] == -1, ['a_norm_XIC\\r\\nAUC[Byos]']] = -1\n",
    "        bp_inter.loc[bp_inter['sumpersite_int'] == -1, ['b_norm_Apex Int.\\r\\n(Posit)[Byos]']] = -1 \n",
    "        bp_inter.loc[bp_inter['sumpersite_mono'] == -1, ['c_norm_MonoArea[pGlyco]']] = -1\n",
    "        bp_inter.loc[bp_inter['sumpersite_iso'] == -1, ['d_norm_IsotopeArea[pGlyco]']] = -1 \n",
    "        # bp_inter.to_excel('bp_inter_norm_test.xlsx', index = False)\n",
    "        \n",
    "        # drop cols & make sure the order of the cols (a-h)\n",
    "        bp_inter = bp_inter.drop(['sumpersite_xicauc', 'sumpersite_int', 'sumpersite_mono', 'sumpersite_iso'], axis=1)\n",
    "        bp_inter = bp_inter[['Glycans ↓', 'N-site(Byonic ∪ pGlyco) →', 'a_norm_XIC\\r\\nAUC[Byos]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]', 'c_norm_MonoArea[pGlyco]', 'd_norm_IsotopeArea[pGlyco]', 'e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']]\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in bp_inter['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        bp_inter.insert(0 , 'N(x) ↓', nx , True)\n",
    "        nx = list(set(bp_inter['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        bp_intersection_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        ## onlyb_top10\n",
    "        onlyb_top10 = onlyb.copy()\n",
    "        # onlyb_top10.to_excel('20210722_onlyb_top10_debug.xlsx', index=False)\n",
    "        # xicauc_top10 = onlyb_top10.groupby('N-site(SequonBased)[Byonic]')['a_norm_XIC\\r\\nAUC[Byos]'].nlargest(topN).droplevel(level = 0).index.tolist()\n",
    "        xicauc_top10 = onlyb_top10.groupby('N-site(SequonBased)[Byonic]').apply(pd.DataFrame.nlargest, n=5, columns='a_norm_XIC\\r\\nAUC[Byos]').droplevel(level=0).index.tolist()\n",
    "        int_top10 = onlyb_top10.groupby('N-site(SequonBased)[Byonic]').apply(pd.DataFrame.nlargest, n=5, columns='b_norm_Apex Int.\\r\\n(Posit)[Byos]').droplevel(level=0).index.tolist()\n",
    "        onlyb_top10.loc[[i for i in onlyb_top10.index.tolist() if i not in xicauc_top10], 'a_norm_XIC\\r\\nAUC[Byos]'] = -1\n",
    "        onlyb_top10.loc[[i for i in onlyb_top10.index.tolist() if i not in int_top10], 'b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = -1\n",
    "        onlyb_top10 = onlyb_top10.loc[(onlyb_top10['a_norm_XIC\\r\\nAUC[Byos]'] != -1)|(onlyb_top10['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] != -1)].reset_index(drop=True).drop(['N(x) ↓', 'e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'N(x) ↓'], axis = 1)\n",
    "\n",
    "        ## onlyp_top10\n",
    "        onlyp_top10 = onlyp.copy()\n",
    "        # onlyp_top10.to_excel('20210722_onlyp_top10_debug.xlsx', index=False)\n",
    "        mono_top10 = onlyp_top10.groupby('ProSites[pGlyco]').apply(pd.DataFrame.nlargest, n=5, columns='c_norm_MonoArea[pGlyco]').droplevel(level=0).index.tolist()\n",
    "        iso_top10 = onlyp_top10.groupby('ProSites[pGlyco]').apply(pd.DataFrame.nlargest, n=5, columns='d_norm_IsotopeArea[pGlyco]').droplevel(level=0).index.tolist()\n",
    "        onlyp_top10.loc[[i for i in onlyp_top10.index.tolist() if i not in mono_top10], 'c_norm_MonoArea[pGlyco]'] = -1\n",
    "        onlyp_top10.loc[[i for i in onlyp_top10.index.tolist() if i not in iso_top10], 'd_norm_IsotopeArea[pGlyco]'] = -1\n",
    "        onlyp_top10 = onlyp_top10.loc[(onlyp_top10['c_norm_MonoArea[pGlyco]'] != -1)|(onlyp_top10['d_norm_IsotopeArea[pGlyco]'] != -1)].reset_index(drop=True).drop(['N(x) ↓', 'g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'N(x) ↓'], axis = 1)\n",
    "\n",
    "        ## bp_top10\n",
    "        onlyb_top10 = onlyb_top10.rename(columns={'N-site(SequonBased)[Byonic]': f'N-site(Byonic ∪ pGlyco [Top{topN}]) →'}) \n",
    "        onlyp_top10 = onlyp_top10.rename(columns={'ProSites[pGlyco]':f'N-site(Byonic ∪ pGlyco [Top{topN}]) →'})\n",
    "        a1, a2 = onlyb_top10.align(onlyp_top10, join='outer', axis = 1) # align cols only\n",
    "        bptop10 = pd.concat([a1,a2]) # concat vertically \n",
    "        bptop10 = bptop10.fillna(-1).sort_values('Glycans ↓').reset_index(drop = True)\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in bptop10['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        bptop10.insert(0 , 'N(x) ↓', nx , True)\n",
    "        nx = list(set(bptop10['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        bptop10_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        print('----- Start summary table construction. -----\\n')\n",
    "        # start grouping: N(X) -> byonic glycans -> byonic sites -> .agg({all 8 cols, apply .mean() & .mean()/total XXX})\n",
    "        # bp_intersection\n",
    "        bp_intersection_gp = bp_inter.groupby(['N(x) ↓', 'Glycans ↓', 'N-site(Byonic ∪ pGlyco) →']).agg({'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x[x!= -1].mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x[x!= -1].mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x[x!= -1].mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x[x!= -1].mean()})\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        bp_intersection_gp = bp_intersection_gp.reindex(bp_intersection_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        bp_intersection_gp = bp_intersection_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        bp_intersection_gp.columns = bp_intersection_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        bp_intersection_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        bp_intersection_gp.columns = bp_intersection_gp.columns.set_names(['N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        bp_intersection_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]'], level = 1, inplace=True)\n",
    "\n",
    "        # bp_union\n",
    "        bp_union_gp = bp_union.groupby(['N(x) ↓', 'Glycans ↓', 'N-site(Byonic ∪ pGlyco) →']).agg({'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x[x!= -1].mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x[x!= -1].mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x[x!= -1].mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x[x!= -1].mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        bp_union_gp = bp_union_gp.reindex(bp_union_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        bp_union_gp = bp_union_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        bp_union_gp.columns = bp_union_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        bp_union_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        bp_union_gp.columns = bp_union_gp.columns.set_names(['N-site(Byonic ∪ pGlyco) →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        bp_union_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]'], level = 1, inplace=True)\n",
    "\n",
    "\n",
    "        # onlyb\n",
    "        onlyb_gp = onlyb.groupby(['N(x) ↓', 'Glycans ↓', 'N-site(SequonBased)[Byonic]']).agg({'e_sum_XIC\\r\\nAUC[Byos]': lambda x: x.mean(), 'f_sum_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x.mean() \\\n",
    "                                                                                              , 'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x.mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x.mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        onlyb_gp = onlyb_gp.reindex(b_new_nx, level = 0)\n",
    "        # unstack byonic n-sites\n",
    "        onlyb_gp = onlyb_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        onlyb_gp.columns = onlyb_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        onlyb_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        onlyb_gp.columns = onlyb_gp.columns.set_names(['N-site(SequonBased)[Byonic] →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        onlyb_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'sum_XIC\\r\\nAUC[Byos]', 'sum_Apex Int.\\r\\n(Posit)[Byos]'], level = 1, inplace=True)\n",
    "\n",
    "        # onlyp\n",
    "        onlyp_gp = onlyp.groupby(['N(x) ↓', 'Glycans ↓', 'ProSites[pGlyco]']).agg({'g_sum_MonoArea[pGlyco]': lambda x: x.mean(), 'h_sum_IsotopeArea[pGlyco]': lambda x: x.mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x.mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x.mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        onlyp_gp = onlyp_gp.reindex(p_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        onlyp_gp = onlyp_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        onlyp_gp.columns = onlyp_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        onlyp_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        onlyp_gp.columns = onlyp_gp.columns.set_names(['ProSites[pGlyco] →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        onlyp_gp.columns.set_levels(['norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]', 'sum_MonoArea[pGlyco]', 'sum_IsotopeArea[pGlyco]'], level = 1, inplace=True)\n",
    "\n",
    "        # bp_top10\n",
    "        bptop10_gp = bptop10.groupby(['N(x) ↓', 'Glycans ↓', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →']).agg({'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x[x!= -1].mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x[x!= -1].mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x[x!= -1].mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x[x!= -1].mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        bptop10_gp = bptop10_gp.reindex(bptop10_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        bptop10_gp = bptop10_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        bptop10_gp.columns = bptop10_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        bptop10_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        bptop10_gp.columns = bptop10_gp.columns.set_names([f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        bptop10_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]'], level = 1, inplace=True)\n",
    "\n",
    "        print('\\n----- Exporting \"_Quant\" files... This may take some time, please wait. -----\\n')\n",
    "        \n",
    "        with pd.ExcelWriter(f'{date}_Quant_{filename}.xlsx') as writer:           \n",
    "            # onlyb\n",
    "            onlyb_gp.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            onlyb_gp.style.background_gradient(cmap ='Greens').highlight_null(null_color='white').to_excel(writer, sheet_name = 'Sheet1(QuantB)')\n",
    "            # onlyp\n",
    "            onlyp_gp.replace(to_replace = -1, value = np.nan , inplace = True) \n",
    "            onlyp_gp.style.background_gradient(cmap ='Blues').highlight_null(null_color='white').to_excel(writer, sheet_name = 'Sheet2(QuantP)')\n",
    "            # bp_intersection\n",
    "            bp_intersection_gp.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bp_intersection_gp.style.background_gradient(cmap ='Reds').highlight_null(null_color='white').to_excel(writer, sheet_name = 'Sheet3(QuantBPinter)') \n",
    "            # bp_union\n",
    "            bp_union_gp.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bp_union_gp.style.background_gradient(cmap ='Reds').highlight_null(null_color='white').to_excel(writer, sheet_name = 'Sheet4(QuantBPunion)') \n",
    "            # bp_top10\n",
    "            bptop10_gp.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bptop10_gp.style.background_gradient(cmap ='Reds').highlight_null(null_color='white').to_excel(writer, sheet_name = f'Sheet5(Top{topN})') \n",
    "            \n",
    "        print('\\n----- \"_Quant\" file exported. -----\\n')\n",
    "        \n",
    "        print('----- Start plotting. -----\\n')\n",
    "        bpunionNORM_dfall_lstv1, bpunionNORM_label_lstv1, bpunionNORM_dfall_lstv2, bpunionNORM_label_lstv2 \\\n",
    "        , bpunionNORM_dfall_lstv3, bpunionNORM_label_lstv3, bpunionNORM_dfall_lstv4, bpunionNORM_label_lstv4 \\\n",
    "        , bptop10NORM_dfall_lstv1, bptop10NORM_label_lstv1, bptop10NORM_dfall_lstv2, bptop10NORM_label_lstv2 \\\n",
    "        , bptop10NORM_dfall_lstv3, bptop10NORM_label_lstv3, bptop10NORM_dfall_lstv4, bptop10NORM_label_lstv4 \\\n",
    "        , bpinterNORM_dfall_lstv1, bpinterNORM_label_lstv1, bpinterNORM_dfall_lstv2, bpinterNORM_label_lstv2 \\\n",
    "        , bpinterNORM_dfall_lstv3, bpinterNORM_label_lstv3, bpinterNORM_dfall_lstv4, bpinterNORM_label_lstv4 \\\n",
    "        , bNORM_dfall_lstv1, bNORM_label_lstv1, bNORM_dfall_lstv2, bNORM_label_lstv2 \\\n",
    "        , bNORM_dfall_lstv3, bNORM_label_lstv3, bNORM_dfall_lstv4, bNORM_label_lstv4 \\\n",
    "        , bSUM_dfall_lstv1, bSUM_label_lstv1, bSUM_nsum_lstv1, bSUM_dfall_lstv2, bSUM_label_lstv2, bSUM_nsum_lstv2 \\\n",
    "        , bSUM_dfall_lstv3, bSUM_label_lstv3, bSUM_nsum_lstv3, bSUM_dfall_lstv4, bSUM_label_lstv4, bSUM_nsum_lstv4 \\\n",
    "        , pNORM_dfall_lstv1, pNORM_label_lstv1, pNORM_dfall_lstv2, pNORM_label_lstv2 \\\n",
    "        , pNORM_dfall_lstv3, pNORM_label_lstv3, pNORM_dfall_lstv4, pNORM_label_lstv4 \\\n",
    "        , pSUM_dfall_lstv1, pSUM_label_lstv1, pSUM_nsum_lstv1, pSUM_dfall_lstv2, pSUM_label_lstv2, pSUM_nsum_lstv2 \\\n",
    "        , pSUM_dfall_lstv3, pSUM_label_lstv3, pSUM_nsum_lstv3, pSUM_dfall_lstv4, pSUM_label_lstv4, pSUM_nsum_lstv4 \\\n",
    "        = [], [], [], [], [], [], [], [], [], [] \\\n",
    "        , [], [], [], [], [], [], [], [], [], [] \\\n",
    "        , [], [], [], [], [], [], [], [], [], [] \\\n",
    "        , [], [], [], [], [], [], [], [], [], [] \\\n",
    "        , [], [], [], [], [], [], [], [], [], [] \\\n",
    "        , [], [], [], [], [], [], [], [], [], [] \\\n",
    "        , [], [], [], []\n",
    "        \n",
    "        if plot_v2 == 'yes':  \n",
    "            col_order = ['N(0)', 'N(1)', 'OligoMannose', 'Complex', 'Complex+Sia'] # col order for v2 plotting\n",
    "            # necessary preprocessings for v2 plotting (modified from v1 nx)\n",
    "            # bp union v2\n",
    "            bp_union.loc[(bp_union['N(x) ↓'] == 'N(0)')|(bp_union['N(x) ↓'] == 'N(1)'), 'nx_version2'] = bp_union['N(x) ↓']\n",
    "            bp_union.loc[(bp_union['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "            bp_union.loc[(bp_union['N(x) ↓'] != 'N(0)')&(bp_union['N(x) ↓'] != 'N(1)')&(bp_union['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "            bp_union.loc[(bp_union['N(x) ↓'] != 'N(0)')&(bp_union['N(x) ↓'] != 'N(1)')&(bp_union['N(x) ↓'] != 'N(2)')&(bp_union['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "            bpunion_neugc_exist = sum(bp_union['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "            # bp top10 (extract from bp union) v2\n",
    "            bptop10.loc[(bptop10['N(x) ↓'] == 'N(0)')|(bptop10['N(x) ↓'] == 'N(1)'), 'nx_version2'] = bptop10['N(x) ↓']\n",
    "            bptop10.loc[(bptop10['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "            bptop10.loc[(bptop10['N(x) ↓'] != 'N(0)')&(bptop10['N(x) ↓'] != 'N(1)')&(bptop10['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "            bptop10.loc[(bptop10['N(x) ↓'] != 'N(0)')&(bptop10['N(x) ↓'] != 'N(1)')&(bptop10['N(x) ↓'] != 'N(2)')&(bptop10['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "            bptop10_neugc_exist = sum(bptop10['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "            # bp inter v2\n",
    "            bp_inter.loc[(bp_inter['N(x) ↓'] == 'N(0)')|(bp_inter['N(x) ↓'] == 'N(1)'), 'nx_version2'] = bp_inter['N(x) ↓']\n",
    "            bp_inter.loc[(bp_inter['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "            bp_inter.loc[(bp_inter['N(x) ↓'] != 'N(0)')&(bp_inter['N(x) ↓'] != 'N(1)')&(bp_inter['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "            bp_inter.loc[(bp_inter['N(x) ↓'] != 'N(0)')&(bp_inter['N(x) ↓'] != 'N(1)')&(bp_inter['N(x) ↓'] != 'N(2)')&(bp_inter['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "            bpinter_neugc_exist = sum(bp_inter['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "            # onlyb v2\n",
    "            onlyb.loc[(onlyb['N(x) ↓'] == 'N(0)')|(onlyb['N(x) ↓'] == 'N(1)'), 'nx_version2'] = onlyb['N(x) ↓']\n",
    "            onlyb.loc[(onlyb['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "            onlyb.loc[(onlyb['N(x) ↓'] != 'N(0)')&(onlyb['N(x) ↓'] != 'N(1)')&(onlyb['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "            onlyb.loc[(onlyb['N(x) ↓'] != 'N(0)')&(onlyb['N(x) ↓'] != 'N(1)')&(onlyb['N(x) ↓'] != 'N(2)')&(onlyb['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "            b_neugc_exist = sum(onlyb['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "            # onlyp v2\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] == 'N(0)')|(onlyp['N(x) ↓'] == 'N(1)'), 'nx_version2'] = onlyp['N(x) ↓']\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] != 'N(0)')&(onlyp['N(x) ↓'] != 'N(1)')&(onlyp['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] != 'N(0)')&(onlyp['N(x) ↓'] != 'N(1)')&(onlyp['N(x) ↓'] != 'N(2)')&(onlyp['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "            p_neugc_exist = sum(onlyp['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "        \n",
    "        if plot_v3 == 'yes':\n",
    "            # necessary preprocessings for v3 plotting (modified from v1 nx)\n",
    "            # bp union v3\n",
    "            bp_union, union_nxhy_fix_order = v3(bp_union)[0], v3(bp_union)[1]\n",
    "            # bp top10 (extract from bp union) v3\n",
    "            bptop10, top10_nxhy_fix_order = v3(bptop10)[0], v3(bptop10)[1]            \n",
    "            # bp inter v3\n",
    "            bp_inter, inter_nxhy_fix_order = v3(bp_inter)[0], v3(bp_inter)[1]             \n",
    "            # onlyb v3\n",
    "            onlyb, onlyb_nxhy_fix_order = v3(onlyb)[0], v3(onlyb)[1]            \n",
    "            # onlyp v3\n",
    "            onlyp, onlyp_nxhy_fix_order = v3(onlyp)[0], v3(onlyp)[1]\n",
    "\n",
    "        if plot_v4 == 'yes':\n",
    "            # necessary preprocessings for v4 plotting (modified from v1 nx)\n",
    "            # bp union v4\n",
    "            bp_union, union_fnxhy_fix_order = v4(bp_union)[0], v4(bp_union)[1]\n",
    "            # bp top10 (extract from bp union) v4\n",
    "            bptop10, top10_fnxhy_fix_order = v4(bptop10)[0], v4(bptop10)[1]             \n",
    "            # bp inter v4\n",
    "            bp_inter, inter_fnxhy_fix_order = v4(bp_inter)[0], v4(bp_inter)[1]            \n",
    "            # onlyb v4\n",
    "            onlyb, onlyb_fnxhy_fix_order = v4(onlyb)[0], v4(onlyb)[1]            \n",
    "            # onlyp v4\n",
    "            onlyp, onlyp_fnxhy_fix_order = v4(onlyp)[0], v4(onlyp)[1]\n",
    "\n",
    "        # rename bp inter colname\n",
    "        bp_inter = bp_inter.rename(columns={'N-site(Byonic ∪ pGlyco) →':'N-site(Byonic ∩ pGlyco [Glycan B=P]) →'})\n",
    "        # make sure that sites are presented as int not float\n",
    "        bp_union = bp_union.astype({'N-site(Byonic ∪ pGlyco) →':'Int64'})\n",
    "        bptop10 = bptop10.astype({f'N-site(Byonic ∪ pGlyco [Top{topN}]) →':'Int64'})\n",
    "        bp_inter = bp_inter.astype({'N-site(Byonic ∩ pGlyco [Glycan B=P]) →':'Int64'})\n",
    "        onlyb = onlyb.astype({'N-site(SequonBased)[Byonic]':'Int64'})\n",
    "        onlyp = onlyp.astype({'ProSites[pGlyco]':'Int64'})\n",
    "\n",
    "        # split bp_union into: xicauc_df / int_df / mono_df / iso_df for later clustered stacked plot (norm only)\n",
    "        if export_xicauc == 'yes':\n",
    "            if plot_v1 == 'yes':\n",
    "                # bpunion norm v1\n",
    "                bpunion_xicaucNORM_df = bp_union.loc[:, ['N(x) ↓', 'N-site(Byonic ∪ pGlyco) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bpunion_xicaucNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_xicaucNORM_df = bpunion_xicaucNORM_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_union_new_nx)\n",
    "                bpunionNORM_dfall_lstv1.append(bpunion_xicaucNORM_df)\n",
    "                bpunionNORM_label_lstv1.append('norm_XIC AUC[Byos]')\n",
    "                # bptop10 norm v1\n",
    "                bptop10_xicaucNORM_df = bptop10.loc[:, ['N(x) ↓', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bptop10_xicaucNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_xicaucNORM_df = bptop10_xicaucNORM_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bptop10_new_nx)\n",
    "                bptop10NORM_dfall_lstv1.append(bptop10_xicaucNORM_df)\n",
    "                bptop10NORM_label_lstv1.append('norm_XIC AUC[Byos]')\n",
    "                # bpinter norm v1\n",
    "                bpinter_xicaucNORM_df = bp_inter.loc[:, ['N(x) ↓', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bpinter_xicaucNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_xicaucNORM_df = bpinter_xicaucNORM_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_intersection_new_nx)\n",
    "                bpinterNORM_dfall_lstv1.append(bpinter_xicaucNORM_df)\n",
    "                bpinterNORM_label_lstv1.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb norm v1\n",
    "                b_xicaucNORM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucNORM_df = b_xicaucNORM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "                bNORM_dfall_lstv1.append(b_xicaucNORM_df)\n",
    "                bNORM_label_lstv1.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb sum v1\n",
    "                b_xicaucSUM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucSUM_df = b_xicaucSUM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "                b_xicaucSUM_df_nsum = [b_xicaucSUM_df.loc[i].sum() for i in b_xicaucSUM_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv1.append(b_xicaucSUM_df)\n",
    "                bSUM_label_lstv1.append('sum_XIC AUC[Byos]')\n",
    "                bSUM_nsum_lstv1.append(b_xicaucSUM_df_nsum)\n",
    "\n",
    "            if plot_v2 == 'yes':\n",
    "                # bpuion norm v2\n",
    "                bpunion_xicaucNORMv2_df = bp_union.loc[:, ['nx_version2', 'N-site(Byonic ∪ pGlyco) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bpunion_xicaucNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_xicaucNORMv2_df = bpunion_xicaucNORMv2_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bpunionNORM_dfall_lstv2.append(bpunion_xicaucNORMv2_df)\n",
    "                bpunionNORM_label_lstv2.append('norm_XIC AUC[Byos]')\n",
    "                # bptop10 norm v2\n",
    "                bptop10_xicaucNORMv2_df = bptop10.loc[:, ['nx_version2', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bptop10_xicaucNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_xicaucNORMv2_df = bptop10_xicaucNORMv2_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bptop10NORM_dfall_lstv2.append(bptop10_xicaucNORMv2_df)\n",
    "                bptop10NORM_label_lstv2.append('norm_XIC AUC[Byos]')\n",
    "                # bpinter norm v2\n",
    "                bpinter_xicaucNORMv2_df = bp_inter.loc[:, ['nx_version2', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bpinter_xicaucNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_xicaucNORMv2_df = bpinter_xicaucNORMv2_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bpinterNORM_dfall_lstv2.append(bpinter_xicaucNORMv2_df)\n",
    "                bpinterNORM_label_lstv2.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb norm v2\n",
    "                b_xicaucNORMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucNORMv2_df = b_xicaucNORMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bNORM_dfall_lstv2.append(b_xicaucNORMv2_df)\n",
    "                bNORM_label_lstv2.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb sum v2\n",
    "                b_xicaucSUMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucSUMv2_df = b_xicaucSUMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                b_xicaucSUMv2_df_nsum = [b_xicaucSUMv2_df.loc[i].sum() for i in b_xicaucSUMv2_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv2.append(b_xicaucSUMv2_df)\n",
    "                bSUM_label_lstv2.append('sum_XIC AUC[Byos]')\n",
    "                bSUM_nsum_lstv2.append(b_xicaucSUMv2_df_nsum)\n",
    "\n",
    "            if plot_v3 == 'yes':\n",
    "                # bpuion norm v3\n",
    "                bpunion_xicaucNORMv3_df = bp_union.loc[:, ['N(x)H(y)', 'N-site(Byonic ∪ pGlyco) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bpunion_xicaucNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_xicaucNORMv3_df = bpunion_xicaucNORMv3_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=union_nxhy_fix_order)\n",
    "                bpunionNORM_dfall_lstv3.append(bpunion_xicaucNORMv3_df)\n",
    "                bpunionNORM_label_lstv3.append('norm_XIC AUC[Byos]')\n",
    "                # bptop10 norm v3\n",
    "                bptop10_xicaucNORMv3_df = bptop10.loc[:, ['N(x)H(y)', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bptop10_xicaucNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_xicaucNORMv3_df = bptop10_xicaucNORMv3_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=top10_nxhy_fix_order)\n",
    "                bptop10NORM_dfall_lstv3.append(bptop10_xicaucNORMv3_df)\n",
    "                bptop10NORM_label_lstv3.append('norm_XIC AUC[Byos]')\n",
    "                # bpinter norm v3\n",
    "                bpinter_xicaucNORMv3_df = bp_inter.loc[:, ['N(x)H(y)', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bpinter_xicaucNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_xicaucNORMv3_df = bpinter_xicaucNORMv3_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=inter_nxhy_fix_order)\n",
    "                bpinterNORM_dfall_lstv3.append(bpinter_xicaucNORMv3_df)\n",
    "                bpinterNORM_label_lstv3.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb norm v3\n",
    "                b_xicaucNORMv3_df = onlyb.loc[:, ['N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucNORMv3_df = b_xicaucNORMv3_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_nxhy_fix_order)\n",
    "                bNORM_dfall_lstv3.append(b_xicaucNORMv3_df)\n",
    "                bNORM_label_lstv3.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb sum v3\n",
    "                b_xicaucSUMv3_df = onlyb.loc[:, ['N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucSUMv3_df = b_xicaucSUMv3_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_nxhy_fix_order)\n",
    "                b_xicaucSUMv3_df_nsum = [b_xicaucSUMv3_df.loc[i].sum() for i in b_xicaucSUMv3_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv3.append(b_xicaucSUMv3_df)\n",
    "                bSUM_label_lstv3.append('sum_XIC AUC[Byos]')\n",
    "                bSUM_nsum_lstv3.append(b_xicaucSUMv3_df_nsum)\n",
    "\n",
    "            if plot_v4 == 'yes':\n",
    "                # bpuion norm v4\n",
    "                bpunion_xicaucNORMv4_df = bp_union.loc[:, ['(F)N(x)H(y)', 'N-site(Byonic ∪ pGlyco) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bpunion_xicaucNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_xicaucNORMv4_df = bpunion_xicaucNORMv4_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=union_fnxhy_fix_order)\n",
    "                bpunionNORM_dfall_lstv4.append(bpunion_xicaucNORMv4_df)\n",
    "                bpunionNORM_label_lstv4.append('norm_XIC AUC[Byos]')\n",
    "                # bptop10 norm v4\n",
    "                bptop10_xicaucNORMv4_df = bptop10.loc[:, ['(F)N(x)H(y)', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bptop10_xicaucNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_xicaucNORMv4_df = bptop10_xicaucNORMv4_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=top10_fnxhy_fix_order)\n",
    "                bptop10NORM_dfall_lstv4.append(bptop10_xicaucNORMv4_df)\n",
    "                bptop10NORM_label_lstv4.append('norm_XIC AUC[Byos]')\n",
    "                # bpinter norm v4\n",
    "                bpinter_xicaucNORMv4_df = bp_inter.loc[:, ['(F)N(x)H(y)', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                bpinter_xicaucNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_xicaucNORMv4_df = bpinter_xicaucNORMv4_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=inter_fnxhy_fix_order)\n",
    "                bpinterNORM_dfall_lstv4.append(bpinter_xicaucNORMv4_df)\n",
    "                bpinterNORM_label_lstv4.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb norm v4\n",
    "                b_xicaucNORMv4_df = onlyb.loc[:, ['(F)N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucNORMv4_df = b_xicaucNORMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_fnxhy_fix_order)\n",
    "                bNORM_dfall_lstv4.append(b_xicaucNORMv4_df)\n",
    "                bNORM_label_lstv4.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb sum v4\n",
    "                b_xicaucSUMv4_df = onlyb.loc[:, ['(F)N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucSUMv4_df = b_xicaucSUMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_fnxhy_fix_order)\n",
    "                b_xicaucSUMv4_df_nsum = [b_xicaucSUMv4_df.loc[i].sum() for i in b_xicaucSUMv4_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv4.append(b_xicaucSUMv4_df)\n",
    "                bSUM_label_lstv4.append('sum_XIC AUC[Byos]')\n",
    "                bSUM_nsum_lstv4.append(b_xicaucSUMv4_df_nsum)    \n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        if export_int == 'yes': \n",
    "            if plot_v1 == 'yes':\n",
    "                # bp union norm v1\n",
    "                bpunion_intNORM_df = bp_union.loc[:, ['N(x) ↓', 'N-site(Byonic ∪ pGlyco) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                bpunion_intNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_intNORM_df = bpunion_intNORM_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_union_new_nx)\n",
    "                bpunionNORM_dfall_lstv1.append(bpunion_intNORM_df)\n",
    "                bpunionNORM_label_lstv1.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # bptop10 norm v1\n",
    "                bptop10_intNORM_df = bptop10.loc[:, ['N(x) ↓', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                bptop10_intNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_intNORM_df = bptop10_intNORM_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bptop10_new_nx)\n",
    "                bptop10NORM_dfall_lstv1.append(bptop10_intNORM_df)\n",
    "                bptop10NORM_label_lstv1.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # bp inter norm v1\n",
    "                bpinter_intNORM_df = bp_inter.loc[:, ['N(x) ↓', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bpinter_intNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_intNORM_df = bpinter_intNORM_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_intersection_new_nx)\n",
    "                bpinterNORM_dfall_lstv1.append(bpinter_intNORM_df)\n",
    "                bpinterNORM_label_lstv1.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb norm v1 \n",
    "                b_intNORM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                b_intNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intNORM_df = b_intNORM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "                bNORM_dfall_lstv1.append(b_intNORM_df)\n",
    "                bNORM_label_lstv1.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb sum v1\n",
    "                b_intSUM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                b_intSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intSUM_df = b_intSUM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "                b_intSUM_df_nsum = [b_intSUM_df.loc[i].sum() for i in b_intSUM_df.index.tolist()] # for B bar label\n",
    "                bSUM_dfall_lstv1.append(b_intSUM_df)\n",
    "                bSUM_label_lstv1.append('sum_Apex Int.(Posit)[Byos]')\n",
    "                bSUM_nsum_lstv1.append(b_intSUM_df_nsum)\n",
    "            if plot_v2 == 'yes':\n",
    "                # bp union norm v2\n",
    "                bpunion_intNORMv2_df = bp_union.loc[:, ['nx_version2', 'N-site(Byonic ∪ pGlyco) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bpunion_intNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_intNORMv2_df = bpunion_intNORMv2_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bpunionNORM_dfall_lstv2.append(bpunion_intNORMv2_df)\n",
    "                bpunionNORM_label_lstv2.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # bptop10 norm v2\n",
    "                bptop10_intNORMv2_df = bptop10.loc[:, ['nx_version2', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bptop10_intNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_intNORMv2_df = bptop10_intNORMv2_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bptop10NORM_dfall_lstv2.append(bptop10_intNORMv2_df)\n",
    "                bptop10NORM_label_lstv2.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # bp inter norm v2\n",
    "                bpinter_intNORMv2_df = bp_inter.loc[:, ['nx_version2', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bpinter_intNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_intNORMv2_df = bpinter_intNORMv2_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bpinterNORM_dfall_lstv2.append(bpinter_intNORMv2_df)\n",
    "                bpinterNORM_label_lstv2.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb norm v2\n",
    "                b_intNORMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                b_intNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intNORMv2_df = b_intNORMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bNORM_dfall_lstv2.append(b_intNORMv2_df)\n",
    "                bNORM_label_lstv2.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb sum v2\n",
    "                b_intSUMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                b_intSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intSUMv2_df = b_intSUMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                b_intSUMv2_df_nsum = [b_intSUMv2_df.loc[i].sum() for i in b_intSUMv2_df.index.tolist()] # for B bar label\n",
    "                bSUM_dfall_lstv2.append(b_intSUMv2_df)\n",
    "                bSUM_label_lstv2.append('sum_Apex Int.(Posit)[Byos]')\n",
    "                bSUM_nsum_lstv2.append(b_intSUMv2_df_nsum)\n",
    "            if plot_v3 == 'yes':\n",
    "                bpunion_intNORMv3_df = bp_union.loc[:, ['N(x)H(y)', 'N-site(Byonic ∪ pGlyco) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bpunion_intNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_intNORMv3_df = bpunion_intNORMv3_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=union_nxhy_fix_order)\n",
    "                bpunionNORM_dfall_lstv3.append(bpunion_intNORMv3_df)\n",
    "                bpunionNORM_label_lstv3.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # bptop10 norm v3\n",
    "                bptop10_intNORMv3_df = bptop10.loc[:, ['N(x)H(y)', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bptop10_intNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_intNORMv3_df = bptop10_intNORMv3_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=top10_nxhy_fix_order)\n",
    "                bptop10NORM_dfall_lstv3.append(bptop10_intNORMv3_df)\n",
    "                bptop10NORM_label_lstv3.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # bpinter norm v3\n",
    "                bpinter_intNORMv3_df = bp_inter.loc[:, ['N(x)H(y)', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bpinter_intNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_intNORMv3_df = bpinter_intNORMv3_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=inter_nxhy_fix_order)\n",
    "                bpinterNORM_dfall_lstv3.append(bpinter_intNORMv3_df)\n",
    "                bpinterNORM_label_lstv3.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb norm v3\n",
    "                b_intNORMv3_df = onlyb.loc[:, ['N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                b_intNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intNORMv3_df = b_intNORMv3_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_nxhy_fix_order)\n",
    "                bNORM_dfall_lstv3.append(b_intNORMv3_df)\n",
    "                bNORM_label_lstv3.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb sum v3\n",
    "                b_intSUMv3_df = onlyb.loc[:, ['N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                b_intSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intSUMv3_df = b_intSUMv3_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_nxhy_fix_order)\n",
    "                b_intSUMv3_df_nsum = [b_intSUMv3_df.loc[i].sum() for i in b_intSUMv3_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv3.append(b_intSUMv3_df)\n",
    "                bSUM_label_lstv3.append('sum_Apex Int.(Posit)[Byos]')\n",
    "                bSUM_nsum_lstv3.append(b_intSUMv3_df_nsum)\n",
    "            if plot_v4 == 'yes':\n",
    "                # bpuion norm v4\n",
    "                bpunion_intNORMv4_df = bp_union.loc[:, ['(F)N(x)H(y)', 'N-site(Byonic ∪ pGlyco) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bpunion_intNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_intNORMv4_df = bpunion_intNORMv4_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=union_fnxhy_fix_order)\n",
    "                bpunionNORM_dfall_lstv4.append(bpunion_intNORMv4_df)\n",
    "                bpunionNORM_label_lstv4.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # bptop10 norm v4\n",
    "                bptop10_intNORMv4_df = bptop10.loc[:, ['(F)N(x)H(y)', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bptop10_intNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_intNORMv4_df = bptop10_intNORMv4_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=top10_fnxhy_fix_order)\n",
    "                bptop10NORM_dfall_lstv4.append(bptop10_intNORMv4_df)\n",
    "                bptop10NORM_label_lstv4.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # bpinter norm v4\n",
    "                bpinter_intNORMv4_df = bp_inter.loc[:, ['(F)N(x)H(y)', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                bpinter_intNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_intNORMv4_df = bpinter_intNORMv4_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=inter_fnxhy_fix_order)\n",
    "                bpinterNORM_dfall_lstv4.append(bpinter_intNORMv4_df)\n",
    "                bpinterNORM_label_lstv4.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb norm v4\n",
    "                b_intNORMv4_df = onlyb.loc[:, ['(F)N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                b_intNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intNORMv4_df = b_intNORMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_fnxhy_fix_order)\n",
    "                bNORM_dfall_lstv4.append(b_intNORMv4_df)\n",
    "                bNORM_label_lstv4.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb sum v4\n",
    "                b_intSUMv4_df = onlyb.loc[:, ['(F)N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                b_intSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intSUMv4_df = b_intSUMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_fnxhy_fix_order)\n",
    "                b_intSUMv4_df_nsum = [b_intSUMv4_df.loc[i].sum() for i in b_intSUMv4_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv4.append(b_intSUMv4_df)\n",
    "                bSUM_label_lstv4.append('sum_Apex Int.(Posit)[Byos]')\n",
    "                bSUM_nsum_lstv4.append(b_intSUMv4_df_nsum)       \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if export_mono == 'yes':\n",
    "            if plot_v1 == 'yes':\n",
    "                # bp union norm v1\n",
    "                bpunion_monoNORM_df = bp_union.loc[:, ['N(x) ↓', 'N-site(Byonic ∪ pGlyco) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bpunion_monoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_monoNORM_df = bpunion_monoNORM_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='c_norm_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_union_new_nx)\n",
    "                bpunionNORM_dfall_lstv1.append(bpunion_monoNORM_df)\n",
    "                bpunionNORM_label_lstv1.append('norm_MonoArea[pGlyco]')\n",
    "                # bptop10 norm v1\n",
    "                bptop10_monoNORM_df = bptop10.loc[:, ['N(x) ↓', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bptop10_monoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_monoNORM_df = bptop10_monoNORM_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='c_norm_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bptop10_new_nx)\n",
    "                bptop10NORM_dfall_lstv1.append(bptop10_monoNORM_df)\n",
    "                bptop10NORM_label_lstv1.append('norm_MonoArea[pGlyco]')\n",
    "                # bp inter norm v1\n",
    "                bpinter_monoNORM_df = bp_inter.loc[:, ['N(x) ↓', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bpinter_monoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_monoNORM_df = bpinter_monoNORM_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='c_norm_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_intersection_new_nx)\n",
    "                bpinterNORM_dfall_lstv1.append(bpinter_monoNORM_df)\n",
    "                bpinterNORM_label_lstv1.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp norm v1\n",
    "                p_monoNORM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "                p_monoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORM_df = p_monoNORM_df.pivot_table(index='ProSites[pGlyco]', values='c_norm_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                pNORM_dfall_lstv1.append(p_monoNORM_df)\n",
    "                pNORM_label_lstv1.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp sum v1\n",
    "                p_monoSUM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "                p_monoSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUM_df = p_monoSUM_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                p_monoSUM_df_nsum = [p_monoSUM_df.loc[i].sum() for i in p_monoSUM_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv1.append(p_monoSUM_df)\n",
    "                pSUM_label_lstv1.append('sum_MonoArea[pGlyco]')\n",
    "                pSUM_nsum_lstv1.append(p_monoSUM_df_nsum)\n",
    "\n",
    "            if plot_v2 == 'yes':\n",
    "                # bp union norm v2\n",
    "                bpunion_monoNORMv2_df = bp_union.loc[:, ['nx_version2', 'N-site(Byonic ∪ pGlyco) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bpunion_monoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_monoNORMv2_df = bpunion_monoNORMv2_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='c_norm_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bpunionNORM_dfall_lstv2.append(bpunion_monoNORMv2_df)\n",
    "                bpunionNORM_label_lstv2.append('norm_MonoArea[pGlyco]')\n",
    "                # bptop10 norm v2\n",
    "                bptop10_monoNORMv2_df = bptop10.loc[:, ['nx_version2', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bptop10_monoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_monoNORMv2_df = bptop10_monoNORMv2_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='c_norm_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bptop10NORM_dfall_lstv2.append(bptop10_monoNORMv2_df)\n",
    "                bptop10NORM_label_lstv2.append('norm_MonoArea[pGlyco]')\n",
    "                # bp inter norm v2\n",
    "                bpinter_monoNORMv2_df = bp_inter.loc[:, ['nx_version2', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bpinter_monoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_monoNORMv2_df = bpinter_monoNORMv2_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='c_norm_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bpinterNORM_dfall_lstv2.append(bpinter_monoNORMv2_df)\n",
    "                bpinterNORM_label_lstv2.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp norm v2\n",
    "                p_monoNORMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "                p_monoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORMv2_df = p_monoNORMv2_df.pivot_table(index='ProSites[pGlyco]', values='c_norm_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                pNORM_dfall_lstv2.append(p_monoNORMv2_df)\n",
    "                pNORM_label_lstv2.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp sum v2\n",
    "                p_monoSUMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "                p_monoSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUMv2_df = p_monoSUMv2_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                p_monoSUMv2_df_nsum = [p_monoSUMv2_df.loc[i].sum() for i in p_monoSUMv2_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv2.append(p_monoSUMv2_df)\n",
    "                pSUM_label_lstv2.append('sum_MonoArea[pGlyco]')\n",
    "                pSUM_nsum_lstv2.append(p_monoSUMv2_df_nsum)\n",
    "\n",
    "            if plot_v3 == 'yes':\n",
    "                bpunion_monoNORMv3_df = bp_union.loc[:, ['N(x)H(y)', 'N-site(Byonic ∪ pGlyco) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bpunion_monoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_monoNORMv3_df = bpunion_monoNORMv3_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='c_norm_MonoArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=union_nxhy_fix_order)\n",
    "                bpunionNORM_dfall_lstv3.append(bpunion_monoNORMv3_df)\n",
    "                bpunionNORM_label_lstv3.append('norm_MonoArea[pGlyco]')\n",
    "                # bptop10 norm v3\n",
    "                bptop10_monoNORMv3_df = bptop10.loc[:, ['N(x)H(y)', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bptop10_monoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_monoNORMv3_df = bptop10_monoNORMv3_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='c_norm_MonoArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=top10_nxhy_fix_order)\n",
    "                bptop10NORM_dfall_lstv3.append(bptop10_monoNORMv3_df)\n",
    "                bptop10NORM_label_lstv3.append('norm_MonoArea[pGlyco]')\n",
    "                # bpinter norm v3\n",
    "                bpinter_monoNORMv3_df = bp_inter.loc[:, ['N(x)H(y)', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bpinter_monoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_monoNORMv3_df = bpinter_monoNORMv3_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='c_norm_MonoArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=inter_nxhy_fix_order)\n",
    "                bpinterNORM_dfall_lstv3.append(bpinter_monoNORMv3_df)\n",
    "                bpinterNORM_label_lstv3.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp norm v3\n",
    "                p_monoNORMv3_df = onlyb.loc[:, ['N(x)H(y)', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "                p_monoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORMv3_df = p_monoNORMv3_df.pivot_table(index='ProSites[pGlyco]', values='c_norm_MonoArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                pNORM_dfall_lstv3.append(p_monoNORMv3_df)\n",
    "                pNORM_label_lstv3.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp sum v3\n",
    "                p_monoSUMv3_df = onlyp.loc[:, ['N(x)H(y)', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "                p_monoSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUMv3_df = p_monoSUMv3_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                p_monoSUMv3_df_nsum = [p_monoSUMv3_df.loc[i].sum() for i in p_monoSUMv3_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv3.append(p_monoSUMv3_df)\n",
    "                pSUM_label_lstv3.append('sum_MonoArea[pGlyco]')\n",
    "                pSUM_nsum_lstv3.append(p_monoSUMv3_df_nsum)\n",
    "\n",
    "            if plot_v4 == 'yes':\n",
    "                # bpuion norm v4\n",
    "                bpunion_monoNORMv4_df = bp_union.loc[:, ['(F)N(x)H(y)', 'N-site(Byonic ∪ pGlyco) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bpunion_monoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_monoNORMv4_df = bpunion_monoNORMv4_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='c_norm_MonoArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=union_fnxhy_fix_order)\n",
    "                bpunionNORM_dfall_lstv4.append(bpunion_monoNORMv4_df)\n",
    "                bpunionNORM_label_lstv4.append('norm_MonoArea[pGlyco]')\n",
    "                # bptop10 norm v4\n",
    "                bptop10_monoNORMv4_df = bptop10.loc[:, ['(F)N(x)H(y)', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bptop10_monoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_monoNORMv4_df = bptop10_monoNORMv4_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='c_norm_MonoArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=top10_fnxhy_fix_order)\n",
    "                bptop10NORM_dfall_lstv4.append(bptop10_monoNORMv4_df)\n",
    "                bptop10NORM_label_lstv4.append('norm_MonoArea[pGlyco]')\n",
    "                # bpinter norm v4\n",
    "                bpinter_monoNORMv4_df = bp_inter.loc[:, ['(F)N(x)H(y)', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "                bpinter_monoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_monoNORMv4_df = bpinter_monoNORMv4_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='c_norm_MonoArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=inter_fnxhy_fix_order)\n",
    "                bpinterNORM_dfall_lstv4.append(bpinter_monoNORMv4_df)\n",
    "                bpinterNORM_label_lstv4.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp norm v4\n",
    "                p_monoNORMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "                p_monoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORMv4_df = p_monoNORMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='c_norm_MonoArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                pNORM_dfall_lstv4.append(p_monoNORMv4_df)\n",
    "                pNORM_label_lstv4.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp sum v4\n",
    "                p_monoSUMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "                p_monoSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUMv4_df = p_monoSUMv4_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                p_monoSUMv4_df_nsum = [p_monoSUMv4_df.loc[i].sum() for i in p_monoSUMv4_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv4.append(p_monoSUMv4_df)\n",
    "                pSUM_label_lstv4.append('sum_MonoArea[pGlyco]')\n",
    "                pSUM_nsum_lstv4.append(p_monoSUMv4_df_nsum)     \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if export_isotope == 'yes':\n",
    "            if plot_v1 == 'yes':\n",
    "                # bp union norm v1\n",
    "                bpunion_isoNORM_df = bp_union.loc[:, ['N(x) ↓', 'N-site(Byonic ∪ pGlyco) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bpunion_isoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_isoNORM_df = bpunion_isoNORM_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='d_norm_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_union_new_nx)\n",
    "                bpunionNORM_dfall_lstv1.append(bpunion_isoNORM_df)\n",
    "                bpunionNORM_label_lstv1.append('norm_IsotopeArea[pGlyco]')\n",
    "                # bp top10 norm v1\n",
    "                bptop10_isoNORM_df = bptop10.loc[:, ['N(x) ↓', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bptop10_isoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_isoNORM_df = bptop10_isoNORM_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='d_norm_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bptop10_new_nx)\n",
    "                bptop10NORM_dfall_lstv1.append(bptop10_isoNORM_df)\n",
    "                bptop10NORM_label_lstv1.append('norm_IsotopeArea[pGlyco]')\n",
    "                # bp inter norm v1\n",
    "                bpinter_isoNORM_df = bp_inter.loc[:, ['N(x) ↓', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bpinter_isoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_isoNORM_df = bpinter_isoNORM_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='d_norm_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_intersection_new_nx)\n",
    "                bpinterNORM_dfall_lstv1.append(bpinter_isoNORM_df)\n",
    "                bpinterNORM_label_lstv1.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp norm v1\n",
    "                p_isoNORM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                p_isoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORM_df = p_isoNORM_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                pNORM_dfall_lstv1.append(p_isoNORM_df)\n",
    "                pNORM_label_lstv1.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp sum v1\n",
    "                p_isoSUM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']] \n",
    "                p_isoSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUM_df = p_isoSUM_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                p_isoSUM_df_nsum = [p_isoSUM_df.loc[i].sum() for i in p_isoSUM_df.index.tolist()] # for B bar label\n",
    "                pSUM_dfall_lstv1.append(p_isoSUM_df)\n",
    "                pSUM_label_lstv1.append('sum_IsotopeArea[pGlyco]')\n",
    "                pSUM_nsum_lstv1.append(p_isoSUM_df_nsum)\n",
    "\n",
    "            if plot_v2 == 'yes':\n",
    "                # bp union norm v2\n",
    "                bpunion_isoNORMv2_df = bp_union.loc[:, ['nx_version2', 'N-site(Byonic ∪ pGlyco) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bpunion_isoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_isoNORMv2_df = bpunion_isoNORMv2_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='d_norm_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bpunionNORM_dfall_lstv2.append(bpunion_isoNORMv2_df)\n",
    "                bpunionNORM_label_lstv2.append('norm_IsotopeArea[pGlyco]')\n",
    "                # bp top10 norm v2\n",
    "                bptop10_isoNORMv2_df = bptop10.loc[:, ['nx_version2', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bptop10_isoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_isoNORMv2_df = bptop10_isoNORMv2_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='d_norm_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bptop10NORM_dfall_lstv2.append(bptop10_isoNORMv2_df)\n",
    "                bptop10NORM_label_lstv2.append('norm_IsotopeArea[pGlyco]')\n",
    "                # bp inter norm v2\n",
    "                bpinter_isoNORMv2_df = bp_inter.loc[:, ['nx_version2', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bpinter_isoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_isoNORMv2_df = bpinter_isoNORMv2_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='d_norm_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bpinterNORM_dfall_lstv2.append(bpinter_isoNORMv2_df)\n",
    "                bpinterNORM_label_lstv2.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp norm v2\n",
    "                p_isoNORMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                p_isoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORMv2_df = p_isoNORMv2_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                pNORM_dfall_lstv2.append(p_isoNORMv2_df)\n",
    "                pNORM_label_lstv2.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp sum v2\n",
    "                p_isoSUMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']] \n",
    "                p_isoSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUMv2_df = p_isoSUMv2_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                p_isoSUMv2_df_nsum = [p_isoSUMv2_df.loc[i].sum() for i in p_isoSUMv2_df.index.tolist()] # for B bar label\n",
    "                pSUM_dfall_lstv2.append(p_isoSUMv2_df)\n",
    "                pSUM_label_lstv2.append('sum_IsotopeArea[pGlyco]')\n",
    "                pSUM_nsum_lstv2.append(p_isoSUMv2_df_nsum)\n",
    "\n",
    "            if plot_v3 == 'yes':\n",
    "                bpunion_isoNORMv3_df = bp_union.loc[:, ['N(x)H(y)', 'N-site(Byonic ∪ pGlyco) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bpunion_isoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_isoNORMv3_df = bpunion_isoNORMv3_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='d_norm_IsotopeArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=union_nxhy_fix_order)\n",
    "                bpunionNORM_dfall_lstv3.append(bpunion_isoNORMv3_df)\n",
    "                bpunionNORM_label_lstv3.append('norm_IsotopeArea[pGlyco]')\n",
    "                # bptop10 norm v3\n",
    "                bptop10_isoNORMv3_df = bptop10.loc[:, ['N(x)H(y)', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bptop10_isoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_isoNORMv3_df = bptop10_isoNORMv3_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='d_norm_IsotopeArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=top10_nxhy_fix_order)\n",
    "                bptop10NORM_dfall_lstv3.append(bptop10_isoNORMv3_df)\n",
    "                bptop10NORM_label_lstv3.append('norm_IsotopeArea[pGlyco]')\n",
    "                # bpinter norm v3\n",
    "                bpinter_isoNORMv3_df = bp_inter.loc[:, ['N(x)H(y)', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bpinter_isoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_isoNORMv3_df = bpinter_isoNORMv3_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='d_norm_IsotopeArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=inter_nxhy_fix_order)\n",
    "                bpinterNORM_dfall_lstv3.append(bpinter_isoNORMv3_df)\n",
    "                bpinterNORM_label_lstv3.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp norm v3\n",
    "                p_isoNORMv3_df = onlyp.loc[:, ['N(x)H(y)', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                p_isoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORMv3_df = p_isoNORMv3_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                pNORM_dfall_lstv3.append(p_isoNORMv3_df)\n",
    "                pNORM_label_lstv3.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp sum v3\n",
    "                p_isoSUMv3_df = onlyp.loc[:, ['N(x)H(y)', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']]\n",
    "                p_isoSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUMv3_df = p_isoSUMv3_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                p_isoSUMv3_df_nsum = [p_isoSUMv3_df.loc[i].sum() for i in p_isoSUMv3_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv3.append(p_isoSUMv3_df)\n",
    "                pSUM_label_lstv3.append('sum_IsotopeArea[pGlyco]')\n",
    "                pSUM_nsum_lstv3.append(p_isoSUMv3_df_nsum)\n",
    "\n",
    "            if plot_v4 == 'yes':\n",
    "                # bpuion norm v4\n",
    "                bpunion_isoNORMv4_df = bp_union.loc[:, ['(F)N(x)H(y)', 'N-site(Byonic ∪ pGlyco) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bpunion_isoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpunion_isoNORMv4_df = bpunion_isoNORMv4_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='d_norm_IsotopeArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=union_fnxhy_fix_order)\n",
    "                bpunionNORM_dfall_lstv4.append(bpunion_isoNORMv4_df)\n",
    "                bpunionNORM_label_lstv4.append('norm_IsotopeArea[pGlyco]')\n",
    "                # bptop10 norm v4\n",
    "                bptop10_isoNORMv4_df = bptop10.loc[:, ['(F)N(x)H(y)', f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bptop10_isoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bptop10_isoNORMv4_df = bptop10_isoNORMv4_df.pivot_table(index=f'N-site(Byonic ∪ pGlyco [Top{topN}]) →', values='d_norm_IsotopeArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=top10_fnxhy_fix_order)\n",
    "                bptop10NORM_dfall_lstv4.append(bptop10_isoNORMv4_df)\n",
    "                bptop10NORM_label_lstv4.append('norm_IsotopeArea[pGlyco]')\n",
    "                # bpinter norm v4\n",
    "                bpinter_isoNORMv4_df = bp_inter.loc[:, ['(F)N(x)H(y)', 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                bpinter_isoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                bpinter_isoNORMv4_df = bpinter_isoNORMv4_df.pivot_table(index='N-site(Byonic ∩ pGlyco [Glycan B=P]) →', values='d_norm_IsotopeArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=inter_fnxhy_fix_order)\n",
    "                bpinterNORM_dfall_lstv4.append(bpinter_isoNORMv4_df)\n",
    "                bpinterNORM_label_lstv4.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp norm v4\n",
    "                p_isoNORMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                p_isoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORMv4_df = p_isoNORMv4_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                pNORM_dfall_lstv4.append(p_isoNORMv4_df)\n",
    "                pNORM_label_lstv4.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp sum v4\n",
    "                p_isoSUMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']]\n",
    "                p_isoSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUMv4_df = p_isoSUMv4_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                p_isoSUMv4_df_nsum = [p_isoSUMv4_df.loc[i].sum() for i in p_isoSUMv4_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv4.append(p_isoSUMv4_df)\n",
    "                pSUM_label_lstv4.append('sum_IsotopeArea[pGlyco]')\n",
    "                pSUM_nsum_lstv4.append(p_isoSUMv4_df_nsum)    \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if export_xicauc == export_int == export_mono == export_isotope == 'no': # no plots will be exported\n",
    "            pass\n",
    "        else: # plotting criterium: cannot be empty list\n",
    "\n",
    "            if bpunionNORM_dfall_lstv1 != []:\n",
    "                # bp_union NORMv1\n",
    "                fig = plot_clustered_stacked(bpunionNORM_dfall_lstv1, [[1]*len(bpunionNORM_dfall_lstv1[0].index) for i in range(len(bpunionNORM_dfall_lstv1))], bpunionNORM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bpUnionNORMv1_{filename}.png', bbox_inches='tight')\n",
    "            if bpunionNORM_dfall_lstv2 != []:\n",
    "                # bp_union NORMv2\n",
    "                fig = plot_clustered_stacked(bpunionNORM_dfall_lstv2, [[1]*len(bpunionNORM_dfall_lstv2[0].index) for i in range(len(bpunionNORM_dfall_lstv2))], bpunionNORM_label_lstv2, neugc_exist=bpunion_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bpUnionNORMv2_{filename}.png', bbox_inches='tight')\n",
    "            if bpunionNORM_dfall_lstv3 != []: # detailedHighMan=True, fucosylation=False(default), hybrid=colorHybrid(default=True)\n",
    "                # bp_union NORMv3\n",
    "                fig = plot_clustered_stacked(bpunionNORM_dfall_lstv3, [[1]*len(bpunionNORM_dfall_lstv3[0].index) for i in range(len(bpunionNORM_dfall_lstv3))], bpunionNORM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bpUnionNORMv3_{filename}.png', bbox_inches='tight')\n",
    "            if bpunionNORM_dfall_lstv4 != []: # detailedHighMan=True, fucosylation=True, hybrid=colorHybrid(default=True)\n",
    "                # bp_union NORMv4\n",
    "                fig = plot_clustered_stacked(bpunionNORM_dfall_lstv4, [[1]*len(bpunionNORM_dfall_lstv4[0].index) for i in range(len(bpunionNORM_dfall_lstv4))], bpunionNORM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bpUnionNORMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "            if bptop10NORM_dfall_lstv1 != []:\n",
    "                # bptop10 NORMv1\n",
    "                fig = plot_clustered_stacked(bptop10NORM_dfall_lstv1, [[1]*len(bptop10NORM_dfall_lstv1[0].index) for i in range(len(bptop10NORM_dfall_lstv1))], bptop10NORM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bptop{topN}NORMv1_{filename}.png', bbox_inches='tight')\n",
    "            if bptop10NORM_dfall_lstv2 != []:\n",
    "                # bptop10 NORMv2\n",
    "                fig = plot_clustered_stacked(bptop10NORM_dfall_lstv2, [[1]*len(bptop10NORM_dfall_lstv2[0].index) for i in range(len(bptop10NORM_dfall_lstv2))], bptop10NORM_label_lstv2, neugc_exist=bptop10_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bptop{topN}NORMv2_{filename}.png', bbox_inches='tight')\n",
    "            if bptop10NORM_dfall_lstv3 != []:\n",
    "                # bptop10 NORMv3\n",
    "                fig = plot_clustered_stacked(bptop10NORM_dfall_lstv3, [[1]*len(bptop10NORM_dfall_lstv3[0].index) for i in range(len(bptop10NORM_dfall_lstv3))], bptop10NORM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bptop{topN}NORMv3_{filename}.png', bbox_inches='tight')\n",
    "            if bptop10NORM_dfall_lstv4 != []:\n",
    "                # bptop10 NORMv4\n",
    "                fig = plot_clustered_stacked(bptop10NORM_dfall_lstv4, [[1]*len(bptop10NORM_dfall_lstv4[0].index) for i in range(len(bptop10NORM_dfall_lstv4))], bptop10NORM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bptop{topN}NORMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "            if bpinterNORM_dfall_lstv1 != []:\n",
    "                # bp_intersection NORMv1\n",
    "                fig = plot_clustered_stacked(bpinterNORM_dfall_lstv1, [[1]*len(bpinterNORM_dfall_lstv1[0].index) for i in range(len(bpinterNORM_dfall_lstv1))], bpinterNORM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bpInterNORMv1_{filename}.png', bbox_inches='tight')\n",
    "            if bpinterNORM_dfall_lstv2 != []:\n",
    "                # bp_intersection NORMv2\n",
    "                fig = plot_clustered_stacked(bpinterNORM_dfall_lstv2, [[1]*len(bpinterNORM_dfall_lstv2[0].index) for i in range(len(bpinterNORM_dfall_lstv2))], bpinterNORM_label_lstv2, neugc_exist=bpinter_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bpInterNORMv2_{filename}.png', bbox_inches='tight')\n",
    "            if bpinterNORM_dfall_lstv3 != []:\n",
    "                # bp_intersection NORMv3\n",
    "                fig = plot_clustered_stacked(bpinterNORM_dfall_lstv3, [[1]*len(bpinterNORM_dfall_lstv3[0].index) for i in range(len(bpinterNORM_dfall_lstv3))], bpinterNORM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bpInterNORMv3_{filename}.png', bbox_inches='tight')\n",
    "            if bpinterNORM_dfall_lstv4 != []:\n",
    "                # bp_intersection NORMv4\n",
    "                fig = plot_clustered_stacked(bpinterNORM_dfall_lstv4, [[1]*len(bpinterNORM_dfall_lstv4[0].index) for i in range(len(bpinterNORM_dfall_lstv4))], bpinterNORM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_bpInterNORMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "            if bNORM_dfall_lstv1 != []:\n",
    "                # onlyb NORMv1\n",
    "                fig = plot_clustered_stacked(bNORM_dfall_lstv1, [[1]*len(bNORM_dfall_lstv1[0].index) for i in range(len(bNORM_dfall_lstv1))],bNORM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybNORMv1_{filename}.png', bbox_inches='tight')\n",
    "            if bNORM_dfall_lstv2 != []:\n",
    "                # onlyb NORMv2\n",
    "                fig = plot_clustered_stacked(bNORM_dfall_lstv2, [[1]*len(bNORM_dfall_lstv2[0].index) for i in range(len(bNORM_dfall_lstv2))],bNORM_label_lstv2, neugc_exist=b_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybNORMv2_{filename}.png', bbox_inches='tight')\n",
    "            if bNORM_dfall_lstv3 != []:\n",
    "                # onlyb NORMv3\n",
    "                fig = plot_clustered_stacked(bNORM_dfall_lstv3, [[1]*len(bNORM_dfall_lstv3[0].index) for i in range(len(bNORM_dfall_lstv3))],bNORM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybNORMv3_{filename}.png', bbox_inches='tight')\n",
    "            if bNORM_dfall_lstv4 != []:\n",
    "                # onlyb NORMv4\n",
    "                fig = plot_clustered_stacked(bNORM_dfall_lstv4, [[1]*len(bNORM_dfall_lstv4[0].index) for i in range(len(bNORM_dfall_lstv4))],bNORM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybNORMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "            if bSUM_dfall_lstv1 != []:\n",
    "                # onlyb SUMv1\n",
    "                fig = plot_clustered_stacked(bSUM_dfall_lstv1, bSUM_nsum_lstv1,bSUM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybSUMv1_{filename}.png', bbox_inches='tight')\n",
    "            if bSUM_dfall_lstv2 != []:\n",
    "                # onlyb SUMv2\n",
    "                fig = plot_clustered_stacked(bSUM_dfall_lstv2,bSUM_nsum_lstv2 ,bSUM_label_lstv2, neugc_exist=b_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybSUMv2_{filename}.png', bbox_inches='tight')\n",
    "            if bSUM_dfall_lstv3 != []:\n",
    "                # onlyb SUMv3\n",
    "                fig = plot_clustered_stacked(bSUM_dfall_lstv3, bSUM_nsum_lstv3,bSUM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybSUMv3_{filename}.png', bbox_inches='tight')\n",
    "            if bSUM_dfall_lstv4 != []:\n",
    "                # onlyb SUMv4\n",
    "                fig = plot_clustered_stacked(bSUM_dfall_lstv4,bSUM_nsum_lstv4 ,bSUM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybSUMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "            if pNORM_dfall_lstv1 != []:\n",
    "                # onlyp NORMv1\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv1,[[1]*len(pNORM_dfall_lstv1[0].index) for i in range(len(pNORM_dfall_lstv1))],pNORM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv1_{filename}.png', bbox_inches='tight')\n",
    "            if pNORM_dfall_lstv2 != []:\n",
    "                # onlyp NORMv2\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv2,[[1]*len(pNORM_dfall_lstv2[0].index) for i in range(len(pNORM_dfall_lstv2))],pNORM_label_lstv2, neugc_exist=p_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv2_{filename}.png', bbox_inches='tight')\n",
    "            if pNORM_dfall_lstv3 != []:\n",
    "                # onlyp NORMv3\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv3,[[1]*len(pNORM_dfall_lstv3[0].index) for i in range(len(pNORM_dfall_lstv3))],pNORM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv3_{filename}.png', bbox_inches='tight')\n",
    "            if pNORM_dfall_lstv4 != []:\n",
    "                # onlyp NORMv4\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv4,[[1]*len(pNORM_dfall_lstv4[0].index) for i in range(len(pNORM_dfall_lstv4))],pNORM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "            if pSUM_dfall_lstv1 != []:\n",
    "                # onlyp SUMv1\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv1,pSUM_nsum_lstv1,pSUM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv1_{filename}.png', bbox_inches='tight')\n",
    "            if pSUM_dfall_lstv2 != []:\n",
    "                # onlyp SUMv2\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv2,pSUM_nsum_lstv2 ,pSUM_label_lstv2, neugc_exist=p_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv2_{filename}.png', bbox_inches='tight')\n",
    "            if pSUM_dfall_lstv3 != []:\n",
    "                # onlyp SUMv3\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv3,pSUM_nsum_lstv3,pSUM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv3_{filename}.png', bbox_inches='tight')\n",
    "            if pSUM_dfall_lstv4 != []:\n",
    "                # onlyp SUMv4\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv4,pSUM_nsum_lstv4 ,pSUM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "        if seq != '':\n",
    "            print('----- Start preparing MajorGlycoformTable. -----\\n')\n",
    "            # prepare needed lists for the table cols (no./nsite/sequon are the indices, major glycoform is the col)\n",
    "            result = findNPosBySequon(seq)\n",
    "            nsite = [t[0] for t in result]\n",
    "            nsite.append('')\n",
    "            sequon = [t[1] for t in result]\n",
    "            sequon.append('')\n",
    "            no = [i+1 for i in range(len(nsite)-1)]\n",
    "            no.append('Intersection/Union')\n",
    "            table = [(no[i], nsite[i], sequon[i]) for i in range(len(no))]\n",
    "            table = pd.DataFrame(table)\n",
    "            table.columns = ['No.', 'N-site', 'Sequon']\n",
    "            # rename col & extract xicauc max and its glycoform\n",
    "            bp_union = bp_union.rename(columns={'Glycans ↓':'Major Glycoform(union)'}).drop_duplicates().reset_index(drop=True)\n",
    "            bp_inter = bp_inter.rename(columns={'Glycans ↓':'Major Glycoform(inter)'}).drop_duplicates().reset_index(drop=True)\n",
    "            # (1 OF 2 WAYS TO DETERMINE MAJOR GLYCOFORM) TABLE1: CHOOSE HIGHEST XICAUC (yu-chun's version: from quant, so man4 & other below-core are not cleaned)\n",
    "            # bp_union = bp_union.groupby('N-site(Byonic ∪ pGlyco) →').apply(lambda x: x.loc[x['a_norm_XIC\\r\\nAUC[Byos]'].idxmax(), ['N-site(Byonic ∪ pGlyco) →', 'Major Glycoform(union)']]).reset_index(drop=True)\n",
    "            bp_union_forTable1 = bp_union.groupby('N-site(Byonic ∪ pGlyco) →').apply(lambda x: x.loc[x['a_norm_XIC\\r\\nAUC[Byos]'].idxmax(), ['N-site(Byonic ∪ pGlyco) →', 'Major Glycoform(union)']] if x['a_norm_XIC\\r\\nAUC[Byos]'].mean()!=-1 else x.loc[x['d_norm_IsotopeArea[pGlyco]'].idxmax(), ['N-site(Byonic ∪ pGlyco) →', 'Major Glycoform(union)']]).reset_index(drop=True)\n",
    "            bp_inter_forTable1 = bp_inter.groupby('N-site(Byonic ∩ pGlyco [Glycan B=P]) →').apply(lambda x: x.loc[x['a_norm_XIC\\r\\nAUC[Byos]'].idxmax(), ['N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'Major Glycoform(inter)']]).reset_index(drop=True)      \n",
    "            bp_union_forTable1 = bp_union_forTable1.set_index('N-site(Byonic ∪ pGlyco) →')\n",
    "            bp_inter_forTable1 = bp_inter_forTable1.set_index('N-site(Byonic ∩ pGlyco [Glycan B=P]) →')\n",
    "            combined = pd.concat([bp_inter_forTable1, bp_union_forTable1], axis=1)\n",
    "            combined.index.name = 'N-site'\n",
    "            combined = combined.reset_index()\n",
    "            combined.loc[(combined['Major Glycoform(inter)']!=combined['Major Glycoform(union)']), 'compare'] = 'color'\n",
    "            dif_num = len(combined.loc[(combined['Major Glycoform(inter)'].isnull())&(combined['compare']=='color')])\n",
    "            union_num = len(combined)\n",
    "            inter_num = union_num - dif_num\n",
    "            # map the result to the empty df\n",
    "            table1 = table.merge(combined, on=['N-site'], how='outer')\n",
    "            table1.loc[table1.index[-1], 'Major Glycoform(union)'] = f'{inter_num}/{union_num}'\n",
    "            # style apply to union only data\n",
    "            table1 = table1.fillna('').style.applymap(findUnionOnly, subset=pd.IndexSlice[(table1['compare']=='color'), 'Major Glycoform(union)'])\n",
    "            table1.data = table1.data.drop('compare', axis=1)\n",
    "            # (2 OF 2 WAYS TO DETERMINE MAJOR GLYCOFORM) TABLE2: CHOOSE MAJOR CLASS (HIGHMAN/HYBRID/COMPLEX/UNOCCUPIED) -> CHOOSE HIGHEST XICAUC WITHIN MAJOR CLASS (danny's version: man4 & other below-core are cleaned, just like data used for xicauc bar/pie charts)\n",
    "            # clean man4 & below-core structure & add glycan classes col by ModifiedGlycanTypeAnalysis func (highman/hybrid/complex/unoccupied) \n",
    "            bp_union_forTable2 = ModifiedGlycanTypeAnalysis(bp_union, 'Major Glycoform(union)')\n",
    "            bp_inter_forTable2 = ModifiedGlycanTypeAnalysis(bp_inter, 'Major Glycoform(inter)')\n",
    "            bp_union_forTable2 = normalizer(bp_union_forTable2, 'N-site(Byonic ∪ pGlyco) →')\n",
    "            bp_inter_forTable2 = normalizer(bp_inter_forTable2, 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →')\n",
    "            # bp_union_forTable2.to_excel('bp_union_forTable2_norm.xlsx')\n",
    "            # bp_inter_forTable2.to_excel('bp_inter_forTable2_norm.xlsx')\n",
    "            # find major class then find the xicauc / isotope area max within major class\n",
    "            bp_union_forTable2 = findMajorClass(bp_union_forTable2, 'N-site(Byonic ∪ pGlyco) →', 'Major Glycoform(union)')\n",
    "            bp_inter_forTable2 = findMajorClass(bp_inter_forTable2, 'N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'Major Glycoform(inter)')\n",
    "            # bp_union_forTable2.to_excel('bp_union_forTable2_majorclass.xlsx')\n",
    "            # bp_inter_forTable2.to_excel('bp_inter_forTable2_majorclass.xlsx')\n",
    "            \n",
    "            bp_union_forTable2 = bp_union_forTable2.groupby('N-site(Byonic ∪ pGlyco) →').apply(lambda x: x.loc[x['a_norm_XIC\\r\\nAUC[Byos]'].idxmax(), ['N-site(Byonic ∪ pGlyco) →', 'Major Glycoform(union)']] if x['a_norm_XIC\\r\\nAUC[Byos]'].mean()!=-1 else x.loc[x['d_norm_IsotopeArea[pGlyco]'].idxmax(), ['N-site(Byonic ∪ pGlyco) →', 'Major Glycoform(union)']]).reset_index(drop=True)\n",
    "            bp_inter_forTable2 = bp_inter_forTable2.groupby('N-site(Byonic ∩ pGlyco [Glycan B=P]) →').apply(lambda x: x.loc[x['a_norm_XIC\\r\\nAUC[Byos]'].idxmax(), ['N-site(Byonic ∩ pGlyco [Glycan B=P]) →', 'Major Glycoform(inter)']]).reset_index(drop=True)      \n",
    "    #         bp_union_forTable2.to_excel('bp_union_forTable2_gp.xlsx')\n",
    "    #         bp_inter_forTable2.to_excel('bp_inter_forTable2_gp.xlsx')\n",
    "            bp_union_forTable2 = bp_union_forTable2.set_index('N-site(Byonic ∪ pGlyco) →')\n",
    "            bp_inter_forTable2 = bp_inter_forTable2.set_index('N-site(Byonic ∩ pGlyco [Glycan B=P]) →')\n",
    "            combined = pd.concat([bp_inter_forTable2, bp_union_forTable2], axis=1)\n",
    "            combined.index.name = 'N-site'\n",
    "            combined = combined.reset_index()\n",
    "            combined.loc[(combined['Major Glycoform(inter)']!=combined['Major Glycoform(union)']), 'compare'] = 'color'\n",
    "            dif_num = len(combined.loc[(combined['Major Glycoform(inter)'].isnull())&(combined['compare']=='color')])\n",
    "            union_num = len(combined)\n",
    "            inter_num = union_num - dif_num\n",
    "            # map the result to the empty df\n",
    "            table2 = table.merge(combined, on=['N-site'], how='outer')\n",
    "            table2.loc[table2.index[-1], 'Major Glycoform(union)'] = f'{inter_num}/{union_num}'\n",
    "            # style apply to union only data\n",
    "            table2 = table2.fillna('').style.applymap(findUnionOnly, subset=pd.IndexSlice[(table2['compare']=='color'), 'Major Glycoform(union)'])\n",
    "            table2.data = table2.data.drop('compare', axis=1)\n",
    "\n",
    "            with pd.ExcelWriter(f'{date}_MajorGlycoformTable_{filename}.xlsx') as writer:   \n",
    "                table1.to_excel(writer, sheet_name = 'XICAUC max. within site', index=False)\n",
    "                table2.to_excel(writer, sheet_name = 'XICAUC max. within major class', index=False)\n",
    "\n",
    "            print('\\n----- MajorGlycoformTable exported. -----\\n')\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile != '': # byonic + pglyco \n",
    "        print('----- Start combining Byonic & pGlyco. -----\\n')\n",
    "        # combined data based on 'Scan'\n",
    "        byonic_scanasid = byonic_df.copy()\n",
    "        new_byonic_col = [n + '[Byonic]' if n != 'Scan' else n for n in byonic_scanasid.columns]\n",
    "        byonic_scanasid.columns = new_byonic_col\n",
    "        pglyco_scanasid = pglyco_df.copy()\n",
    "        new_pglyco_col = [n + '[pGlyco]' if n != 'Scan' else n for n in pglyco_scanasid.columns]\n",
    "        pglyco_scanasid.columns = new_pglyco_col\n",
    "        byonic_scanasid = byonic_scanasid.set_index('Scan')\n",
    "        pglyco_scanasid = pglyco_scanasid.set_index('Scan')\n",
    "        # align scan & concat (all align on row to make row number all the same)\n",
    "        a1, a2 = byonic_scanasid.align(pglyco_scanasid, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        all_combined_df = pd.concat([a1,a2], axis = 1)\n",
    "        all_combined_df.index.name = 'Scan'\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        all_combined_df = all_combined_df.fillna(-1)\n",
    "        all_combined_df.to_excel('20210819_all.xlsx', index=False)\n",
    "        move_df(all_combined_df, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        ## result post-processing \n",
    "        glycansource(all_combined_df, 'Scan')\n",
    "        print('\\nCombined data shape:\\nrow --> %s, column --> %s'%(all_combined_df.shape[0], all_combined_df.shape[1]))\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > BYONIC_SCORE_CUTOFF & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "\n",
    "        byonic_colored_id = list(set(lightgreen_ind + normalgreen_ind + lightorange_ind + normalorange_ind + deepgreen_ind)) # byonic pass threshold (include below-threshold ethcd w/o pair) \n",
    "        byonic_colored_id_for_pairfile = byonic_colored_id.copy()\n",
    "        pglyco_colored_id = list(set(lightblue_ind + normalblue_ind + lightorange_ind + normalorange_ind + deepblue_ind)) # pglyco pass threshold\n",
    "        pglyco_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in pglyco_colored_id]\n",
    "        ## analyze PSM (need to pass threshold)\n",
    "        # need to record the ind of below-threshold ethcd w/o pair in advance (will be excluded later, so we should not count PSM as well)\n",
    "        # so here we are forced to find pair in advance (since we are forced to list psm in all file)\n",
    "        if 'Pair[Byonic]' in all_combined_df.columns.tolist(): # pair is to identify etd with pass-threshold hcd pair for later rescue\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair[Byonic]': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id]\n",
    "            pair_df = pair_df[pair_df['Pair[Byonic]'].str.contains('pair')]\n",
    "            pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if 'ethcd' in all_combined_df['Fragment\\r\\nType[Byonic]'].tolist(): # if etd data is present (i.e. have pair)\n",
    "            byonic_excluded_ethcd_ind =  all_combined_df.loc[((all_combined_df['Fragment\\r\\nType[Byonic]'] == 'ethcd')&((all_combined_df['Score[Byonic]'] <= BYONIC_SCORE_CUTOFF)|(all_combined_df['PEP\\r\\n2D[Byonic]'].abs() >= 0.001))&(~(all_combined_df['Pair[Byonic]'].isin(pair_df['Pair[Byonic]']))))].index.tolist()\n",
    "            byonic_pass_id = [i for i in byonic_colored_id if i not in byonic_excluded_ethcd_ind]\n",
    "            byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_pass_id] \n",
    "        else: # all hcd, all in (cause here all the hcd are above threshold, i.e. all colored)\n",
    "            byonic_pass_id = byonic_colored_id \n",
    "            byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_pass_id] \n",
    "\n",
    "        # using groupby size function to count psm & add psm columns (new criterion: add fragment type, RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif.)\n",
    "        # byonic & byos\n",
    "        all_combined_df = all_combined_df.astype({'N-site(SequonBased)[Byonic]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        b_df_pass = all_combined_df.loc[byonic_pass_id]\n",
    "        b_df_pass_forUnique = ScantimeGp(b_df_pass, gp_by = ['Fragment\\r\\nType[Byonic]', 'N-site(SequonBased)[Byonic]',  'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]'], score_col = 'Score[Byonic]', rt_col = 'Scan\\r\\nTime[Byonic]', software = '[Byonic]', purpose = 'forUnique')\n",
    "        b_df_pass_forNglyco = ScantimeGp(b_df_pass, gp_by = ['N-site(SequonBased)[Byonic]',  'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]'], score_col = 'Score[Byonic]', rt_col = 'Scan\\r\\nTime[Byonic]', software = '[Byonic]', purpose = 'forNglyco')\n",
    "        # b_df_pass_forNglyco.to_excel('b_df_pass_forNglyco.xlsx', index=False)\n",
    "        byonic_psm = b_df_pass_forNglyco.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset_forNglyco[Byonic]'])['N-site(SequonBased)[Byonic]'].transform('size')\n",
    "        \n",
    "        all_combined_df.loc[(byonic_pass_id), 'PSM[Byonic]'] = byonic_psm\n",
    "        move_df(all_combined_df, 'PSM[Byonic]', 'N-site(SequonBased)[Byonic]')\n",
    "        all_combined_df.loc[(byonic_pass_id), 'rt_dif_reset_forUnique[Byonic]'] = b_df_pass_forUnique['rt_dif_reset_forUnique[Byonic]']\n",
    "        all_combined_df.loc[(byonic_pass_id), 'rt_dif_reset_forNglyco[Byonic]'] = b_df_pass_forNglyco['rt_dif_reset_forNglyco[Byonic]']\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == 'N/A'), 'PSM[Byonic]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[byonic_belowthreshold_id, 'PSM[Byonic]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == '-1'), 'PSM[Byonic]'] = -1 # if site is '-1', then psm set to -1\n",
    "        # pglyco\n",
    "        all_combined_df = all_combined_df.astype({'ProSites[pGlyco]': 'int'})\n",
    "        all_combined_df = all_combined_df.astype({'ProSites[pGlyco]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        p_df_pass = all_combined_df.loc[pglyco_colored_id]\n",
    "        p_df_pass_forUnique = ScantimeGp(p_df_pass, gp_by = ['FragmentType[pGlyco]', 'ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]'], score_col = 'PepScore[pGlyco]', rt_col = 'RT[pGlyco]', software = '[pGlyco]', purpose = 'forUnique')\n",
    "        p_df_pass_forNglyco = ScantimeGp(p_df_pass, gp_by = ['ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]'], score_col = 'PepScore[pGlyco]', rt_col = 'RT[pGlyco]', software = '[pGlyco]', purpose = 'forNglyco')\n",
    "        \n",
    "        pglyco_psm = p_df_pass_forNglyco.groupby(['ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]'])['ProSites[pGlyco]'].transform('size')\n",
    "        all_combined_df.loc[(pglyco_colored_id), 'PSM[pGlyco]'] = pglyco_psm\n",
    "        move_df(all_combined_df, 'PSM[pGlyco]', 'ProSites[pGlyco]')\n",
    "        all_combined_df.loc[(pglyco_colored_id), 'rt_dif_reset_forUnique[pGlyco]'] = p_df_pass_forUnique['rt_dif_reset_forUnique[pGlyco]']\n",
    "        all_combined_df.loc[(pglyco_colored_id), 'rt_dif_reset_forNglyco[pGlyco]'] = p_df_pass_forNglyco['rt_dif_reset_forNglyco[pGlyco]']\n",
    "        all_combined_df.loc[(all_combined_df['ProSites[pGlyco]'] == 'N/A'), 'PSM[pGlyco]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[pglyco_belowthreshold_id, 'PSM[pGlyco]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['ProSites[pGlyco]'] == '-1'), 'PSM[pGlyco]'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'rt_dif_reset_forUnique[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]'], axis = 1)\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_All_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "        \n",
    "        if 'Pair[Byonic]' in all_combined_df.columns.tolist(): # pair is to identify etd with pass-threshold hcd pair for later rescue\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair[Byonic]': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id_for_pairfile]\n",
    "            pair_df = pair_df[pair_df['Pair[Byonic]'].str.contains('pair')]\n",
    "            pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            threshold_masks_colorind(pair_df)\n",
    "            print('\\n----- Exporting \"_Pair\" file... This may take some time, please wait. -----\\n')\n",
    "            pair_df.style.apply(bg_color, axis=None).to_excel(f'{date}_Pair_{filename}.xlsx', index = False)  \n",
    "            print('\\n----- \"_Pair\" file exported. -----\\n')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        # extract rows included in colored indices list separately\n",
    "        byonicbyos_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[Byonic]' in col or '[Byos]' in col]\n",
    "        pglyco_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[pGlyco]' in col]\n",
    "        simple_byonicbyos = all_forsimple_df.loc[byonic_pass_id, byonicbyos_col_range] # extract colored (pass threshold) rows - below-threshold ethcd w/o pair\n",
    "        simple_pglyco = all_forsimple_df.loc[pglyco_colored_id, pglyco_col_range] # extract colored (pass threshold) rows\n",
    "        \n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != '-1')] # preserve n/a sites for potential o glycan data in unique\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != 'N/A')&(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != '-1')] # for simplified, n-site must exist\n",
    "        \n",
    "        simple_pglyco_forUnique = simple_pglyco[(simple_pglyco['ProSites[pGlyco]'] != '-1')] # preserve n/a sites for potential o glycan data in unique\n",
    "        simple_pglyco_forNglyco = simple_pglyco[(simple_pglyco['ProSites[pGlyco]'] != 'N/A')&(simple_pglyco['ProSites[pGlyco]'] != '-1')] # for simplified, n-site must exist\n",
    "\n",
    "        # for nglycopep\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.loc[simple_pglyco_forNglyco['FragmentType[pGlyco]'] == 'hcd'] # pglyco etd has the same values as hcd, so only let hcd enter unique file\n",
    "        \n",
    "        # clean data by dropping duplicates        \n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.drop_duplicates().reset_index(drop=True)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        simple_pglyco_forUnique = simple_pglyco_forUnique.drop_duplicates().reset_index(drop=True)\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        # HIGHSCORE SELECTION: get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.groupby(['Fragment\\r\\nType[Byonic]', 'N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset_forUnique[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score[Byonic]'].idxmax()]).reset_index(drop=True)\n",
    "        simple_pglyco_forUnique = simple_pglyco_forUnique.groupby(['FragmentType[pGlyco]', 'ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset_forUnique[pGlyco]'], as_index=False).apply(lambda x: x.loc[x['PepScore[pGlyco]'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset_forNglyco[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score[Byonic]'].idxmax()]).reset_index(drop=True)\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.groupby(['ProSites[pGlyco]', 'rounded_PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]'], as_index=False).apply(lambda x: x.loc[x['PepScore[pGlyco]'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan (for unique)\n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.set_index('Scan')\n",
    "        simple_pglyco_forUnique = simple_pglyco_forUnique.set_index('Scan')\n",
    "        a1, a2 = simple_byonicbyos_forUnique.align(simple_pglyco_forUnique, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        id_df_forUnique = pd.concat([a1,a2], axis = 1)\n",
    "        id_df_forUnique.index.name = 'Scan'\n",
    "        id_df_forUnique.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        id_df_forUnique = id_df_forUnique.fillna(-1)\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df_forUnique['Mods\\r\\n(variable)[Byonic]'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df_forUnique['glycan_mods_sum[Byonic]'] = mods_nglycan_sum\n",
    "        id_df_forUnique['PepMS[Byonic]'] = id_df_forUnique['Calc.\\r\\nMH[Byonic]'] - id_df_forUnique['glycan_mods_sum[Byonic]']\n",
    "        id_df_forUnique.loc[(id_df_forUnique['glycan_mods_sum[Byonic]'] == -1), 'PepMS[Byonic]'] = -1\n",
    "        move_df(id_df_forUnique, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        move_df(id_df_forUnique, 'PepMS[Byonic]', 'Fragment\\r\\nType[Byonic]')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forUnique['N-site(SequonBased)[Byonic]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i and i!='N/A' else i for i in id_df_forUnique['N-site(SequonBased)[Byonic]'].tolist()] # convert str back to int & tuple\n",
    "        id_df_forUnique['ProSites[pGlyco]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i and i!='N/A' else i for i in id_df_forUnique['ProSites[pGlyco]'].tolist()] # convert str back to int & tuple\n",
    "        \n",
    "        id_df_forUnique.loc[(id_df_forUnique['N-site(SequonBased)[Byonic]'] == -1), 'mock_site[Byonic]'] = id_df_forUnique['ProSites[pGlyco]']\n",
    "        id_df_forUnique.loc[(id_df_forUnique['N-site(SequonBased)[Byonic]'] != -1), 'mock_site[Byonic]'] = id_df_forUnique['N-site(SequonBased)[Byonic]']\n",
    "        # drop intermediate cols\n",
    "        id_df_forUnique = id_df_forUnique.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'rt_dif_reset_forUnique[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]', 'glycan_mods_sum[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "        glycansource(id_df_forUnique, 'Scan')\n",
    "        move_df(id_df_forUnique, 'mock_site[Byonic]', 'GlycanSource')\n",
    "        col_order = id_df_forUnique.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Charge[pGlyco]')\n",
    "        print('Done sorting by Charge[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PrecursorMH[pGlyco]')\n",
    "        print('Done sorting by PrecursorMH[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PeptideMH[pGlyco]')\n",
    "        print('Done sorting by PeptideMH[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        print('Done sorting by GlycanComposition_ByonicStyle[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Peptide[pGlyco]')\n",
    "        print('Done sorting by Peptide[pGlyco] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'z[Byonic]')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Calc.\\r\\nMH[Byonic]')\n",
    "        print('Done sorting by Calc.MH[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PepMS[Byonic]')\n",
    "        print('Done sorting by PepMS[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'rounded_FinalGlycans[Byonic]')\n",
    "        print('Done sorting by rounded_FinalGlycans[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PureSequence[Byonic]')\n",
    "        print('Done sorting by PureSequence[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'mock_site[Byonic]')\n",
    "        print('Done sorting by mock_site[Byonic] (added during processing)')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forUnique['rounded_FinalGlycans[Byonic]'] = [int(i) if i == '-1' else i for i in id_df_forUnique['rounded_FinalGlycans[Byonic]']]\n",
    "        id_df_forUnique['GlycanComposition_ByonicStyle[pGlyco]'] = [int(i) if i == '-1' else i for i in id_df_forUnique['GlycanComposition_ByonicStyle[pGlyco]']]\n",
    "        id_df_forUnique = id_df_forUnique[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forUnique)\n",
    "        id_df_forUnique.style.apply(bg_color, axis=None).to_excel(f'{date}_UniquePep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_UniquePep\" file exported. -----\\n')\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan (for nglyco)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.set_index('Scan')\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.set_index('Scan')\n",
    "        a1, a2 = simple_byonicbyos_forNglyco.align(simple_pglyco_forNglyco, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        id_df_forNglyco = pd.concat([a1,a2], axis = 1)\n",
    "        id_df_forNglyco.index.name = 'Scan'\n",
    "        id_df_forNglyco.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        id_df_forNglyco = id_df_forNglyco.fillna(-1)\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df_forNglyco['Mods\\r\\n(variable)[Byonic]'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df_forNglyco['glycan_mods_sum[Byonic]'] = mods_nglycan_sum\n",
    "        id_df_forNglyco['PepMS[Byonic]'] = id_df_forNglyco['Calc.\\r\\nMH[Byonic]'] - id_df_forNglyco['glycan_mods_sum[Byonic]']\n",
    "        id_df_forNglyco.loc[(id_df_forNglyco['glycan_mods_sum[Byonic]'] == -1), 'PepMS[Byonic]'] = -1\n",
    "        move_df(id_df_forNglyco, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        move_df(id_df_forNglyco, 'PepMS[Byonic]', 'Fragment\\r\\nType[Byonic]')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forNglyco['N-site(SequonBased)[Byonic]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df_forNglyco['N-site(SequonBased)[Byonic]'].tolist()] # convert str back to int & tuple\n",
    "        id_df_forNglyco['ProSites[pGlyco]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df_forNglyco['ProSites[pGlyco]'].tolist()] # convert str back to int & tuple\n",
    "\n",
    "        id_df_forNglyco.loc[(id_df_forNglyco['N-site(SequonBased)[Byonic]'] == -1), 'mock_site[Byonic]'] = id_df_forNglyco['ProSites[pGlyco]']\n",
    "        id_df_forNglyco.loc[(id_df_forNglyco['N-site(SequonBased)[Byonic]'] != -1), 'mock_site[Byonic]'] = id_df_forNglyco['N-site(SequonBased)[Byonic]']\n",
    "        # drop intermediate cols\n",
    "        id_df_forNglyco = id_df_forNglyco.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'rt_dif_reset_forUnique[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]', 'glycan_mods_sum[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "        glycansource(id_df_forNglyco, 'Scan')\n",
    "        move_df(id_df_forNglyco, 'mock_site[Byonic]', 'GlycanSource')\n",
    "        col_order = id_df_forNglyco.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Charge[pGlyco]')\n",
    "        print('Done sorting by Charge[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PrecursorMH[pGlyco]')\n",
    "        print('Done sorting by PrecursorMH[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PeptideMH[pGlyco]')\n",
    "        print('Done sorting by PeptideMH[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        print('Done sorting by GlycanComposition_ByonicStyle[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Peptide[pGlyco]')\n",
    "        print('Done sorting by Peptide[pGlyco] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'z[Byonic]')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Calc.\\r\\nMH[Byonic]')\n",
    "        print('Done sorting by Calc.MH[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PepMS[Byonic]')\n",
    "        print('Done sorting by PepMS[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'rounded_FinalGlycans[Byonic]')\n",
    "        print('Done sorting by rounded_FinalGlycans[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PureSequence[Byonic]')\n",
    "        print('Done sorting by PureSequence[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'mock_site[Byonic]')\n",
    "        print('Done sorting by mock_site[Byonic] (added during processing)')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forNglyco['rounded_FinalGlycans[Byonic]'] = [int(i) if i == '-1' else i for i in id_df_forNglyco['rounded_FinalGlycans[Byonic]']]\n",
    "        id_df_forNglyco['GlycanComposition_ByonicStyle[pGlyco]'] = [int(i) if i == '-1' else i for i in id_df_forNglyco['GlycanComposition_ByonicStyle[pGlyco]']]\n",
    "        id_df_forNglyco = id_df_forNglyco[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_NglycoPep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forNglyco)\n",
    "        id_df_forNglyco.style.apply(bg_color, axis=None).to_excel(f'{date}_NglycoPep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_NglycoPep\" file exported. -----\\n')\n",
    "\n",
    "        print('----- Start preparing quantification file of N-glycosylation . -----\\n')\n",
    "        # only single sites for quant (quant_df offers important info. for later multiIndex df construction)\n",
    "        quant = id_df_forNglyco[id_df_forNglyco['N-site(SequonBased)[Byonic]'].apply(lambda x: isinstance(x, int))]\n",
    "        # avoid adding values from below-threshold rows: if deepgreen -> change value to -1, if deepblue -> change value to -1.(-1 to make lambda function easier to write)\n",
    "        threshold_masks_colorind(quant)\n",
    "        quant.loc[deepgreen_ind, ['MonoArea[pGlyco]', 'IsotopeArea[pGlyco]']] = -1\n",
    "        # calculate the sum within each n-site, then normalize mono/ iso by these sum\n",
    "        quant['sumpersite_mono'] = quant.groupby(['ProSites[pGlyco]'])['MonoArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        quant['sumpersite_iso'] = quant.groupby(['ProSites[pGlyco]'])['IsotopeArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        # convert all the 'N/A' in byonic glycans to 'Unoccupied'\n",
    "        quant.loc[(quant['rounded_FinalGlycans[Byonic]'] == 'N/A'), ['rounded_FinalGlycans[Byonic]']] = 'Unoccupied'\n",
    "        # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "        quant['g_sum_MonoArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['MonoArea[pGlyco]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['h_sum_IsotopeArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['IsotopeArea[pGlyco]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['c_norm_MonoArea[pGlyco]'] = quant['g_sum_MonoArea[pGlyco]']/quant['sumpersite_mono']\n",
    "        quant['d_norm_IsotopeArea[pGlyco]'] = quant['h_sum_IsotopeArea[pGlyco]']/quant['sumpersite_iso']\n",
    "        # since it's possible to have real 0 from calculation, change the real absent data back to -1 in sum_ & norm_\n",
    "        quant.loc[quant['MonoArea[pGlyco]'] == -1, ['g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'c_norm_MonoArea[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']] = -1\n",
    "        # extract the needed cols only & split byonicbyos/pglyco, drop all -1 rows, glycans as index to outer union concat data again\n",
    "        quant_bb = quant[['GlycanSource', 'N-site(SequonBased)[Byonic]', 'rounded_FinalGlycans[Byonic]']].rename(columns={'GlycanSource':'GlycanSource[Byonic]'})\n",
    "        quant_p = quant[['GlycanSource', 'ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]', 'g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'c_norm_MonoArea[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']].rename(columns={'GlycanSource':'GlycanSource[pGlyco]'})\n",
    "        quant_bb = quant_bb.loc[quant_bb['N-site(SequonBased)[Byonic]'] != -1]\n",
    "        quant_p = quant_p.loc[quant_p['ProSites[pGlyco]'] != -1]\n",
    "        quant_bb = quant_bb.set_index('rounded_FinalGlycans[Byonic]')\n",
    "        quant_p = quant_p.set_index('GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        a1, a2 = quant_bb.align(quant_p, join = 'outer', axis = 0) \n",
    "        quant_glycanid = pd.concat([a1,a2], axis = 1)\n",
    "        quant_glycanid.index.name = 'Glycans ↓'\n",
    "        quant_glycanid.reset_index(level=0, inplace=True)\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in quant_glycanid['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        quant_glycanid.insert(0 , 'N(x) ↓', nx , True)\n",
    "        move_df(quant_glycanid, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        # change all nan to blank -1\n",
    "        quant_glycanid = quant_glycanid.fillna(-1)\n",
    "        quant_glycanid = quant_glycanid.drop_duplicates() # remember to drop duplicates after splitting & reconcat df\n",
    "\n",
    "        ## onlyp\n",
    "        onlyp = quant_glycanid.loc[(quant_glycanid['ProSites[pGlyco]'] != -1), [col for col in quant_glycanid.columns.tolist() if 'Byonic' not in col and 'Byos' not in col]]\n",
    "        onlyp_forunion = onlyp.copy().drop_duplicates()\n",
    "        onlyp = onlyp.drop('GlycanSource[pGlyco]', axis = 1).drop_duplicates()\n",
    "        # clean off all no data rows\n",
    "        onlyp = onlyp.loc[~((onlyp['g_sum_MonoArea[pGlyco]']==-1)&(onlyp['h_sum_IsotopeArea[pGlyco]']==-1)&(onlyp['c_norm_MonoArea[pGlyco]']==-1)&(onlyp['d_norm_IsotopeArea[pGlyco]']==-1))]\n",
    "        nx = list(set(onlyp['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        p_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        print('----- Start summary table construction. -----\\n')\n",
    "        # start grouping: N(X) -> byonic glycans -> byonic sites -> .agg({all 8 cols, apply .mean() & .mean()/total XXX})\n",
    "\n",
    "        # onlyp\n",
    "        onlyp_gp = onlyp.groupby(['N(x) ↓', 'Glycans ↓', 'ProSites[pGlyco]']).agg({'g_sum_MonoArea[pGlyco]': lambda x: x.mean(), 'h_sum_IsotopeArea[pGlyco]': lambda x: x.mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x.mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x.mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        onlyp_gp = onlyp_gp.reindex(p_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        onlyp_gp = onlyp_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        onlyp_gp.columns = onlyp_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        onlyp_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        onlyp_gp.columns = onlyp_gp.columns.set_names(['ProSites[pGlyco] →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        onlyp_gp.columns.set_levels(['norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]', 'sum_MonoArea[pGlyco]', 'sum_IsotopeArea[pGlyco]'], level = 1, inplace=True)\n",
    "\n",
    "        print('\\n----- Exporting \"_Quant\" files... This may take some time, please wait. -----\\n')\n",
    "        \n",
    "        with pd.ExcelWriter(f'{date}_Quant_{filename}.xlsx') as writer:           \n",
    "            # onlyp\n",
    "            onlyp_gp.replace(to_replace = -1, value = np.nan , inplace = True) \n",
    "            onlyp_gp.style.background_gradient(cmap ='Blues').highlight_null(null_color='white').to_excel(writer, sheet_name = 'Sheet2(QuantP)')\n",
    "            \n",
    "        print('\\n----- \"_Quant\" file exported. -----\\n')\n",
    "        \n",
    "        print('----- Start plotting. -----\\n')\n",
    "\n",
    "        pNORM_dfall_lstv1, pNORM_label_lstv1, pNORM_dfall_lstv2, pNORM_label_lstv2 \\\n",
    "        , pNORM_dfall_lstv3, pNORM_label_lstv3, pNORM_dfall_lstv4, pNORM_label_lstv4 \\\n",
    "        , pSUM_dfall_lstv1, pSUM_label_lstv1, pSUM_nsum_lstv1, pSUM_dfall_lstv2, pSUM_label_lstv2, pSUM_nsum_lstv2 \\\n",
    "        , pSUM_dfall_lstv3, pSUM_label_lstv3, pSUM_nsum_lstv3, pSUM_dfall_lstv4, pSUM_label_lstv4, pSUM_nsum_lstv4 \\\n",
    "        = [], [], [], [], [], [], [], [], [], [] \\\n",
    "        , [], [], [], [], [], [], [], [], [], [] \n",
    "        \n",
    "        if plot_v2 == 'yes':  \n",
    "            col_order = ['N(0)', 'N(1)', 'OligoMannose', 'Complex', 'Complex+Sia'] # col order for v2 plotting\n",
    "            # necessary preprocessings for v2 plotting (modified from v1 nx)\n",
    "            # onlyp v2\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] == 'N(0)')|(onlyp['N(x) ↓'] == 'N(1)'), 'nx_version2'] = onlyp['N(x) ↓']\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] != 'N(0)')&(onlyp['N(x) ↓'] != 'N(1)')&(onlyp['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] != 'N(0)')&(onlyp['N(x) ↓'] != 'N(1)')&(onlyp['N(x) ↓'] != 'N(2)')&(onlyp['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "            p_neugc_exist = sum(onlyp['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "        \n",
    "        if plot_v3 == 'yes':\n",
    "            # necessary preprocessings for v3 plotting (modified from v1 nx)           \n",
    "            # onlyp v3\n",
    "            onlyp, onlyp_nxhy_fix_order = v3(onlyp)[0], v3(onlyp)[1]\n",
    "\n",
    "        if plot_v4 == 'yes':\n",
    "            # necessary preprocessings for v4 plotting (modified from v1 nx)            \n",
    "            # onlyp v4\n",
    "            onlyp, onlyp_fnxhy_fix_order = v4(onlyp)[0], v4(onlyp)[1]\n",
    "\n",
    "        # # make sure that sites are presented as int not float\n",
    "        onlyp = onlyp.astype({'ProSites[pGlyco]':'Int64'})\n",
    "\n",
    "        # split bp_union into: xicauc_df / int_df / mono_df / iso_df for later clustered stacked plot (norm only)\n",
    "        if export_mono == 'yes':\n",
    "            if plot_v1 == 'yes':\n",
    "                # onlyp norm v1\n",
    "                p_monoNORM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "                p_monoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORM_df = p_monoNORM_df.pivot_table(index='ProSites[pGlyco]', values='c_norm_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                pNORM_dfall_lstv1.append(p_monoNORM_df)\n",
    "                pNORM_label_lstv1.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp sum v1\n",
    "                p_monoSUM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "                p_monoSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUM_df = p_monoSUM_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                p_monoSUM_df_nsum = [p_monoSUM_df.loc[i].sum() for i in p_monoSUM_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv1.append(p_monoSUM_df)\n",
    "                pSUM_label_lstv1.append('sum_MonoArea[pGlyco]')\n",
    "                pSUM_nsum_lstv1.append(p_monoSUM_df_nsum)\n",
    "\n",
    "            if plot_v2 == 'yes':\n",
    "                # onlyp norm v2\n",
    "                p_monoNORMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "                p_monoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORMv2_df = p_monoNORMv2_df.pivot_table(index='ProSites[pGlyco]', values='c_norm_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                pNORM_dfall_lstv2.append(p_monoNORMv2_df)\n",
    "                pNORM_label_lstv2.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp sum v2\n",
    "                p_monoSUMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "                p_monoSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUMv2_df = p_monoSUMv2_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                p_monoSUMv2_df_nsum = [p_monoSUMv2_df.loc[i].sum() for i in p_monoSUMv2_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv2.append(p_monoSUMv2_df)\n",
    "                pSUM_label_lstv2.append('sum_MonoArea[pGlyco]')\n",
    "                pSUM_nsum_lstv2.append(p_monoSUMv2_df_nsum)\n",
    "\n",
    "            if plot_v3 == 'yes':\n",
    "                # onlyp norm v3\n",
    "                p_monoNORMv3_df = onlyb.loc[:, ['N(x)H(y)', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "                p_monoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORMv3_df = p_monoNORMv3_df.pivot_table(index='ProSites[pGlyco]', values='c_norm_MonoArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                pNORM_dfall_lstv3.append(p_monoNORMv3_df)\n",
    "                pNORM_label_lstv3.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp sum v3\n",
    "                p_monoSUMv3_df = onlyp.loc[:, ['N(x)H(y)', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "                p_monoSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUMv3_df = p_monoSUMv3_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                p_monoSUMv3_df_nsum = [p_monoSUMv3_df.loc[i].sum() for i in p_monoSUMv3_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv3.append(p_monoSUMv3_df)\n",
    "                pSUM_label_lstv3.append('sum_MonoArea[pGlyco]')\n",
    "                pSUM_nsum_lstv3.append(p_monoSUMv3_df_nsum)\n",
    "\n",
    "            if plot_v4 == 'yes':\n",
    "                # onlyp norm v4\n",
    "                p_monoNORMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "                p_monoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORMv4_df = p_monoNORMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='c_norm_MonoArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                pNORM_dfall_lstv4.append(p_monoNORMv4_df)\n",
    "                pNORM_label_lstv4.append('norm_MonoArea[pGlyco]')\n",
    "                # onlyp sum v4\n",
    "                p_monoSUMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "                p_monoSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUMv4_df = p_monoSUMv4_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                p_monoSUMv4_df_nsum = [p_monoSUMv4_df.loc[i].sum() for i in p_monoSUMv4_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv4.append(p_monoSUMv4_df)\n",
    "                pSUM_label_lstv4.append('sum_MonoArea[pGlyco]')\n",
    "                pSUM_nsum_lstv4.append(p_monoSUMv4_df_nsum)     \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if export_isotope == 'yes':\n",
    "            if plot_v1 == 'yes':\n",
    "                # onlyp norm v1\n",
    "                p_isoNORM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                p_isoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORM_df = p_isoNORM_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                pNORM_dfall_lstv1.append(p_isoNORM_df)\n",
    "                pNORM_label_lstv1.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp sum v1\n",
    "                p_isoSUM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']] \n",
    "                p_isoSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUM_df = p_isoSUM_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                p_isoSUM_df_nsum = [p_isoSUM_df.loc[i].sum() for i in p_isoSUM_df.index.tolist()] # for B bar label\n",
    "                pSUM_dfall_lstv1.append(p_isoSUM_df)\n",
    "                pSUM_label_lstv1.append('sum_IsotopeArea[pGlyco]')\n",
    "                pSUM_nsum_lstv1.append(p_isoSUM_df_nsum)\n",
    "\n",
    "            if plot_v2 == 'yes':\n",
    "                # onlyp norm v2\n",
    "                p_isoNORMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                p_isoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORMv2_df = p_isoNORMv2_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                pNORM_dfall_lstv2.append(p_isoNORMv2_df)\n",
    "                pNORM_label_lstv2.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp sum v2\n",
    "                p_isoSUMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']] \n",
    "                p_isoSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUMv2_df = p_isoSUMv2_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                p_isoSUMv2_df_nsum = [p_isoSUMv2_df.loc[i].sum() for i in p_isoSUMv2_df.index.tolist()] # for B bar label\n",
    "                pSUM_dfall_lstv2.append(p_isoSUMv2_df)\n",
    "                pSUM_label_lstv2.append('sum_IsotopeArea[pGlyco]')\n",
    "                pSUM_nsum_lstv2.append(p_isoSUMv2_df_nsum)\n",
    "\n",
    "            if plot_v3 == 'yes':\n",
    "                # onlyp norm v3\n",
    "                p_isoNORMv3_df = onlyp.loc[:, ['N(x)H(y)', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                p_isoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORMv3_df = p_isoNORMv3_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                pNORM_dfall_lstv3.append(p_isoNORMv3_df)\n",
    "                pNORM_label_lstv3.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp sum v3\n",
    "                p_isoSUMv3_df = onlyp.loc[:, ['N(x)H(y)', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']]\n",
    "                p_isoSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUMv3_df = p_isoSUMv3_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                p_isoSUMv3_df_nsum = [p_isoSUMv3_df.loc[i].sum() for i in p_isoSUMv3_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv3.append(p_isoSUMv3_df)\n",
    "                pSUM_label_lstv3.append('sum_IsotopeArea[pGlyco]')\n",
    "                pSUM_nsum_lstv3.append(p_isoSUMv3_df_nsum)\n",
    "\n",
    "            if plot_v4 == 'yes':\n",
    "                # onlyp norm v4\n",
    "                p_isoNORMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "                p_isoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORMv4_df = p_isoNORMv4_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                pNORM_dfall_lstv4.append(p_isoNORMv4_df)\n",
    "                pNORM_label_lstv4.append('norm_IsotopeArea[pGlyco]')\n",
    "                # onlyp sum v4\n",
    "                p_isoSUMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']]\n",
    "                p_isoSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUMv4_df = p_isoSUMv4_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                p_isoSUMv4_df_nsum = [p_isoSUMv4_df.loc[i].sum() for i in p_isoSUMv4_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv4.append(p_isoSUMv4_df)\n",
    "                pSUM_label_lstv4.append('sum_IsotopeArea[pGlyco]')\n",
    "                pSUM_nsum_lstv4.append(p_isoSUMv4_df_nsum)    \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if export_mono == export_isotope == 'no': # no plots will be exported\n",
    "            pass\n",
    "        else: # plotting criterium: cannot be empty list\n",
    "\n",
    "            if pNORM_dfall_lstv1 != []:\n",
    "                # onlyp NORMv1\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv1,[[1]*len(pNORM_dfall_lstv1[0].index) for i in range(len(pNORM_dfall_lstv1))],pNORM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv1_{filename}.png', bbox_inches='tight')\n",
    "            if pNORM_dfall_lstv2 != []:\n",
    "                # onlyp NORMv2\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv2,[[1]*len(pNORM_dfall_lstv2[0].index) for i in range(len(pNORM_dfall_lstv2))],pNORM_label_lstv2, neugc_exist=p_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv2_{filename}.png', bbox_inches='tight')\n",
    "            if pNORM_dfall_lstv3 != []:\n",
    "                # onlyp NORMv3\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv3,[[1]*len(pNORM_dfall_lstv3[0].index) for i in range(len(pNORM_dfall_lstv3))],pNORM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv3_{filename}.png', bbox_inches='tight')\n",
    "            if pNORM_dfall_lstv4 != []:\n",
    "                # onlyp NORMv4\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv4,[[1]*len(pNORM_dfall_lstv4[0].index) for i in range(len(pNORM_dfall_lstv4))],pNORM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "            if pSUM_dfall_lstv1 != []:\n",
    "                # onlyp SUMv1\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv1,pSUM_nsum_lstv1,pSUM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv1_{filename}.png', bbox_inches='tight')\n",
    "            if pSUM_dfall_lstv2 != []:\n",
    "                # onlyp SUMv2\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv2,pSUM_nsum_lstv2 ,pSUM_label_lstv2, neugc_exist=p_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv2_{filename}.png', bbox_inches='tight')\n",
    "            if pSUM_dfall_lstv3 != []:\n",
    "                # onlyp SUMv3\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv3,pSUM_nsum_lstv3,pSUM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv3_{filename}.png', bbox_inches='tight')\n",
    "            if pSUM_dfall_lstv4 != []:\n",
    "                # onlyp SUMv4\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv4,pSUM_nsum_lstv4 ,pSUM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile == '': # only byonic\n",
    "        print('----- Only Byonic file is detected. Start the corresponding processing. -----\\n')\n",
    "\n",
    "        # change the variable name\n",
    "        all_combined_df = byonic_df\n",
    "        # make sure scan is at the start\n",
    "        all_combined_df = all_combined_df.set_index('Scan')\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > BYONIC_SCORE_CUTOFF & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "\n",
    "        byonic_colored_id = list(set(lightgreen_ind + normalgreen_ind)) # byonic pass threshold (include below-threshold ethcd w/o pair) \n",
    "        byonic_colored_id_for_pairfile = byonic_colored_id.copy()\n",
    "        # analyze PSM (need to pass threshold)\n",
    "#         need to record the ind of below-threshold ethcd w/o pair in advance (will be excluded later, so we should not count PSM as well)\n",
    "#         so here we are forced to find pair in advance (since we are forced to list psm in all file)\n",
    "\n",
    "        if 'Pair' in all_combined_df.columns.tolist(): # pair is to identify etd with pass-threshold hcd pair for later rescue\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id]\n",
    "            pair_df = pair_df[pair_df['Pair'].str.contains('pair')]\n",
    "        #             pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            if 'ethcd' in all_combined_df['Fragment\\r\\nType'].tolist(): \n",
    "                hcd_pair_num = set(pair_df.loc[(pair_df['Fragment\\r\\nType']=='hcd'), 'Pair'].tolist())\n",
    "                pair_df.drop(pair_df[(pair_df['Fragment\\r\\nType']=='ethcd')&(~(pair_df['Pair'].isin(hcd_pair_num)))].index, inplace=True)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if 'ethcd' in all_combined_df['Fragment\\r\\nType'].tolist(): # if etd data is present (i.e. have pair)\n",
    "            byonic_excluded_ethcd_ind =  all_combined_df.loc[((all_combined_df['Fragment\\r\\nType'] == 'ethcd')&((all_combined_df['Score'] <= BYONIC_SCORE_CUTOFF)|(all_combined_df['PEP\\r\\n2D'].abs() >= 0.001))&(~(all_combined_df['Pair'].isin(pair_df['Pair']))))].index.tolist()\n",
    "            byonic_pass_id = [i for i in byonic_colored_id if i not in byonic_excluded_ethcd_ind]\n",
    "            byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_pass_id] \n",
    "        else: # all hcd, all in (cause here all the hcd are above threshold, i.e. all colored)\n",
    "            byonic_pass_id = byonic_colored_id \n",
    "            byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_pass_id] \n",
    "\n",
    "        # using groupby size function to count psm & add psm columns (new criterion: add fragment type, RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif.)\n",
    "        # byonic & byos\n",
    "        all_combined_df = all_combined_df.astype({'N-site(SequonBased)': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        b_df_pass = all_combined_df.loc[byonic_pass_id]\n",
    "        b_df_pass_forUnique = ScantimeGp(b_df_pass, gp_by = ['Fragment\\r\\nType', 'N-site(SequonBased)',  'Calc.\\r\\nm/z','rounded_FinalGlycans', 'PureSequence'], score_col = 'Score', rt_col = 'Scan\\r\\nTime', software = '[Byonic]', purpose = 'forUnique')\n",
    "        b_df_pass_forNglyco = ScantimeGp(b_df_pass, gp_by = ['N-site(SequonBased)',  'Calc.\\r\\nm/z','rounded_FinalGlycans', 'PureSequence'], score_col = 'Score', rt_col = 'Scan\\r\\nTime', software = '[Byonic]', purpose = 'forNglyco')\n",
    "        byonic_psm = b_df_pass_forNglyco.groupby(['N-site(SequonBased)', 'Calc.\\r\\nm/z','rounded_FinalGlycans', 'PureSequence', 'rt_dif_reset_forNglyco[Byonic]'])['N-site(SequonBased)'].transform('size')\n",
    "\n",
    "        all_combined_df.loc[(byonic_pass_id), 'PSM'] = byonic_psm\n",
    "        move_df(all_combined_df, 'PSM', 'N-site(SequonBased)')\n",
    "        all_combined_df.loc[(byonic_pass_id), 'rt_dif_reset_forUnique[Byonic]'] = b_df_pass_forUnique['rt_dif_reset_forUnique[Byonic]']\n",
    "        all_combined_df.loc[(byonic_pass_id), 'rt_dif_reset_forNglyco[Byonic]'] = b_df_pass_forNglyco['rt_dif_reset_forNglyco[Byonic]']\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)'] == 'N/A'), 'PSM'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[byonic_belowthreshold_id, 'PSM'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)'] == '-1'), 'PSM'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]'], axis = 1)\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_All_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "        \n",
    "\n",
    "        if 'Pair' in all_combined_df.columns.tolist(): # pair is to identify etd with pass-threshold hcd pair for later rescue\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id_for_pairfile]\n",
    "            pair_df = pair_df[pair_df['Pair'].str.contains('pair')]\n",
    "        #             pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            hcd_pair_num = set(pair_df.loc[(pair_df['Fragment\\r\\nType']=='hcd'), 'Pair'].tolist())\n",
    "            pair_df.drop(pair_df[(pair_df['Fragment\\r\\nType']=='ethcd')&(~(pair_df['Pair'].isin(hcd_pair_num)))].index, inplace=True)\n",
    "            threshold_masks_colorind(pair_df)\n",
    "            print('\\n----- Exporting \"_Pair\" file... This may take some time, please wait. -----\\n')\n",
    "            pair_df.style.apply(bg_color, axis=None).to_excel(f'{date}_Pair_{filename}.xlsx', index = False)  \n",
    "            print('\\n----- \"_Pair\" file exported. -----\\n')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        \n",
    "  #       extract rows included in colored indices list separately\n",
    "        byonicbyos_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist()]\n",
    "        byonicbyos_col_range = [col for col in all_forsimple_df.columns.tolist()]\n",
    "        \n",
    "        simple_byonicbyos = all_forsimple_df.loc[byonic_pass_id, byonicbyos_col_range] # extract colored (pass threshold) rows - below-threshold ethcd w/o pair\n",
    "\n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)'] != '-1')] # preserve n/a sites for potential o glycan data in unique\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)'] != 'N/A')&(simple_byonicbyos['N-site(SequonBased)'] != '-1')] # for simplified, n-site must exist\n",
    "\n",
    "        # clean data by dropping duplicates        \n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.drop_duplicates().reset_index(drop=True)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        # HIGHSCORE SELECTION: get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.groupby(['Fragment\\r\\nType', 'N-site(SequonBased)', 'Calc.\\r\\nm/z','rounded_FinalGlycans', 'PureSequence', 'rt_dif_reset_forUnique[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score'].idxmax()]).reset_index(drop=True)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.groupby(['N-site(SequonBased)', 'Calc.\\r\\nm/z','rounded_FinalGlycans', 'PureSequence', 'rt_dif_reset_forNglyco[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        # change variable name\n",
    "        id_df_forUnique = simple_byonicbyos_forUnique\n",
    "\n",
    "        # change all nan to blank -1\n",
    "        id_df_forUnique = id_df_forUnique.fillna(-1)\n",
    "\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df_forUnique['Mods\\r\\n(variable)'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df_forUnique['glycan_mods_sum'] = mods_nglycan_sum\n",
    "        id_df_forUnique['PepMS'] = id_df_forUnique['Calc.\\r\\nMH'] - id_df_forUnique['glycan_mods_sum']\n",
    "        id_df_forUnique.loc[(id_df_forUnique['glycan_mods_sum'] == -1), 'PepMS'] = -1\n",
    "        move_df(id_df_forUnique, 'PepMS', 'Fragment\\r\\nType')\n",
    "\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forUnique['N-site(SequonBased)'] = [ast.literal_eval(i) if type(i) == str and '(' not in i and i!='N/A' else i for i in id_df_forUnique['N-site(SequonBased)'].tolist()] # convert str back to int & tuple\n",
    "\n",
    "        # drop intermediate cols\n",
    "        id_df_forUnique = id_df_forUnique.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'glycan_mods_sum'], axis = 1) # drop the intermediate cols\n",
    "\n",
    "        col_order = id_df_forUnique.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'z')\n",
    "        print('Done sorting by z --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Calc.\\r\\nMH')\n",
    "        print('Done sorting by Calc.MH --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PepMS')\n",
    "        print('Done sorting by PepMS --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'rounded_FinalGlycans')\n",
    "        print('Done sorting by rounded_FinalGlycans --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PureSequence')\n",
    "        print('Done sorting by PureSequence --> ', end = '')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forUnique['rounded_FinalGlycans'] = [int(i) if i == '-1' else i for i in id_df_forUnique['rounded_FinalGlycans']]\n",
    "        id_df_forUnique = id_df_forUnique[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forUnique)\n",
    "        id_df_forUnique.style.apply(bg_color, axis=None).to_excel(f'{date}_UniquePep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_UniquePep\" file exported. -----\\n')\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan (for nglyco)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.set_index('Scan')\n",
    "        simple_byonicbyos_forNglyco.reset_index(level=0, inplace=True)\n",
    "\n",
    "        # change variable name\n",
    "        id_df_forNglyco = simple_byonicbyos_forNglyco\n",
    "        # change all nan to blank -1\n",
    "        id_df_forNglyco = id_df_forNglyco.fillna(-1)\n",
    "\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df_forNglyco['Mods\\r\\n(variable)'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df_forNglyco['glycan_mods_sum'] = mods_nglycan_sum\n",
    "        id_df_forNglyco['PepMS'] = id_df_forNglyco['Calc.\\r\\nMH'] - id_df_forNglyco['glycan_mods_sum']\n",
    "        id_df_forNglyco.loc[(id_df_forNglyco['glycan_mods_sum'] == -1), 'PepMS'] = -1\n",
    "        move_df(id_df_forNglyco, 'PepMS', 'Fragment\\r\\nType')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forNglyco['N-site(SequonBased)'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df_forNglyco['N-site(SequonBased)'].tolist()] # convert str back to int & tuple\n",
    "\n",
    "        # drop intermediate cols\n",
    "        id_df_forNglyco = id_df_forNglyco.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'glycan_mods_sum'], axis = 1) # drop the intermediate cols\n",
    "\n",
    "        col_order = id_df_forNglyco.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'z')\n",
    "        print('Done sorting by z --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Calc.\\r\\nMH')\n",
    "        print('Done sorting by Calc.MH --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PepMS')\n",
    "        print('Done sorting by PepMS --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'rounded_FinalGlycans')\n",
    "        print('Done sorting by rounded_FinalGlycans --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PureSequence')\n",
    "        print('Done sorting by PureSequence --> ', end = '')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forNglyco['rounded_FinalGlycans'] = [int(i) if i == '-1' else i for i in id_df_forNglyco['rounded_FinalGlycans']]\n",
    "        id_df_forNglyco = id_df_forNglyco[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_NglycoPep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forNglyco)\n",
    "        id_df_forNglyco.style.apply(bg_color, axis=None).to_excel(f'{date}_NglycoPep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_NglycoPep\" file exported. -----\\n')\n",
    "\n",
    "\n",
    "        \n",
    "    elif byonicfile == '' and byosfile == '' and pglycofile != '': # only pglyco\n",
    "        print('----- Only pGlyco file is detected. Start the corresponding processing. -----\\n')\n",
    "        # change the variable name\n",
    "        all_combined_df = pglyco_df\n",
    "        # make sure scan is at the start\n",
    "        all_combined_df = all_combined_df.set_index('Scan')\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > BYONIC_SCORE_CUTOFF & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "\n",
    "        pglyco_colored_id = list(set(lightblue_ind + normalblue_ind)) # pglyco pass threshold \n",
    "        pglyco_colored_id_for_pairfile = pglyco_colored_id.copy()\n",
    "        pglyco_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in pglyco_colored_id]\n",
    "        ## analyze PSM (need to pass threshold)\n",
    "        # need to record the ind of below-threshold ethcd w/o pair in advance (will be excluded later, so we should not count PSM as well)\n",
    "        # so here we are forced to find pair in advance (since we are forced to list psm in all file)\n",
    "        \n",
    "        # using groupby size function to count psm & add psm columns (new criterion: add fragment type, RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif.)\n",
    "        # pglyco\n",
    "        all_combined_df = all_combined_df.astype({'ProSites': 'int'})\n",
    "        all_combined_df = all_combined_df.astype({'ProSites': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        p_df_pass = all_combined_df.loc[pglyco_colored_id]\n",
    "        p_df_pass_forUnique = ScantimeGp(p_df_pass, gp_by = ['FragmentType', 'ProSites', 'rounded_PrecursorMZ','GlycanComposition_ByonicStyle', 'Peptide'], score_col = 'PepScore', rt_col = 'RT', software = '[pGlyco]', purpose = 'forUnique')\n",
    "        p_df_pass_forNglyco = ScantimeGp(p_df_pass, gp_by = ['ProSites', 'rounded_PrecursorMZ','GlycanComposition_ByonicStyle', 'Peptide'], score_col = 'PepScore', rt_col = 'RT', software = '[pGlyco]', purpose = 'forNglyco')\n",
    "        \n",
    "        pglyco_psm = p_df_pass_forNglyco.groupby(['ProSites', 'rounded_PrecursorMZ','GlycanComposition_ByonicStyle', 'Peptide', 'rt_dif_reset_forNglyco[pGlyco]'])['ProSites'].transform('size')\n",
    "        all_combined_df.loc[(pglyco_colored_id), 'PSM'] = pglyco_psm\n",
    "        move_df(all_combined_df, 'PSM', 'ProSites')\n",
    "        all_combined_df.loc[(pglyco_colored_id), 'rt_dif_reset_forUnique[pGlyco]'] = p_df_pass_forUnique['rt_dif_reset_forUnique[pGlyco]']\n",
    "        all_combined_df.loc[(pglyco_colored_id), 'rt_dif_reset_forNglyco[pGlyco]'] = p_df_pass_forNglyco['rt_dif_reset_forNglyco[pGlyco]']\n",
    "        all_combined_df.loc[(all_combined_df['ProSites'] == 'N/A'), 'PSM'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[pglyco_belowthreshold_id, 'PSM'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['ProSites'] == '-1'), 'PSM'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['rt_dif_reset_forUnique[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]'], axis = 1)\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_All_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "        \n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        # extract rows included in colored indices list separately\n",
    "        pglyco_col_range = [col for col in all_forsimple_df.columns.tolist()]\n",
    "        simple_pglyco = all_forsimple_df.loc[pglyco_colored_id, pglyco_col_range] # extract colored (pass threshold) rows\n",
    "        \n",
    "        simple_pglyco_forUnique = simple_pglyco[(simple_pglyco['ProSites'] != '-1')] # preserve n/a sites for potential o glycan data in unique\n",
    "        simple_pglyco_forNglyco = simple_pglyco[(simple_pglyco['ProSites'] != 'N/A')&(simple_pglyco['ProSites'] != '-1')] # for simplified, n-site must exist\n",
    "\n",
    "        # for nglycopep\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.loc[simple_pglyco_forNglyco['FragmentType'] == 'hcd'] # pglyco etd has the same values as hcd, so only let hcd enter unique file\n",
    "        \n",
    "        # clean data by dropping duplicates        \n",
    "        simple_pglyco_forUnique = simple_pglyco_forUnique.drop_duplicates().reset_index(drop=True)\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        # HIGHSCORE SELECTION: get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_pglyco_forUnique = simple_pglyco_forUnique.groupby(['FragmentType', 'ProSites', 'rounded_PrecursorMZ','GlycanComposition_ByonicStyle', 'Peptide', 'rt_dif_reset_forUnique[pGlyco]'], as_index=False).apply(lambda x: x.loc[x['PepScore'].idxmax()]).reset_index(drop=True)\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.groupby(['ProSites', 'rounded_PrecursorMZ','GlycanComposition_ByonicStyle', 'Peptide', 'rt_dif_reset_forNglyco[pGlyco]'], as_index=False).apply(lambda x: x.loc[x['PepScore'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        id_df_forUnique = simple_pglyco_forUnique.fillna(-1)\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forUnique['ProSites'] = [ast.literal_eval(i) if type(i) == str and '(' not in i and i!='N/A' else i for i in id_df_forUnique['ProSites'].tolist()] # convert str back to int & tuple\n",
    "        \n",
    "        # drop intermediate cols\n",
    "        id_df_forUnique = id_df_forUnique.drop(['rt_dif_reset_forUnique[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]'], axis = 1) # drop the intermediate cols\n",
    "        col_order = id_df_forUnique.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Charge')\n",
    "        print('Done sorting by Charge --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PrecursorMH')\n",
    "        print('Done sorting by PrecursorMH --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PeptideMH')\n",
    "        print('Done sorting by PeptideMH --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'GlycanComposition_ByonicStyle')\n",
    "        print('Done sorting by GlycanComposition_ByonicStyle --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Peptide')\n",
    "        print('Done sorting by Peptide --> ', end = '')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forUnique['GlycanComposition_ByonicStyle'] = [int(i) if i == '-1' else i for i in id_df_forUnique['GlycanComposition_ByonicStyle']]\n",
    "        id_df_forUnique = id_df_forUnique[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forUnique)\n",
    "        id_df_forUnique.style.apply(bg_color, axis=None).to_excel(f'{date}_UniquePep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_UniquePep\" file exported. -----\\n')\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan (for nglyco)\n",
    "        simple_pglyco_forNglyco = simple_pglyco_forNglyco.set_index('Scan')\n",
    "        simple_pglyco_forNglyco.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        id_df_forNglyco = simple_pglyco_forNglyco.fillna(-1)\n",
    "\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forNglyco['ProSites'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df_forNglyco['ProSites'].tolist()] # convert str back to int & tuple\n",
    "\n",
    "        # drop intermediate cols\n",
    "        id_df_forNglyco = id_df_forNglyco.drop(['rt_dif_reset_forUnique[pGlyco]', 'rt_dif_reset_forNglyco[pGlyco]'], axis = 1) # drop the intermediate cols\n",
    "        col_order = id_df_forNglyco.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Charge')\n",
    "        print('Done sorting by Charge --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PrecursorMH')\n",
    "        print('Done sorting by PrecursorMH --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PeptideMH')\n",
    "        print('Done sorting by PeptideMH --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'GlycanComposition_ByonicStyle')\n",
    "        print('Done sorting by GlycanComposition_ByonicStyle --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Peptide')\n",
    "        print('Done sorting by Peptide --> ', end = '')\n",
    "        \n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forNglyco['GlycanComposition_ByonicStyle'] = [int(i) if i == '-1' else i for i in id_df_forNglyco['GlycanComposition_ByonicStyle']]\n",
    "        id_df_forNglyco = id_df_forNglyco[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_NglycoPep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forNglyco)\n",
    "        id_df_forNglyco.style.apply(bg_color, axis=None).to_excel(f'{date}_NglycoPep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_NglycoPep\" file exported. -----\\n')\n",
    "\n",
    "        print('----- Start preparing quantification file of N-glycosylation . -----\\n')\n",
    "        # only single sites for quant (quant_df offers important info. for later multiIndex df construction)\n",
    "        quant = id_df_forNglyco.loc[:, ['ProSites', 'GlycanComposition_ByonicStyle', 'MonoArea', 'IsotopeArea']]\n",
    "        # calculate the sum within each n-site, then normalize mono/ iso by these sum\n",
    "        quant['sumpersite_mono'] = quant.groupby(['ProSites'])['MonoArea'].transform(lambda x: x[x!=-1].sum())\n",
    "        quant['sumpersite_iso'] = quant.groupby(['ProSites'])['IsotopeArea'].transform(lambda x: x[x!=-1].sum())\n",
    "        # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "        quant['g_sum_MonoArea'] = quant.groupby(['ProSites', 'GlycanComposition_ByonicStyle'])['MonoArea'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['h_sum_IsotopeArea'] = quant.groupby(['ProSites', 'GlycanComposition_ByonicStyle'])['IsotopeArea'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['c_norm_MonoArea'] = quant['g_sum_MonoArea']/quant['sumpersite_mono']\n",
    "        quant['d_norm_IsotopeArea'] = quant['h_sum_IsotopeArea']/quant['sumpersite_iso']\n",
    "        # since it's possible to have real 0 from calculation, change the real absent data back to -1 in sum_ & norm_\n",
    "        quant.loc[quant['MonoArea'] == -1, ['g_sum_MonoArea', 'h_sum_IsotopeArea', 'c_norm_MonoArea', 'd_norm_IsotopeArea']] = -1\n",
    "        # extract the needed cols only & split byonicbyos/pglyco, drop all -1 rows, glycans as index to outer union concat data again\n",
    "        quant_glycanid = quant.set_index('GlycanComposition_ByonicStyle')\n",
    "        quant_glycanid.index.name = 'Glycans ↓'\n",
    "        quant_glycanid.reset_index(level=0, inplace=True)\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in quant_glycanid['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        quant_glycanid.insert(0 , 'N(x) ↓', nx , True)\n",
    "        # change all nan to blank -1\n",
    "        quant_glycanid = quant_glycanid.fillna(-1)\n",
    "        quant_glycanid = quant_glycanid.drop_duplicates() # remember to drop duplicates after splitting & reconcat df\n",
    "\n",
    "        ## onlyp\n",
    "        onlyp = quant_glycanid.loc[(quant_glycanid['ProSites'] != -1), [col for col in quant_glycanid.columns.tolist()]].drop(['MonoArea', 'IsotopeArea', 'sumpersite_mono', 'sumpersite_iso'], axis=1).drop_duplicates()\n",
    "        # clean off all no data rows\n",
    "        onlyp = onlyp.loc[~((onlyp['g_sum_MonoArea']==-1)&(onlyp['h_sum_IsotopeArea']==-1)&(onlyp['c_norm_MonoArea']==-1)&(onlyp['d_norm_IsotopeArea']==-1))]\n",
    "        nx = list(set(onlyp['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        p_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        print('----- Start summary table construction. -----\\n')\n",
    "        # start grouping: N(X) -> byonic glycans -> byonic sites -> .agg({all 8 cols, apply .mean() & .mean()/total XXX})\n",
    "\n",
    "        # onlyp\n",
    "        onlyp_gp = onlyp.groupby(['N(x) ↓', 'Glycans ↓', 'ProSites']).agg({'g_sum_MonoArea': lambda x: x.mean(), 'h_sum_IsotopeArea': lambda x: x.mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea': lambda x: x.mean(), 'd_norm_IsotopeArea': lambda x: x.mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        onlyp_gp = onlyp_gp.reindex(p_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        onlyp_gp = onlyp_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        onlyp_gp.columns = onlyp_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        onlyp_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        onlyp_gp.columns = onlyp_gp.columns.set_names(['ProSites →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        onlyp_gp.columns.set_levels(['norm_MonoArea', 'norm_IsotopeArea', 'sum_MonoArea', 'sum_IsotopeArea'], level = 1, inplace=True)\n",
    "\n",
    "        print('\\n----- Exporting \"_Quant\" files... This may take some time, please wait. -----\\n')\n",
    "        \n",
    "        with pd.ExcelWriter(f'{date}_Quant_{filename}.xlsx') as writer:           \n",
    "            # onlyp\n",
    "            onlyp_gp.replace(to_replace = -1, value = np.nan , inplace = True) \n",
    "            onlyp_gp.style.background_gradient(cmap ='Blues').highlight_null(null_color='white').to_excel(writer, sheet_name = 'Sheet2(QuantP)')\n",
    "            \n",
    "        print('\\n----- \"_Quant\" file exported. -----\\n')\n",
    "        \n",
    "        print('----- Start plotting. -----\\n')\n",
    "\n",
    "        pNORM_dfall_lstv1, pNORM_label_lstv1, pNORM_dfall_lstv2, pNORM_label_lstv2 \\\n",
    "        , pNORM_dfall_lstv3, pNORM_label_lstv3, pNORM_dfall_lstv4, pNORM_label_lstv4 \\\n",
    "        , pSUM_dfall_lstv1, pSUM_label_lstv1, pSUM_nsum_lstv1, pSUM_dfall_lstv2, pSUM_label_lstv2, pSUM_nsum_lstv2 \\\n",
    "        , pSUM_dfall_lstv3, pSUM_label_lstv3, pSUM_nsum_lstv3, pSUM_dfall_lstv4, pSUM_label_lstv4, pSUM_nsum_lstv4 \\\n",
    "        = [], [], [], [], [], [], [], [], [], [] \\\n",
    "        , [], [], [], [], [], [], [], [], [], [] \n",
    "        \n",
    "        if plot_v2 == 'yes':  \n",
    "            col_order = ['N(0)', 'N(1)', 'OligoMannose', 'Complex', 'Complex+Sia'] # col order for v2 plotting\n",
    "            # necessary preprocessings for v2 plotting (modified from v1 nx)\n",
    "            # onlyp v2\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] == 'N(0)')|(onlyp['N(x) ↓'] == 'N(1)'), 'nx_version2'] = onlyp['N(x) ↓']\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] != 'N(0)')&(onlyp['N(x) ↓'] != 'N(1)')&(onlyp['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "            onlyp.loc[(onlyp['N(x) ↓'] != 'N(0)')&(onlyp['N(x) ↓'] != 'N(1)')&(onlyp['N(x) ↓'] != 'N(2)')&(onlyp['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "            p_neugc_exist = sum(onlyp['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "        \n",
    "        if plot_v3 == 'yes':\n",
    "            # necessary preprocessings for v3 plotting (modified from v1 nx)           \n",
    "            # onlyp v3\n",
    "            onlyp, onlyp_nxhy_fix_order = v3(onlyp)[0], v3(onlyp)[1]\n",
    "\n",
    "        if plot_v4 == 'yes':\n",
    "            # necessary preprocessings for v4 plotting (modified from v1 nx)            \n",
    "            # onlyp v4\n",
    "            onlyp, onlyp_fnxhy_fix_order = v4(onlyp)[0], v4(onlyp)[1]\n",
    "\n",
    "        # # make sure that sites are presented as int not float\n",
    "        onlyp = onlyp.astype({'ProSites':'Int64'})\n",
    "\n",
    "        # split bp_union into: xicauc_df / int_df / mono_df / iso_df for later clustered stacked plot (norm only)\n",
    "        if export_mono == 'yes':\n",
    "            if plot_v1 == 'yes':\n",
    "                # onlyp norm v1\n",
    "                p_monoNORM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites', 'c_norm_MonoArea']]\n",
    "                p_monoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORM_df = p_monoNORM_df.pivot_table(index='ProSites', values='c_norm_MonoArea', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                pNORM_dfall_lstv1.append(p_monoNORM_df)\n",
    "                pNORM_label_lstv1.append('norm_MonoArea')\n",
    "                # onlyp sum v1\n",
    "                p_monoSUM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites', 'g_sum_MonoArea']]\n",
    "                p_monoSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUM_df = p_monoSUM_df.pivot_table(index='ProSites', values='g_sum_MonoArea', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                p_monoSUM_df_nsum = [p_monoSUM_df.loc[i].sum() for i in p_monoSUM_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv1.append(p_monoSUM_df)\n",
    "                pSUM_label_lstv1.append('sum_MonoArea')\n",
    "                pSUM_nsum_lstv1.append(p_monoSUM_df_nsum)\n",
    "\n",
    "            if plot_v2 == 'yes':\n",
    "                # onlyp norm v2\n",
    "                p_monoNORMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites', 'c_norm_MonoArea']]\n",
    "                p_monoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORMv2_df = p_monoNORMv2_df.pivot_table(index='ProSites', values='c_norm_MonoArea', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                pNORM_dfall_lstv2.append(p_monoNORMv2_df)\n",
    "                pNORM_label_lstv2.append('norm_MonoArea')\n",
    "                # onlyp sum v2\n",
    "                p_monoSUMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites', 'g_sum_MonoArea']]\n",
    "                p_monoSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUMv2_df = p_monoSUMv2_df.pivot_table(index='ProSites', values='g_sum_MonoArea', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                p_monoSUMv2_df_nsum = [p_monoSUMv2_df.loc[i].sum() for i in p_monoSUMv2_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv2.append(p_monoSUMv2_df)\n",
    "                pSUM_label_lstv2.append('sum_MonoArea')\n",
    "                pSUM_nsum_lstv2.append(p_monoSUMv2_df_nsum)\n",
    "\n",
    "            if plot_v3 == 'yes':\n",
    "                # onlyp norm v3\n",
    "                p_monoNORMv3_df = onlyb.loc[:, ['N(x)H(y)', 'ProSites', 'c_norm_MonoArea']]\n",
    "                p_monoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORMv3_df = p_monoNORMv3_df.pivot_table(index='ProSites', values='c_norm_MonoArea', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                pNORM_dfall_lstv3.append(p_monoNORMv3_df)\n",
    "                pNORM_label_lstv3.append('norm_MonoArea')\n",
    "                # onlyp sum v3\n",
    "                p_monoSUMv3_df = onlyp.loc[:, ['N(x)H(y)', 'ProSites', 'g_sum_MonoArea']]\n",
    "                p_monoSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUMv3_df = p_monoSUMv3_df.pivot_table(index='ProSites', values='g_sum_MonoArea', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                p_monoSUMv3_df_nsum = [p_monoSUMv3_df.loc[i].sum() for i in p_monoSUMv3_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv3.append(p_monoSUMv3_df)\n",
    "                pSUM_label_lstv3.append('sum_MonoArea')\n",
    "                pSUM_nsum_lstv3.append(p_monoSUMv3_df_nsum)\n",
    "\n",
    "            if plot_v4 == 'yes':\n",
    "                # onlyp norm v4\n",
    "                p_monoNORMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites', 'c_norm_MonoArea']]\n",
    "                p_monoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoNORMv4_df = p_monoNORMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='c_norm_MonoArea', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                pNORM_dfall_lstv4.append(p_monoNORMv4_df)\n",
    "                pNORM_label_lstv4.append('norm_MonoArea')\n",
    "                # onlyp sum v4\n",
    "                p_monoSUMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites', 'g_sum_MonoArea']]\n",
    "                p_monoSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_monoSUMv4_df = p_monoSUMv4_df.pivot_table(index='ProSites', values='g_sum_MonoArea', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                p_monoSUMv4_df_nsum = [p_monoSUMv4_df.loc[i].sum() for i in p_monoSUMv4_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv4.append(p_monoSUMv4_df)\n",
    "                pSUM_label_lstv4.append('sum_MonoArea')\n",
    "                pSUM_nsum_lstv4.append(p_monoSUMv4_df_nsum)     \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if export_isotope == 'yes':\n",
    "            if plot_v1 == 'yes':\n",
    "                # onlyp norm v1\n",
    "                p_isoNORM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites', 'd_norm_IsotopeArea']]\n",
    "                p_isoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORM_df = p_isoNORM_df.pivot_table(index='ProSites', values='d_norm_IsotopeArea', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                pNORM_dfall_lstv1.append(p_isoNORM_df)\n",
    "                pNORM_label_lstv1.append('norm_IsotopeArea')\n",
    "                # onlyp sum v1\n",
    "                p_isoSUM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites', 'h_sum_IsotopeArea']] \n",
    "                p_isoSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUM_df = p_isoSUM_df.pivot_table(index='ProSites', values='h_sum_IsotopeArea', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "                p_isoSUM_df_nsum = [p_isoSUM_df.loc[i].sum() for i in p_isoSUM_df.index.tolist()] # for B bar label\n",
    "                pSUM_dfall_lstv1.append(p_isoSUM_df)\n",
    "                pSUM_label_lstv1.append('sum_IsotopeArea')\n",
    "                pSUM_nsum_lstv1.append(p_isoSUM_df_nsum)\n",
    "\n",
    "            if plot_v2 == 'yes':\n",
    "                # onlyp norm v2\n",
    "                p_isoNORMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites', 'd_norm_IsotopeArea']]\n",
    "                p_isoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORMv2_df = p_isoNORMv2_df.pivot_table(index='ProSites', values='d_norm_IsotopeArea', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                pNORM_dfall_lstv2.append(p_isoNORMv2_df)\n",
    "                pNORM_label_lstv2.append('norm_IsotopeArea')\n",
    "                # onlyp sum v2\n",
    "                p_isoSUMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites', 'h_sum_IsotopeArea']] \n",
    "                p_isoSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUMv2_df = p_isoSUMv2_df.pivot_table(index='ProSites', values='h_sum_IsotopeArea', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                p_isoSUMv2_df_nsum = [p_isoSUMv2_df.loc[i].sum() for i in p_isoSUMv2_df.index.tolist()] # for B bar label\n",
    "                pSUM_dfall_lstv2.append(p_isoSUMv2_df)\n",
    "                pSUM_label_lstv2.append('sum_IsotopeArea')\n",
    "                pSUM_nsum_lstv2.append(p_isoSUMv2_df_nsum)\n",
    "\n",
    "            if plot_v3 == 'yes':\n",
    "                # onlyp norm v3\n",
    "                p_isoNORMv3_df = onlyp.loc[:, ['N(x)H(y)', 'ProSites', 'd_norm_IsotopeArea']]\n",
    "                p_isoNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORMv3_df = p_isoNORMv3_df.pivot_table(index='ProSites', values='d_norm_IsotopeArea', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                pNORM_dfall_lstv3.append(p_isoNORMv3_df)\n",
    "                pNORM_label_lstv3.append('norm_IsotopeArea')\n",
    "                # onlyp sum v3\n",
    "                p_isoSUMv3_df = onlyp.loc[:, ['N(x)H(y)', 'ProSites', 'h_sum_IsotopeArea']]\n",
    "                p_isoSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUMv3_df = p_isoSUMv3_df.pivot_table(index='ProSites', values='h_sum_IsotopeArea', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_nxhy_fix_order)\n",
    "                p_isoSUMv3_df_nsum = [p_isoSUMv3_df.loc[i].sum() for i in p_isoSUMv3_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv3.append(p_isoSUMv3_df)\n",
    "                pSUM_label_lstv3.append('sum_IsotopeArea')\n",
    "                pSUM_nsum_lstv3.append(p_isoSUMv3_df_nsum)\n",
    "\n",
    "            if plot_v4 == 'yes':\n",
    "                # onlyp norm v4\n",
    "                p_isoNORMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites', 'd_norm_IsotopeArea']]\n",
    "                p_isoNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoNORMv4_df = p_isoNORMv4_df.pivot_table(index='ProSites', values='d_norm_IsotopeArea', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                pNORM_dfall_lstv4.append(p_isoNORMv4_df)\n",
    "                pNORM_label_lstv4.append('norm_IsotopeArea')\n",
    "                # onlyp sum v4\n",
    "                p_isoSUMv4_df = onlyp.loc[:, ['(F)N(x)H(y)', 'ProSites', 'h_sum_IsotopeArea']]\n",
    "                p_isoSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                p_isoSUMv4_df = p_isoSUMv4_df.pivot_table(index='ProSites', values='h_sum_IsotopeArea', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyp_fnxhy_fix_order)\n",
    "                p_isoSUMv4_df_nsum = [p_isoSUMv4_df.loc[i].sum() for i in p_isoSUMv4_df.index.tolist()] # for A bar label\n",
    "                pSUM_dfall_lstv4.append(p_isoSUMv4_df)\n",
    "                pSUM_label_lstv4.append('sum_IsotopeArea')\n",
    "                pSUM_nsum_lstv4.append(p_isoSUMv4_df_nsum)    \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if export_mono == export_isotope == 'no': # no plots will be exported\n",
    "            pass\n",
    "\n",
    "        else: # plotting criterium: cannot be empty list\n",
    "\n",
    "            if pNORM_dfall_lstv1 != []:\n",
    "                # onlyp NORMv1\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv1,[[1]*len(pNORM_dfall_lstv1[0].index) for i in range(len(pNORM_dfall_lstv1))],pNORM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv1_{filename}.png', bbox_inches='tight')\n",
    "            if pNORM_dfall_lstv2 != []:\n",
    "                # onlyp NORMv2\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv2,[[1]*len(pNORM_dfall_lstv2[0].index) for i in range(len(pNORM_dfall_lstv2))],pNORM_label_lstv2, neugc_exist=p_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv2_{filename}.png', bbox_inches='tight')\n",
    "            if pNORM_dfall_lstv3 != []:\n",
    "                # onlyp NORMv3\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv3,[[1]*len(pNORM_dfall_lstv3[0].index) for i in range(len(pNORM_dfall_lstv3))],pNORM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv3_{filename}.png', bbox_inches='tight')\n",
    "            if pNORM_dfall_lstv4 != []:\n",
    "                # onlyp NORMv4\n",
    "                fig = plot_clustered_stacked(pNORM_dfall_lstv4,[[1]*len(pNORM_dfall_lstv4[0].index) for i in range(len(pNORM_dfall_lstv4))],pNORM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypNORMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "            if pSUM_dfall_lstv1 != []:\n",
    "                # onlyp SUMv1\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv1,pSUM_nsum_lstv1,pSUM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv1_{filename}.png', bbox_inches='tight')\n",
    "            if pSUM_dfall_lstv2 != []:\n",
    "                # onlyp SUMv2\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv2,pSUM_nsum_lstv2 ,pSUM_label_lstv2, neugc_exist=p_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv2_{filename}.png', bbox_inches='tight')\n",
    "            if pSUM_dfall_lstv3 != []:\n",
    "                # onlyp SUMv3\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv3,pSUM_nsum_lstv3,pSUM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv3_{filename}.png', bbox_inches='tight')\n",
    "            if pSUM_dfall_lstv4 != []:\n",
    "                # onlyp SUMv4\n",
    "                fig = plot_clustered_stacked(pSUM_dfall_lstv4,pSUM_nsum_lstv4 ,pSUM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlypSUMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "    elif byonicfile == '' and byosfile != '' and pglycofile == '': # only byos \n",
    "        print('----- Only Byos file is detected. Please at least submit either Byonic or pGlyco file for further processing. -----\\n')\n",
    "    elif byonicfile == '' and byosfile != '' and pglycofile == '': # byos + pglyco \n",
    "        print('----- Byos & pGlyco files are detected. Please submit Byonic file for further processing. -----\\n')\n",
    "    elif byonicfile != '' and byosfile != '' and pglycofile == '': # byonic + byos \n",
    "        print('----- Start combining Byonic & Byos. -----\\n')\n",
    "        # combined data based on 'Scan'\n",
    "        byonic_scanasid = byonic_df.copy()\n",
    "        new_byonic_col = [n + '[Byonic]' if n != 'Scan' else n for n in byonic_scanasid.columns]\n",
    "        byonic_scanasid.columns = new_byonic_col\n",
    "        byos_scanasid = byos_df.copy()\n",
    "        new_byos_col = [n + '[Byos]' if n != 'Scan Number(s)\\r\\n(Posit)' else n for n in byos_scanasid.columns]\n",
    "        byos_scanasid.columns = new_byos_col\n",
    "        byonic_scanasid = byonic_scanasid.set_index('Scan')\n",
    "        byos_scanasid = byos_scanasid.set_index('Scan Number(s)\\r\\n(Posit)')\n",
    "        # align scan & concat (all align on row to make row number all the same)\n",
    "        a1, a2 = byonic_scanasid.align(byos_scanasid, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        all_combined_df = pd.concat([a1,a2], axis = 1)\n",
    "        all_combined_df.index.name = 'Scan'\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        all_combined_df = all_combined_df.fillna(-1)\n",
    "        ## result post-processing \n",
    "        print('\\nCombined data shape:\\nrow --> %s, column --> %s'%(all_combined_df.shape[0], all_combined_df.shape[1]))\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > BYONIC_SCORE_CUTOFF & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "        byonic_colored_id = list(set(lightgreen_ind + normalgreen_ind)) # byonic pass threshold (include below-threshold ethcd w/o pair) \n",
    "        byonic_colored_id_for_pairfile = byonic_colored_id.copy()\n",
    "        ## analyze PSM (need to pass threshold)\n",
    "        # need to record the ind of below-threshold ethcd w/o pair in advance (will be excluded later, so we should not count PSM as well)\n",
    "        # so here we are forced to find pair in advance (since we are forced to list psm in all file)\n",
    "        if 'Pair[Byonic]' in all_combined_df.columns.tolist(): # pair is to identify etd with pass-threshold hcd pair for later rescue\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair[Byonic]': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id]\n",
    "            pair_df = pair_df[pair_df['Pair[Byonic]'].str.contains('pair')]\n",
    "        #             pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            if 'ethcd' in all_combined_df['Fragment\\r\\nType[Byonic]'].tolist(): \n",
    "                hcd_pair_num = set(pair_df.loc[(pair_df['Fragment\\r\\nType[Byonic]']=='hcd'), 'Pair[Byonic]'].tolist())\n",
    "                pair_df.drop(pair_df[(pair_df['Fragment\\r\\nType[Byonic]']=='ethcd')&(~(pair_df['Pair[Byonic]'].isin(hcd_pair_num)))].index, inplace=True)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if 'ethcd' in all_combined_df['Fragment\\r\\nType[Byonic]'].tolist(): # if etd data is present (i.e. have pair)\n",
    "            byonic_excluded_ethcd_ind =  all_combined_df.loc[((all_combined_df['Fragment\\r\\nType[Byonic]'] == 'ethcd')&((all_combined_df['Score[Byonic]'] <= BYONIC_SCORE_CUTOFF)|(all_combined_df['PEP\\r\\n2D[Byonic]'].abs() >= 0.001))&(~(all_combined_df['Pair[Byonic]'].isin(pair_df['Pair[Byonic]']))))].index.tolist()\n",
    "            byonic_pass_id = [i for i in byonic_colored_id if i not in byonic_excluded_ethcd_ind]\n",
    "            byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_pass_id] \n",
    "        else: # all hcd, all in (cause here all the hcd are above threshold, i.e. all colored)\n",
    "            byonic_pass_id = byonic_colored_id \n",
    "            byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_pass_id] \n",
    "\n",
    "        # using groupby size function to count psm & add psm columns (new criterion: add fragment type, RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif.)\n",
    "        # byonic & byos\n",
    "        all_combined_df = all_combined_df.astype({'N-site(SequonBased)[Byonic]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        b_df_pass = all_combined_df.loc[byonic_pass_id]\n",
    "        b_df_pass_forUnique = ScantimeGp(b_df_pass, gp_by = ['Fragment\\r\\nType[Byonic]', 'N-site(SequonBased)[Byonic]',  'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]'], score_col = 'Score[Byonic]', rt_col = 'Scan\\r\\nTime[Byonic]', software = '[Byonic]', purpose = 'forUnique')\n",
    "        b_df_pass_forNglyco = ScantimeGp(b_df_pass, gp_by = ['N-site(SequonBased)[Byonic]',  'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]'], score_col = 'Score[Byonic]', rt_col = 'Scan\\r\\nTime[Byonic]', software = '[Byonic]', purpose = 'forNglyco')\n",
    "        byonic_psm = b_df_pass_forNglyco.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset_forNglyco[Byonic]'])['N-site(SequonBased)[Byonic]'].transform('size')\n",
    "\n",
    "        all_combined_df.loc[(byonic_pass_id), 'PSM[Byonic]'] = byonic_psm\n",
    "        move_df(all_combined_df, 'PSM[Byonic]', 'N-site(SequonBased)[Byonic]')\n",
    "        all_combined_df.loc[(byonic_pass_id), 'rt_dif_reset_forUnique[Byonic]'] = b_df_pass_forUnique['rt_dif_reset_forUnique[Byonic]']\n",
    "        all_combined_df.loc[(byonic_pass_id), 'rt_dif_reset_forNglyco[Byonic]'] = b_df_pass_forNglyco['rt_dif_reset_forNglyco[Byonic]']\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == 'N/A'), 'PSM[Byonic]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[byonic_belowthreshold_id, 'PSM[Byonic]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == '-1'), 'PSM[Byonic]'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]'], axis = 1)\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_All_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "\n",
    "        if 'Pair[Byonic]' in all_combined_df.columns.tolist(): # pair is to identify etd with pass-threshold hcd pair for later rescue\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair[Byonic]': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id_for_pairfile]\n",
    "            pair_df = pair_df[pair_df['Pair[Byonic]'].str.contains('pair')]\n",
    "        #             pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            hcd_pair_num = set(pair_df.loc[(pair_df['Fragment\\r\\nType[Byonic]']=='hcd'), 'Pair[Byonic]'].tolist())\n",
    "            pair_df.drop(pair_df[(pair_df['Fragment\\r\\nType[Byonic]']=='ethcd')&(~(pair_df['Pair[Byonic]'].isin(hcd_pair_num)))].index, inplace=True)\n",
    "            threshold_masks_colorind(pair_df)\n",
    "            print('\\n----- Exporting \"_Pair\" file... This may take some time, please wait. -----\\n')\n",
    "            pair_df.style.apply(bg_color, axis=None).to_excel(f'{date}_Pair_{filename}.xlsx', index = False)  \n",
    "            print('\\n----- \"_Pair\" file exported. -----\\n')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        # extract rows included in colored indices list separately\n",
    "        byonicbyos_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[Byonic]' in col or '[Byos]' in col]\n",
    "        simple_byonicbyos = all_forsimple_df.loc[byonic_pass_id, byonicbyos_col_range] # extract colored (pass threshold) rows - below-threshold ethcd w/o pair\n",
    "\n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != '-1')] # preserve n/a sites for potential o glycan data in unique\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != 'N/A')&(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != '-1')] # for simplified, n-site must exist\n",
    "\n",
    "        # clean data by dropping duplicates        \n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.drop_duplicates().reset_index(drop=True)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        # HIGHSCORE SELECTION: get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.groupby(['Fragment\\r\\nType[Byonic]', 'N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset_forUnique[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score[Byonic]'].idxmax()]).reset_index(drop=True)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','rounded_FinalGlycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset_forNglyco[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score[Byonic]'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "#         simple_byonicbyos_forUnique.to_excel(\"simple_byonicbyos_forUnique.xlsx\", index=False)\n",
    "#         simple_byonicbyos_forNglyco.to_excel(\"simple_byonicbyos_forNglyco.xlsx\", index=False)\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan (for unique)\n",
    "        simple_byonicbyos_forUnique = simple_byonicbyos_forUnique.set_index('Scan')\n",
    "\n",
    "        # change variable name\n",
    "        id_df_forUnique = simple_byonicbyos_forUnique\n",
    "        id_df_forUnique.index.name = 'Scan'\n",
    "        id_df_forUnique.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        id_df_forUnique = id_df_forUnique.fillna(-1)\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df_forUnique['Mods\\r\\n(variable)[Byonic]'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df_forUnique['glycan_mods_sum[Byonic]'] = mods_nglycan_sum\n",
    "        id_df_forUnique['PepMS[Byonic]'] = id_df_forUnique['Calc.\\r\\nMH[Byonic]'] - id_df_forUnique['glycan_mods_sum[Byonic]']\n",
    "        id_df_forUnique.loc[(id_df_forUnique['glycan_mods_sum[Byonic]'] == -1), 'PepMS[Byonic]'] = -1\n",
    "        move_df(id_df_forUnique, 'PepMS[Byonic]', 'Fragment\\r\\nType[Byonic]')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forUnique['N-site(SequonBased)[Byonic]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i and i!='N/A' else i for i in id_df_forUnique['N-site(SequonBased)[Byonic]'].tolist()] # convert str back to int & tuple\n",
    "\n",
    "        # drop intermediate cols\n",
    "        id_df_forUnique = id_df_forUnique.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'glycan_mods_sum[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "\n",
    "        col_order = id_df_forUnique.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'z[Byonic]')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'Calc.\\r\\nMH[Byonic]')\n",
    "        print('Done sorting by Calc.MH[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PepMS[Byonic]')\n",
    "        print('Done sorting by PepMS[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'rounded_FinalGlycans[Byonic]')\n",
    "        print('Done sorting by rounded_FinalGlycans[Byonic] --> ', end = '')\n",
    "        id_df_forUnique = sort_intstr_col(id_df_forUnique, 'PureSequence[Byonic]')\n",
    "        print('Done sorting by PureSequence[Byonic] --> ', end = '')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forUnique['rounded_FinalGlycans[Byonic]'] = [int(i) if i == '-1' else i for i in id_df_forUnique['rounded_FinalGlycans[Byonic]']]\n",
    "        id_df_forUnique = id_df_forUnique[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forUnique)\n",
    "        id_df_forUnique.style.apply(bg_color, axis=None).to_excel(f'{date}_UniquePep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_UniquePep\" file exported. -----\\n')\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan (for nglyco)\n",
    "        simple_byonicbyos_forNglyco = simple_byonicbyos_forNglyco.set_index('Scan')\n",
    "        # change variable name\n",
    "        id_df_forNglyco = simple_byonicbyos_forNglyco\n",
    "        id_df_forNglyco.index.name = 'Scan'\n",
    "        id_df_forNglyco.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        id_df_forNglyco = id_df_forNglyco.fillna(-1)\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df_forNglyco['Mods\\r\\n(variable)[Byonic]'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df_forNglyco['glycan_mods_sum[Byonic]'] = mods_nglycan_sum\n",
    "        id_df_forNglyco['PepMS[Byonic]'] = id_df_forNglyco['Calc.\\r\\nMH[Byonic]'] - id_df_forNglyco['glycan_mods_sum[Byonic]']\n",
    "        id_df_forNglyco.loc[(id_df_forNglyco['glycan_mods_sum[Byonic]'] == -1), 'PepMS[Byonic]'] = -1\n",
    "        move_df(id_df_forNglyco, 'PepMS[Byonic]', 'Fragment\\r\\nType[Byonic]')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df_forNglyco['N-site(SequonBased)[Byonic]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df_forNglyco['N-site(SequonBased)[Byonic]'].tolist()] # convert str back to int & tuple\n",
    "\n",
    "        # drop intermediate cols\n",
    "        id_df_forNglyco = id_df_forNglyco.drop(['rt_dif_reset_forUnique[Byonic]', 'rt_dif_reset_forNglyco[Byonic]', 'glycan_mods_sum[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "        col_order = id_df_forNglyco.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'z[Byonic]')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'Calc.\\r\\nMH[Byonic]')\n",
    "        print('Done sorting by Calc.MH[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PepMS[Byonic]')\n",
    "        print('Done sorting by PepMS[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'rounded_FinalGlycans[Byonic]')\n",
    "        print('Done sorting by rounded_FinalGlycans[Byonic] --> ', end = '')\n",
    "        id_df_forNglyco = sort_intstr_col(id_df_forNglyco, 'PureSequence[Byonic]')\n",
    "        print('Done sorting by PureSequence[Byonic] --> ', end = '')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df_forNglyco['rounded_FinalGlycans[Byonic]'] = [int(i) if i == '-1' else i for i in id_df_forNglyco['rounded_FinalGlycans[Byonic]']]\n",
    "        id_df_forNglyco = id_df_forNglyco[col_order]\n",
    "\n",
    "        print('\\n----- Exporting \"_NglycoPep\" file... This may take some time, please wait. -----\\n')\n",
    "        threshold_masks_colorind(id_df_forNglyco)\n",
    "        id_df_forNglyco.style.apply(bg_color, axis=None).to_excel(f'{date}_NglycoPep_{filename}.xlsx', index = False)  \n",
    "        print('\\n----- \"_NglycoPep\" file exported. -----\\n')\n",
    "\n",
    "        print('----- Start preparing quantification file of N-glycosylation . -----\\n')\n",
    "        # only single sites for quant (quant_df offers important info. for later multiIndex df construction)\n",
    "        quant = id_df_forNglyco[id_df_forNglyco['N-site(SequonBased)[Byonic]'].apply(lambda x: isinstance(x, int))]\n",
    "        # avoid adding values from below-threshold rows: if deepgreen -> change value to -1, if deepblue -> change value to -1.(-1 to make lambda function easier to write)\n",
    "        threshold_masks_colorind(quant)\n",
    "        # calculate the sum within each n-site, then normalize xicauc/ int/ mono/ iso by these sum\n",
    "        quant['sumpersite_xicauc'] = quant.groupby(['N-site(SequonBased)[Byonic]'])['XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        quant['sumpersite_int'] = quant.groupby(['N-site(SequonBased)[Byonic]'])['Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        # convert all the 'N/A' in byonic glycans to 'Unoccupied'\n",
    "        quant.loc[(quant['rounded_FinalGlycans[Byonic]'] == 'N/A'), ['rounded_FinalGlycans[Byonic]']] = 'Unoccupied'\n",
    "        # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "        quant['e_sum_XIC\\r\\nAUC[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'rounded_FinalGlycans[Byonic]'])['XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['f_sum_Apex Int.\\r\\n(Posit)[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'rounded_FinalGlycans[Byonic]'])['Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['a_norm_XIC\\r\\nAUC[Byos]'] = quant['e_sum_XIC\\r\\nAUC[Byos]']/quant['sumpersite_xicauc']\n",
    "        quant['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = quant['f_sum_Apex Int.\\r\\n(Posit)[Byos]']/quant['sumpersite_int']\n",
    "\n",
    "        # since it's possible to have real 0 from calculation, change the real absent data back to -1 in sum_ & norm_\n",
    "        quant.loc[quant['XIC\\r\\nAUC[Byos]'] == -1, ['e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'a_norm_XIC\\r\\nAUC[Byos]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] = -1 \n",
    "        # extract the needed cols only & split byonicbyos/pglyco, drop all -1 rows, glycans as index to outer union concat data again\n",
    "        quant_bb = quant[['N-site(SequonBased)[Byonic]', 'rounded_FinalGlycans[Byonic]', 'MS2 Search\\r\\nAlias name[Byos]', 'e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'a_norm_XIC\\r\\nAUC[Byos]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "        quant_bb = quant_bb.loc[quant_bb['N-site(SequonBased)[Byonic]'] != -1]\n",
    "        quant_bb = quant_bb.set_index('rounded_FinalGlycans[Byonic]')\n",
    "        # change variable name\n",
    "        quant_glycanid = quant_bb\n",
    "        quant_glycanid.index.name = 'Glycans ↓'\n",
    "        quant_glycanid.reset_index(level=0, inplace=True)\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in quant_glycanid['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        quant_glycanid.insert(0 , 'N(x) ↓', nx , True)\n",
    "        quant_glycanid = quant_glycanid.drop('MS2 Search\\r\\nAlias name[Byos]', axis = 1)\n",
    "        # change all nan to blank -1\n",
    "        quant_glycanid = quant_glycanid.fillna(-1)\n",
    "        quant_glycanid = quant_glycanid.drop_duplicates() # remember to drop duplicates after splitting & reconcat df\n",
    "        # generate 5 versions: bp_intersection (both sites are present at the same time <intersection>), bp_union (n site union), only b (xicauc/int), only p (mono/isotope)\n",
    "        ## onlyb\n",
    "        onlyb = quant_glycanid.loc[(quant_glycanid['N-site(SequonBased)[Byonic]'] != -1)]\n",
    "        onlyb_forunion = onlyb.copy().drop_duplicates()\n",
    "        # clean off all no data rows\n",
    "        onlyb = onlyb.loc[~((onlyb['e_sum_XIC\\r\\nAUC[Byos]']==-1)&(onlyb['f_sum_Apex Int.\\r\\n(Posit)[Byos]']==-1)&(onlyb['a_norm_XIC\\r\\nAUC[Byos]']==-1)&(onlyb['b_norm_Apex Int.\\r\\n(Posit)[Byos]']==-1))]\n",
    "        nx = list(set(onlyb['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        b_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        ## onlyb_top10\n",
    "        onlyb_top10 = onlyb.copy()\n",
    "        # xicauc_top10 = onlyb_top10.groupby('N-site(SequonBased)[Byonic]')['a_norm_XIC\\r\\nAUC[Byos]'].nlargest(topN).droplevel(level = 0).index.tolist()\n",
    "        xicauc_top10 = onlyb_top10.groupby('N-site(SequonBased)[Byonic]').apply(pd.DataFrame.nlargest, n=5, columns='a_norm_XIC\\r\\nAUC[Byos]').droplevel(level=0).index.tolist()\n",
    "        int_top10 = onlyb_top10.groupby('N-site(SequonBased)[Byonic]').apply(pd.DataFrame.nlargest, n=5, columns='b_norm_Apex Int.\\r\\n(Posit)[Byos]').droplevel(level=0).index.tolist()\n",
    "        onlyb_top10.loc[[i for i in onlyb_top10.index.tolist() if i not in xicauc_top10], 'a_norm_XIC\\r\\nAUC[Byos]'] = -1\n",
    "        onlyb_top10.loc[[i for i in onlyb_top10.index.tolist() if i not in int_top10], 'b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = -1\n",
    "        onlyb_top10 = onlyb_top10.loc[(onlyb_top10['a_norm_XIC\\r\\nAUC[Byos]'] != -1)|(onlyb_top10['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] != -1)].reset_index(drop=True).drop(['N(x) ↓', 'e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'N(x) ↓'], axis = 1)\n",
    "\n",
    "        print('----- Start summary table construction. -----\\n')\n",
    "        # start grouping: N(X) -> byonic glycans -> byonic sites -> .agg({all 8 cols, apply .mean() & .mean()/total XXX})\n",
    "        # onlyb\n",
    "        onlyb_gp = onlyb.groupby(['N(x) ↓', 'Glycans ↓', 'N-site(SequonBased)[Byonic]']).agg({'e_sum_XIC\\r\\nAUC[Byos]': lambda x: x.mean(), 'f_sum_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x.mean() \\\n",
    "                                                                                              , 'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x.mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x.mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        onlyb_gp = onlyb_gp.reindex(b_new_nx, level = 0)\n",
    "        # unstack byonic n-sites\n",
    "        onlyb_gp = onlyb_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        onlyb_gp.columns = onlyb_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        onlyb_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        onlyb_gp.columns = onlyb_gp.columns.set_names(['N-site(SequonBased)[Byonic] →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "#         onlyb_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'sum_XIC\\r\\nAUC[Byos]', 'sum_Apex Int.\\r\\n(Posit)[Byos]'], level = 1, inplace=True)\n",
    "        onlyb_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'sum_XIC\\r\\nAUC[Byos]', 'sum_Apex Int.\\r\\n(Posit)[Byos]'], level = 1)\n",
    "#         onlyb_gp.to_excel(\"onlyb_gp_setlevels.xlsx\")\n",
    "#         print('\\n----- Exporting \"_Quant\" files... This may take some time, please wait. -----\\n')\n",
    "\n",
    "#         with pd.ExcelWriter(f'{date}_Quant_{filename}.xlsx') as writer:           \n",
    "#             # onlyb\n",
    "#             onlyb_gp.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "# #             onlyb_gp.to_excel(\"onlyb_gp.xlsx\")\n",
    "#             onlyb_gp.style.background_gradient(cmap ='Greens').highlight_null(null_color='white').to_excel(writer, sheet_name = 'Sheet1(QuantB)')\n",
    "\n",
    "#         print('\\n----- \"_Quant\" file exported. -----\\n')\n",
    "\n",
    "        print('----- Start plotting. -----\\n')\n",
    "        bNORM_dfall_lstv1, bNORM_label_lstv1, bNORM_dfall_lstv2, bNORM_label_lstv2 \\\n",
    "        , bNORM_dfall_lstv3, bNORM_label_lstv3, bNORM_dfall_lstv4, bNORM_label_lstv4 \\\n",
    "        , bSUM_dfall_lstv1, bSUM_label_lstv1, bSUM_nsum_lstv1, bSUM_dfall_lstv2, bSUM_label_lstv2, bSUM_nsum_lstv2 \\\n",
    "        , bSUM_dfall_lstv3, bSUM_label_lstv3, bSUM_nsum_lstv3, bSUM_dfall_lstv4, bSUM_label_lstv4, bSUM_nsum_lstv4 \\\n",
    "        = [], [], [], [], [], [], [], [], [], [] \\\n",
    "        , [], [], [], [], [], [], [], [], [], [] \n",
    "\n",
    "        if plot_v2 == 'yes':  \n",
    "            col_order = ['N(0)', 'N(1)', 'OligoMannose', 'Complex', 'Complex+Sia'] # col order for v2 plotting\n",
    "            # necessary preprocessings for v2 plotting (modified from v1 nx)\n",
    "            # onlyb v2\n",
    "            onlyb.loc[(onlyb['N(x) ↓'] == 'N(0)')|(onlyb['N(x) ↓'] == 'N(1)'), 'nx_version2'] = onlyb['N(x) ↓']\n",
    "            onlyb.loc[(onlyb['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "            onlyb.loc[(onlyb['N(x) ↓'] != 'N(0)')&(onlyb['N(x) ↓'] != 'N(1)')&(onlyb['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "            onlyb.loc[(onlyb['N(x) ↓'] != 'N(0)')&(onlyb['N(x) ↓'] != 'N(1)')&(onlyb['N(x) ↓'] != 'N(2)')&(onlyb['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "            b_neugc_exist = sum(onlyb['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "\n",
    "        if plot_v3 == 'yes':\n",
    "            # necessary preprocessings for v3 plotting (modified from v1 nx)            \n",
    "            # onlyb v3\n",
    "            onlyb, onlyb_nxhy_fix_order = v3(onlyb)[0], v3(onlyb)[1] \n",
    "\n",
    "        if plot_v4 == 'yes':\n",
    "            # necessary preprocessings for v4 plotting (modified from v1 nx)         \n",
    "            # onlyb v4\n",
    "            onlyb, onlyb_fnxhy_fix_order = v4(onlyb)[0], v4(onlyb)[1]    \n",
    "\n",
    "        # make sure that sites are presented as int not float\n",
    "        onlyb = onlyb.astype({'N-site(SequonBased)[Byonic]':'Int64'})\n",
    "\n",
    "        # split bp_union into: xicauc_df / int_df / mono_df / iso_df for later clustered stacked plot (norm only)\n",
    "        if export_xicauc == 'yes':\n",
    "            if plot_v1 == 'yes':\n",
    "                # onlyb norm v1\n",
    "                b_xicaucNORM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucNORM_df = b_xicaucNORM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "                bNORM_dfall_lstv1.append(b_xicaucNORM_df)\n",
    "                bNORM_label_lstv1.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb sum v1\n",
    "                b_xicaucSUM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucSUM_df = b_xicaucSUM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "                b_xicaucSUM_df_nsum = [b_xicaucSUM_df.loc[i].sum() for i in b_xicaucSUM_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv1.append(b_xicaucSUM_df)\n",
    "                bSUM_label_lstv1.append('sum_XIC AUC[Byos]')\n",
    "                bSUM_nsum_lstv1.append(b_xicaucSUM_df_nsum)\n",
    "\n",
    "            if plot_v2 == 'yes':\n",
    "                # onlyb norm v2\n",
    "                b_xicaucNORMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucNORMv2_df = b_xicaucNORMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bNORM_dfall_lstv2.append(b_xicaucNORMv2_df)\n",
    "                bNORM_label_lstv2.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb sum v2\n",
    "                b_xicaucSUMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucSUMv2_df = b_xicaucSUMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                b_xicaucSUMv2_df_nsum = [b_xicaucSUMv2_df.loc[i].sum() for i in b_xicaucSUMv2_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv2.append(b_xicaucSUMv2_df)\n",
    "                bSUM_label_lstv2.append('sum_XIC AUC[Byos]')\n",
    "                bSUM_nsum_lstv2.append(b_xicaucSUMv2_df_nsum)\n",
    "\n",
    "            if plot_v3 == 'yes':\n",
    "                # onlyb norm v3\n",
    "                b_xicaucNORMv3_df = onlyb.loc[:, ['N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucNORMv3_df = b_xicaucNORMv3_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_nxhy_fix_order)\n",
    "                bNORM_dfall_lstv3.append(b_xicaucNORMv3_df)\n",
    "                bNORM_label_lstv3.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb sum v3\n",
    "                b_xicaucSUMv3_df = onlyb.loc[:, ['N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucSUMv3_df = b_xicaucSUMv3_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_nxhy_fix_order)\n",
    "                b_xicaucSUMv3_df_nsum = [b_xicaucSUMv3_df.loc[i].sum() for i in b_xicaucSUMv3_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv3.append(b_xicaucSUMv3_df)\n",
    "                bSUM_label_lstv3.append('sum_XIC AUC[Byos]')\n",
    "                bSUM_nsum_lstv3.append(b_xicaucSUMv3_df_nsum)\n",
    "\n",
    "            if plot_v4 == 'yes':\n",
    "                # onlyb norm v4\n",
    "                b_xicaucNORMv4_df = onlyb.loc[:, ['(F)N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucNORMv4_df = b_xicaucNORMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_fnxhy_fix_order)\n",
    "                bNORM_dfall_lstv4.append(b_xicaucNORMv4_df)\n",
    "                bNORM_label_lstv4.append('norm_XIC AUC[Byos]')\n",
    "                # onlyb sum v4\n",
    "                b_xicaucSUMv4_df = onlyb.loc[:, ['(F)N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "                b_xicaucSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_xicaucSUMv4_df = b_xicaucSUMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_fnxhy_fix_order)\n",
    "                b_xicaucSUMv4_df_nsum = [b_xicaucSUMv4_df.loc[i].sum() for i in b_xicaucSUMv4_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv4.append(b_xicaucSUMv4_df)\n",
    "                bSUM_label_lstv4.append('sum_XIC AUC[Byos]')\n",
    "                bSUM_nsum_lstv4.append(b_xicaucSUMv4_df_nsum)    \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if export_int == 'yes': \n",
    "            if plot_v1 == 'yes':\n",
    "                # onlyb norm v1 \n",
    "                b_intNORM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                b_intNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intNORM_df = b_intNORM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "                bNORM_dfall_lstv1.append(b_intNORM_df)\n",
    "                bNORM_label_lstv1.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb sum v1\n",
    "                b_intSUM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                b_intSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intSUM_df = b_intSUM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "                b_intSUM_df_nsum = [b_intSUM_df.loc[i].sum() for i in b_intSUM_df.index.tolist()] # for B bar label\n",
    "                bSUM_dfall_lstv1.append(b_intSUM_df)\n",
    "                bSUM_label_lstv1.append('sum_Apex Int.(Posit)[Byos]')\n",
    "                bSUM_nsum_lstv1.append(b_intSUM_df_nsum)\n",
    "            if plot_v2 == 'yes':\n",
    "                # onlyb norm v2\n",
    "                b_intNORMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                b_intNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intNORMv2_df = b_intNORMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                bNORM_dfall_lstv2.append(b_intNORMv2_df)\n",
    "                bNORM_label_lstv2.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb sum v2\n",
    "                b_intSUMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "                b_intSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intSUMv2_df = b_intSUMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "                b_intSUMv2_df_nsum = [b_intSUMv2_df.loc[i].sum() for i in b_intSUMv2_df.index.tolist()] # for B bar label\n",
    "                bSUM_dfall_lstv2.append(b_intSUMv2_df)\n",
    "                bSUM_label_lstv2.append('sum_Apex Int.(Posit)[Byos]')\n",
    "                bSUM_nsum_lstv2.append(b_intSUMv2_df_nsum)\n",
    "            if plot_v3 == 'yes':\n",
    "                # onlyb norm v3\n",
    "                b_intNORMv3_df = onlyb.loc[:, ['N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                b_intNORMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intNORMv3_df = b_intNORMv3_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_nxhy_fix_order)\n",
    "                bNORM_dfall_lstv3.append(b_intNORMv3_df)\n",
    "                bNORM_label_lstv3.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb sum v3\n",
    "                b_intSUMv3_df = onlyb.loc[:, ['N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                b_intSUMv3_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intSUMv3_df = b_intSUMv3_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_nxhy_fix_order)\n",
    "                b_intSUMv3_df_nsum = [b_intSUMv3_df.loc[i].sum() for i in b_intSUMv3_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv3.append(b_intSUMv3_df)\n",
    "                bSUM_label_lstv3.append('sum_Apex Int.(Posit)[Byos]')\n",
    "                bSUM_nsum_lstv3.append(b_intSUMv3_df_nsum)\n",
    "            if plot_v4 == 'yes':\n",
    "                # onlyb norm v4\n",
    "                b_intNORMv4_df = onlyb.loc[:, ['(F)N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                b_intNORMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intNORMv4_df = b_intNORMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_fnxhy_fix_order)\n",
    "                bNORM_dfall_lstv4.append(b_intNORMv4_df)\n",
    "                bNORM_label_lstv4.append('norm_Apex Int.(Posit)[Byos]')\n",
    "                # onlyb sum v4\n",
    "                b_intSUMv4_df = onlyb.loc[:, ['(F)N(x)H(y)', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "                b_intSUMv4_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "                b_intSUMv4_df = b_intSUMv4_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='(F)N(x)H(y)', aggfunc=np.sum).reindex(columns=onlyb_fnxhy_fix_order)\n",
    "                b_intSUMv4_df_nsum = [b_intSUMv4_df.loc[i].sum() for i in b_intSUMv4_df.index.tolist()] # for A bar label\n",
    "                bSUM_dfall_lstv4.append(b_intSUMv4_df)\n",
    "                bSUM_label_lstv4.append('sum_Apex Int.(Posit)[Byos]')\n",
    "                bSUM_nsum_lstv4.append(b_intSUMv4_df_nsum)       \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if export_xicauc == export_int == export_mono == export_isotope == 'no': # no plots will be exported\n",
    "            pass\n",
    "        else: # plotting criterium: cannot be empty list\n",
    "\n",
    "            if bNORM_dfall_lstv1 != []:\n",
    "                # onlyb NORMv1\n",
    "                fig = plot_clustered_stacked(bNORM_dfall_lstv1, [[1]*len(bNORM_dfall_lstv1[0].index) for i in range(len(bNORM_dfall_lstv1))],bNORM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybNORMv1_{filename}.png', bbox_inches='tight')\n",
    "            if bNORM_dfall_lstv2 != []:\n",
    "                # onlyb NORMv2\n",
    "                fig = plot_clustered_stacked(bNORM_dfall_lstv2, [[1]*len(bNORM_dfall_lstv2[0].index) for i in range(len(bNORM_dfall_lstv2))],bNORM_label_lstv2, neugc_exist=b_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybNORMv2_{filename}.png', bbox_inches='tight')\n",
    "            if bNORM_dfall_lstv3 != []:\n",
    "                # onlyb NORMv3\n",
    "                fig = plot_clustered_stacked(bNORM_dfall_lstv3, [[1]*len(bNORM_dfall_lstv3[0].index) for i in range(len(bNORM_dfall_lstv3))],bNORM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybNORMv3_{filename}.png', bbox_inches='tight')\n",
    "            if bNORM_dfall_lstv4 != []:\n",
    "                # onlyb NORMv4\n",
    "                fig = plot_clustered_stacked(bNORM_dfall_lstv4, [[1]*len(bNORM_dfall_lstv4[0].index) for i in range(len(bNORM_dfall_lstv4))],bNORM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybNORMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "            if bSUM_dfall_lstv1 != []:\n",
    "                # onlyb SUMv1\n",
    "                fig = plot_clustered_stacked(bSUM_dfall_lstv1, bSUM_nsum_lstv1,bSUM_label_lstv1)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybSUMv1_{filename}.png', bbox_inches='tight')\n",
    "            if bSUM_dfall_lstv2 != []:\n",
    "                # onlyb SUMv2\n",
    "                fig = plot_clustered_stacked(bSUM_dfall_lstv2,bSUM_nsum_lstv2 ,bSUM_label_lstv2, neugc_exist=b_neugc_exist)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybSUMv2_{filename}.png', bbox_inches='tight')\n",
    "            if bSUM_dfall_lstv3 != []:\n",
    "                # onlyb SUMv3\n",
    "                fig = plot_clustered_stacked(bSUM_dfall_lstv3, bSUM_nsum_lstv3,bSUM_label_lstv3, detailedHighMan=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybSUMv3_{filename}.png', bbox_inches='tight')\n",
    "            if bSUM_dfall_lstv4 != []:\n",
    "                # onlyb SUMv4\n",
    "                fig = plot_clustered_stacked(bSUM_dfall_lstv4,bSUM_nsum_lstv4 ,bSUM_label_lstv4, detailedHighMan=True, fucosylation=True)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(f'{date}_onlybSUMv4_{filename}.png', bbox_inches='tight')\n",
    "\n",
    "        if seq != '':\n",
    "            print('----- Start preparing MajorGlycoformTable. -----\\n')\n",
    "            # prepare needed lists for the table cols (no./nsite/sequon are the indices, major glycoform is the col)\n",
    "            result = findNPosBySequon(seq)\n",
    "            nsite = [t[0] for t in result]\n",
    "            nsite.append('')\n",
    "            sequon = [t[1] for t in result]\n",
    "            sequon.append('')\n",
    "            no = [i+1 for i in range(len(nsite)-1)]\n",
    "            table = [(no[i], nsite[i], sequon[i]) for i in range(len(no))]\n",
    "            table = pd.DataFrame(table)\n",
    "            table.columns = ['No.', 'N-site', 'Sequon']\n",
    "            # rename col & extract xicauc max and its glycoform\n",
    "            onlyb = onlyb.rename(columns={'Glycans ↓':'Major Glycoform'}).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "            # (1 OF 2 WAYS TO DETERMINE MAJOR GLYCOFORM) TABLE1: CHOOSE HIGHEST XICAUC (yu-chun's version: from quant, so man4 & other below-core are not cleaned)\n",
    "            # bp_union = bp_union.groupby('N-site(Byonic ∪ pGlyco) →').apply(lambda x: x.loc[x['a_norm_XIC\\r\\nAUC[Byos]'].idxmax(), ['N-site(Byonic ∪ pGlyco) →', 'Major Glycoform(union)']]).reset_index(drop=True)\n",
    "            onlyb_forTable1 = onlyb.groupby('N-site(SequonBased)[Byonic]').apply(lambda x: x.loc[x['a_norm_XIC\\r\\nAUC[Byos]'].idxmax(), ['N-site(SequonBased)[Byonic]', 'Major Glycoform']]).reset_index(drop=True)    \n",
    "            onlyb_forTable1 = onlyb_forTable1.set_index('N-site(SequonBased)[Byonic]')\n",
    "            onlyb_forTable1.index.name = 'N-site'\n",
    "            onlyb_forTable1 = onlyb_forTable1.reset_index()\n",
    "            # map the result to the empty df\n",
    "            table1 = table.merge(onlyb_forTable1, on=['N-site'], how='outer')\n",
    "\n",
    "            # (2 OF 2 WAYS TO DETERMINE MAJOR GLYCOFORM) TABLE2: CHOOSE MAJOR CLASS (HIGHMAN/HYBRID/COMPLEX/UNOCCUPIED) -> CHOOSE HIGHEST XICAUC WITHIN MAJOR CLASS (danny's version: man4 & other below-core are cleaned, just like data used for xicauc bar/pie charts)\n",
    "            # clean man4 & below-core structure & add glycan classes col by ModifiedGlycanTypeAnalysis func (highman/hybrid/complex/unoccupied) \n",
    "            onlyb_forTable2 = ModifiedGlycanTypeAnalysis(onlyb, 'Major Glycoform')\n",
    "            onlyb_forTable2 = normalizer(onlyb_forTable2, 'N-site(SequonBased)[Byonic]')\n",
    "\n",
    "            # find major class then find the xicauc / isotope area max within major class\n",
    "            onlyb_forTable2 = findMajorClass(onlyb_forTable2, 'N-site(SequonBased)[Byonic]', 'Major Glycoform')\n",
    "            onlyb_forTable2 = onlyb_forTable2.groupby('N-site(SequonBased)[Byonic]').apply(lambda x: x.loc[x['a_norm_XIC\\r\\nAUC[Byos]'].idxmax(), ['N-site(SequonBased)[Byonic]', 'Major Glycoform']]).reset_index(drop=True)\n",
    "            onlyb_forTable2 = onlyb_forTable2.set_index('N-site(SequonBased)[Byonic]')\n",
    "            onlyb_forTable2.index.name = 'N-site'\n",
    "            onlyb_forTable2 = onlyb_forTable2.reset_index()\n",
    "\n",
    "            # map the result to the empty df\n",
    "            table2 = table.merge(onlyb_forTable2, on=['N-site'], how='outer')\n",
    "\n",
    "            with pd.ExcelWriter(f'{date}_MajorGlycoformTable_{filename}.xlsx') as writer:   \n",
    "                table1.to_excel(writer, sheet_name = 'XICAUC max. within site', index=False)\n",
    "                table2.to_excel(writer, sheet_name = 'XICAUC max. within major class', index=False)\n",
    "\n",
    "            print('\\n----- MajorGlycoformTable exported. -----\\n')\n",
    "    # EXECUTION TIME\n",
    "    print(\"\\nAll tasks completed.\\nExecution time: %.2f seconds\"%(time.time() - start_time))\n",
    "    \n",
    "# RUN PROCESSING\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af861f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
